# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1\fix_akshare_collector.py
# File Name: fix_akshare_collector
# @ Author: mango-gh22
# @ Dateï¼š2025/12/6 19:18
"""
desc 
"""
# !/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤AKShareé‡‡é›†å™¨ä½¿ç”¨æ ‡å‡†åˆ—å
"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

print("ğŸ”§ ä¿®å¤AKShareé‡‡é›†å™¨")
print("=" * 60)


def fix_akshare_column_names():
    """ä¿®å¤AKShareé‡‡é›†å™¨çš„åˆ—å"""
    akshare_file = 'src/data/akshare_collector.py'

    if not os.path.exists(akshare_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {akshare_file}")
        return False

    print("ğŸ“„ è¯»å–AKShareé‡‡é›†å™¨æ–‡ä»¶...")
    with open(akshare_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # å¤‡ä»½åŸæ–‡ä»¶
    import shutil
    backup_file = akshare_file + '.backup_nonstandard'
    shutil.copy2(akshare_file, backup_file)
    print(f"ğŸ“¦ å·²å¤‡ä»½åˆ°: {backup_file}")

    # æ£€æŸ¥å¹¶ä¿®å¤åˆ—åæ˜ å°„
    if 'open_price' in content and 'close_price' in content:
        print("ğŸ”„ å‘ç°éæ ‡å‡†åˆ—åï¼Œè¿›è¡Œä¿®å¤...")

        # ä¿®å¤åˆ—åæ˜ å°„
        old_mapping = """column_mapping = {
                'æ—¥æœŸ': 'trade_date',
                'å¼€ç›˜': 'open_price',
                'æ”¶ç›˜': 'close_price',
                'æœ€é«˜': 'high_price',
                'æœ€ä½': 'low_price',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'pct_change',
                'æ¶¨è·Œé¢': 'change_amount',
                'æ¢æ‰‹ç‡': 'turnover_rate'
            }"""

        new_mapping = """column_mapping = {
                'æ—¥æœŸ': 'trade_date',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'pct_change',
                'æ¶¨è·Œé¢': 'change',
                'æ¢æ‰‹ç‡': 'turnover_rate'
            }"""

        if old_mapping in content:
            content = content.replace(old_mapping, new_mapping)
            print("âœ… ä¿®å¤åˆ—åæ˜ å°„")
        else:
            # å°è¯•å…¶ä»–æ ¼å¼
            content = content.replace("'å¼€ç›˜': 'open_price'", "'å¼€ç›˜': 'open'")
            content = content.replace("'æ”¶ç›˜': 'close_price'", "'æ”¶ç›˜': 'close'")
            content = content.replace("'æœ€é«˜': 'high_price'", "'æœ€é«˜': 'high'")
            content = content.replace("'æœ€ä½': 'low_price'", "'æœ€ä½': 'low'")
            content = content.replace("'æ¶¨è·Œé¢': 'change_amount'", "'æ¶¨è·Œé¢': 'change'")
            print("âœ… ç›´æ¥æ›¿æ¢åˆ—å")

    # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
    with open(akshare_file, 'w', encoding='utf-8') as f:
        f.write(content)

    print("âœ… AKShareé‡‡é›†å™¨å·²ä¿®å¤ä¸ºä½¿ç”¨æ ‡å‡†åˆ—å")

    # æ˜¾ç¤ºä¿®å¤å†…å®¹
    print("\nğŸ“ ä¿®å¤åçš„åˆ—åæ˜ å°„:")
    lines = content.split('\n')
    for i, line in enumerate(lines):
        if 'column_mapping' in line:
            for j in range(i, min(i + 15, len(lines))):
                print(f"  {lines[j]}")
            break

    return True


def create_standard_akshare_collector():
    """åˆ›å»ºæ ‡å‡†åŒ–çš„AKShareé‡‡é›†å™¨"""
    print("\nğŸ“ åˆ›å»ºæ ‡å‡†åŒ–çš„AKShareé‡‡é›†å™¨æ¨¡æ¿...")

    standard_template = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AKShareæ•°æ®é‡‡é›†å™¨ï¼ˆæ ‡å‡†åŒ–ç‰ˆï¼‰- ä½¿ç”¨æ ‡å‡†åˆ—å
"""

import akshare as ak
import pandas as pd
from typing import Optional, Dict, Any
import logging
from datetime import datetime

from .data_collector import BaseDataCollector

logger = logging.getLogger(__name__)

class StandardAKShareCollector(BaseDataCollector):
    """æ ‡å‡†AKShareæ•°æ®é‡‡é›†å™¨ï¼ˆä½¿ç”¨æ ‡å‡†åˆ—åï¼‰"""

    def __init__(self, config_path: str = 'config/database.yaml'):
        super().__init__(config_path)
        logger.info("æ ‡å‡†AKShareé‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")

    def fetch_daily_data(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """è·å–æ—¥çº¿æ•°æ®ï¼ˆä½¿ç”¨æ ‡å‡†åˆ—åï¼‰"""
        try:
            # è½¬æ¢symbolæ ¼å¼
            if symbol.endswith('.SH') or symbol.endswith('.SZ'):
                stock_code = symbol[:-3]
            else:
                stock_code = symbol

            logger.info(f"è·å–æ—¥çº¿æ•°æ®: {{symbol}} ({{start_date}} è‡³ {{end_date}})")

            # ä½¿ç”¨AKShareè·å–æ•°æ®
            df = ak.stock_zh_a_hist(
                symbol=stock_code,
                period="daily",
                start_date=start_date.replace("-", ""),
                end_date=end_date.replace("-", ""),
                adjust="qfq"
            )

            if df.empty:
                logger.warning(f"æœªè·å–åˆ°æ•°æ®: {{symbol}}")
                return None

            # æ ‡å‡†åˆ—åæ˜ å°„
            column_mapping = {
                'æ—¥æœŸ': 'trade_date',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¶¨è·Œå¹…': 'pct_change',
                'æ¶¨è·Œé¢': 'change',
                'æ¢æ‰‹ç‡': 'turnover_rate'
            }

            df = df.rename(columns=column_mapping)
            df['symbol'] = symbol

            # æ·»åŠ å…¶ä»–æ ‡å‡†åˆ—ï¼ˆå¦‚æœæ•°æ®ä¸­æœ‰ï¼‰
            if 'æ¢æ‰‹ç‡' in df.columns:
                df['turnover_rate'] = df['æ¢æ‰‹ç‡']

            # è®¡ç®—å‰æ”¶ç›˜ä»·ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
            if 'pre_close' not in df.columns and 'change' in df.columns and 'close' in df.columns:
                df['pre_close'] = df['close'] - df['change']

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            df['trade_date'] = pd.to_datetime(df['trade_date'])

            # é€‰æ‹©æ ‡å‡†åˆ—
            standard_columns = [
                'trade_date', 'symbol', 'open', 'high', 'low', 'close',
                'volume', 'amount', 'pct_change', 'change',
                'pre_close', 'turnover_rate', 'amplitude'
            ]

            # åªä¿ç•™å­˜åœ¨çš„åˆ—
            available_columns = [col for col in standard_columns if col in df.columns]
            df = df[available_columns]

            logger.info(f"æˆåŠŸè·å– {{symbol}} æ—¥çº¿æ•°æ® {{len(df)}} æ¡")
            return df

        except Exception as e:
            logger.error(f"è·å–æ—¥çº¿æ•°æ®å¤±è´¥ {{symbol}}: {{e}}")
            return None

    def fetch_basic_info(self, symbol: str) -> Optional[Dict[str, Any]]:
        """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        try:
            # ç®€å•è¿”å›
            return {
                'symbol': symbol,
                'name': 'å¾…ä»AKShareè·å–',
                'source': 'akshare'
            }
        except Exception as e:
            logger.error(f"è·å–åŸºæœ¬ä¿¡æ¯å¤±è´¥ {{symbol}}: {{e}}")
            return None

    def fetch_minute_data(self, symbol: str, trade_date: str, freq: str = '1min') -> Optional[pd.DataFrame]:
        """è·å–åˆ†é’Ÿçº¿æ•°æ®"""
        return None

if __name__ == "__main__":
    # æµ‹è¯•æ ‡å‡†é‡‡é›†å™¨
    import sys
    sys.path.insert(0, '.')
    collector = StandardAKShareCollector()
    print("æ ‡å‡†AKShareé‡‡é›†å™¨åˆ›å»ºæˆåŠŸ")
'''

    # ä¿å­˜ä¸ºæ ‡å‡†æ¨¡æ¿
    with open('src/data/akshare_collector_standard.py', 'w', encoding='utf-8') as f:
        f.write(standard_template)

    print("âœ… æ ‡å‡†åŒ–é‡‡é›†å™¨æ¨¡æ¿å·²ä¿å­˜åˆ° src/data/akshare_collector_standard.py")

    return True


def update_data_storage_for_standard():
    """æ›´æ–°æ•°æ®å­˜å‚¨ä½¿ç”¨æ ‡å‡†åˆ—å"""
    print("\nğŸ’¾ æ›´æ–°æ•°æ®å­˜å‚¨æ¨¡å—...")

    storage_file = 'src/data/data_storage.py'

    if not os.path.exists(storage_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {storage_file}")
        return False

    with open(storage_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æŸ¥æ‰¾å¹¶ä¿®å¤æ’å…¥SQL
    if 'INSERT INTO stock_daily_data' in content:
        print("ğŸ” å‘ç°æ’å…¥SQLï¼Œæ£€æŸ¥åˆ—å...")

        # å¤‡ä»½
        import shutil
        shutil.copy2(storage_file, storage_file + '.backup')

        # ä¿®å¤åˆ—å
        old_column_patterns = [
            'open_price', 'close_price', 'high_price', 'low_price',
            'change_amount', 'pre_close_price'
        ]

        new_column_names = [
            'open', 'close', 'high', 'low',
            'change', 'pre_close'
        ]

        for old, new in zip(old_column_patterns, new_column_names):
            if old in content:
                content = content.replace(old, new)
                print(f"  âœ… {old} â†’ {new}")

        # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
        with open(storage_file, 'w', encoding='utf-8') as f:
            f.write(content)

        print("âœ… æ•°æ®å­˜å‚¨æ¨¡å—å·²æ›´æ–°")
    else:
        print("âœ… æ•°æ®å­˜å‚¨æ¨¡å—å¯èƒ½å·²ç»ä½¿ç”¨æ ‡å‡†åˆ—å")

    return True


def test_standard_collector():
    """æµ‹è¯•æ ‡å‡†åŒ–é‡‡é›†å™¨"""
    print("\nğŸ§ª æµ‹è¯•æ ‡å‡†åŒ–é‡‡é›†å™¨...")

    try:
        # ä¸´æ—¶å¯¼å…¥æ ‡å‡†é‡‡é›†å™¨
        test_code = '''
import sys
sys.path.insert(0, '.')
import akshare as ak
import pandas as pd

# æµ‹è¯•AKShareæ•°æ®è·å–
symbol = "000001"
df = ak.stock_zh_a_hist(
    symbol=symbol,
    period="daily",
    start_date="20240101",
    end_date="20240110",
    adjust="qfq"
)

print(f"è·å–åˆ° {len(df)} æ¡æ•°æ®")
print("åŸå§‹åˆ—å:", df.columns.tolist())

# æ ‡å‡†åˆ—åæ˜ å°„
column_mapping = {
    'æ—¥æœŸ': 'trade_date',
    'å¼€ç›˜': 'open',
    'æ”¶ç›˜': 'close',
    'æœ€é«˜': 'high',
    'æœ€ä½': 'low',
    'æˆäº¤é‡': 'volume',
    'æˆäº¤é¢': 'amount',
    'æŒ¯å¹…': 'amplitude',
    'æ¶¨è·Œå¹…': 'pct_change',
    'æ¶¨è·Œé¢': 'change',
    'æ¢æ‰‹ç‡': 'turnover_rate'
}

df = df.rename(columns=column_mapping)
print("æ ‡å‡†åˆ—å:", [col for col in column_mapping.values() if col in df.columns])
print("æ•°æ®ç¤ºä¾‹:")
print(df[['trade_date', 'open', 'high', 'low', 'close', 'volume']].head())
'''

        exec(test_code)
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def create_fix_data_script():
    """åˆ›å»ºä¿®å¤ç°æœ‰æ•°æ®çš„è„šæœ¬"""
    print("\nğŸ”„ åˆ›å»ºæ•°æ®ä¿®å¤è„šæœ¬...")

    fix_script = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤ç°æœ‰æ•°æ® - å°†éæ ‡å‡†åˆ—åæ”¹ä¸ºæ ‡å‡†åˆ—å
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.database.connection import engine
from sqlalchemy import text
import pandas as pd

print("ğŸ”§ ä¿®å¤ç°æœ‰æ•°æ®åˆ—å")
print("=" * 60)

def check_current_data():
    """æ£€æŸ¥å½“å‰æ•°æ®"""
    print("ğŸ” æ£€æŸ¥å½“å‰æ•°æ®...")

    try:
        with engine.connect() as conn:
            # 1. æŸ¥çœ‹è¡¨ç»“æ„
            print("ğŸ“‹ stock_daily_dataè¡¨ç»“æ„:")
            result = conn.execute(text("DESCRIBE stock_daily_data"))
            columns = []
            for row in result:
                print(f"  {row[0]:20} {row[1]:20}")
                columns.append(row[0])

            # 2. æ£€æŸ¥åˆ—å
            non_standard_cols = []
            standard_cols = []

            for col in columns:
                if col in ['open_price', 'close_price', 'high_price', 'low_price', 'change_amount', 'pre_close_price']:
                    non_standard_cols.append(col)
                elif col in ['open', 'close', 'high', 'low', 'change', 'pre_close']:
                    standard_cols.append(col)

            print(f"\nğŸ“ éæ ‡å‡†åˆ—å: {non_standard_cols}")
            print(f"ğŸ“ æ ‡å‡†åˆ—å: {standard_cols}")

            # 3. æŸ¥çœ‹æ•°æ®
            if non_standard_cols:
                print(f"\nğŸ“Š æŸ¥çœ‹éæ ‡å‡†åˆ—æ•°æ®ç¤ºä¾‹:")
                query = f"SELECT {', '.join(non_standard_cols[:3])} FROM stock_daily_data LIMIT 3"
                result = conn.execute(text(query))
                for row in result:
                    print(f"  {row}")

            return columns, non_standard_cols

    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return [], []

def fix_column_names():
    """ä¿®å¤åˆ—å"""
    print("\nğŸ”„ ä¿®å¤åˆ—å...")

    rename_operations = [
        ('open_price', 'open'),
        ('high_price', 'high'),
        ('low_price', 'low'),
        ('close_price', 'close'),
        ('pre_close_price', 'pre_close'),
        ('change_amount', 'change'),
        ('created_time', 'created_at'),
        ('updated_time', 'updated_at')
    ]

    try:
        with engine.connect() as conn:
            for old_name, new_name in rename_operations:
                try:
                    # å…ˆæ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
                    check_sql = f"""
                    SELECT COUNT(*) FROM information_schema.COLUMNS 
                    WHERE TABLE_SCHEMA = DATABASE() 
                    AND TABLE_NAME = 'stock_daily_data' 
                    AND COLUMN_NAME = '{old_name}'
                    """
                    result = conn.execute(text(check_sql))
                    exists = result.scalar() > 0

                    if exists:
                        # è·å–åˆ—å®šä¹‰
                        describe_sql = f"DESCRIBE stock_daily_data {old_name}"
                        result = conn.execute(text(f"DESCRIBE stock_daily_data"))
                        col_info = None
                        for row in result:
                            if row[0] == old_name:
                                col_info = row
                                break

                        if col_info:
                            col_type = col_info[1]
                            nullable = 'NOT NULL' if col_info[2] == 'NO' else ''
                            default = f"DEFAULT '{col_info[4]}'" if col_info[4] else ''
                            extra = col_info[5] or ''

                            # æ‰§è¡Œé‡å‘½å
                            alter_sql = f"""
                            ALTER TABLE stock_daily_data 
                            CHANGE COLUMN {old_name} {new_name} {col_type} {nullable} {default} {extra}
                            """

                            conn.execute(text(alter_sql))
                            print(f"  âœ… {old_name} â†’ {new_name}")
                    else:
                        print(f"  âš ï¸  {old_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")

                except Exception as e:
                    print(f"  âŒ é‡å‘½å {old_name} å¤±è´¥: {e}")

            conn.commit()
            print("\nâœ… åˆ—åä¿®å¤å®Œæˆ")

    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")

def test_after_fix():
    """ä¿®å¤åæµ‹è¯•"""
    print("\nğŸ§ª ä¿®å¤åæµ‹è¯•...")

    try:
        # æµ‹è¯•æŸ¥è¯¢
        test_query = """
        SELECT 
            trade_date, symbol, 
            open, high, low, close,
            volume, pct_change
        FROM stock_daily_data
        WHERE symbol = '000001.SZ'
        ORDER BY trade_date DESC
        LIMIT 3
        """

        with engine.connect() as conn:
            result = conn.execute(text(test_query))
            rows = result.fetchall()

            if rows:
                print(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(rows)} æ¡æ•°æ®")
                print("ğŸ“Š æ•°æ®ç¤ºä¾‹:")
                for row in rows:
                    print(f"  {row[0]} | å¼€:{row[2]:.2f} æ”¶:{row[5]:.2f} é‡:{row[6]:,.0f}")
            else:
                print("âš ï¸  æŸ¥è¯¢æˆåŠŸä½†æ— æ•°æ®")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def main():
    print("ç°æœ‰æ•°æ®ä¿®å¤å·¥å…·")
    print("=" * 60)

    # æ£€æŸ¥å½“å‰çŠ¶æ€
    columns, non_standard = check_current_data()

    if non_standard:
        choice = input(f"\nå‘ç° {len(non_standard)} ä¸ªéæ ‡å‡†åˆ—åï¼Œæ˜¯å¦ä¿®å¤ï¼Ÿ(y/n): ")
        if choice.lower() == 'y':
            fix_column_names()
            test_after_fix()
    else:
        print("\nâœ… æ‰€æœ‰åˆ—åå·²ç»æ˜¯æ ‡å‡†åç§°")

    print("\nğŸ‰ ä¿®å¤å®Œæˆ")

if __name__ == "__main__":
    main()
'''

    with open('fix_existing_data.py', 'w', encoding='utf-8') as f:
        f.write(fix_script)

    print("âœ… æ•°æ®ä¿®å¤è„šæœ¬å·²åˆ›å»º: fix_existing_data.py")
    print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print("  python fix_existing_data.py")

    return True


def main():
    """ä¸»å‡½æ•°"""
    print("AKShareé‡‡é›†å™¨æ ‡å‡†åŒ–è§£å†³æ–¹æ¡ˆ")
    print("=" * 60)

    steps = [
        ("ä¿®å¤AKShareé‡‡é›†å™¨åˆ—å", fix_akshare_column_names),
        ("åˆ›å»ºæ ‡å‡†åŒ–é‡‡é›†å™¨æ¨¡æ¿", create_standard_akshare_collector),
        ("æ›´æ–°æ•°æ®å­˜å‚¨æ¨¡å—", update_data_storage_for_standard),
        ("æµ‹è¯•æ ‡å‡†åŒ–é‡‡é›†å™¨", test_standard_collector),
        ("åˆ›å»ºæ•°æ®ä¿®å¤è„šæœ¬", create_fix_data_script),
    ]

    results = []
    for step_name, step_func in steps:
        print(f"\n{'=' * 50}")
        print(f"â–¶ï¸  {step_name}")
        print(f"{'=' * 50}")

        try:
            result = step_func()
            results.append((step_name, result))
        except Exception as e:
            print(f"âŒ {step_name} æ‰§è¡Œå‡ºé”™: {e}")
            results.append((step_name, False))

    print(f"\n{'=' * 60}")
    print("ğŸ“‹ ä¿®å¤å®Œæˆæ±‡æ€»")
    print(f"{'=' * 60}")

    success_count = 0
    for step_name, result in results:
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±è´¥"
        print(f"  {step_name:25}: {status}")
        if result:
            success_count += 1

    print(f"\nğŸ“Š å®Œæˆåº¦: {success_count}/{len(steps)}")

    print("\nğŸ“‹ åç»­æ­¥éª¤:")
    print("  1. è¿è¡Œæ•°æ®ä¿®å¤: python fix_existing_data.py")
    print("  2. æµ‹è¯•æŸ¥è¯¢å¼•æ“: python main.py --action p4_query_test")
    print("  3. æµ‹è¯•æ•°æ®å¯¼å‡º: python main.py --action p4_export_test")


if __name__ == "__main__":
    main()