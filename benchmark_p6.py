# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1\benchmark_p6.py
# File Name: benchmark_p6
# @ Author: mango-gh22
# @ Dateï¼š2025/12/21 23:16
"""
desc 
"""

# File: benchmark_p6.py
# !/usr/bin/env python3
"""
P6é˜¶æ®µä¸‰æ€§èƒ½åŸºå‡†æµ‹è¯•
"""

import sys
import os
import time
import pandas as pd
import numpy as np
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def benchmark_dataframe_optimization():
    """åŸºå‡†æµ‹è¯•ï¼šæ•°æ®æ¡†ä¼˜åŒ–"""
    print("ğŸ“Š æ•°æ®æ¡†ä¼˜åŒ–åŸºå‡†æµ‹è¯•")
    print("-" * 40)

    try:
        from src.performance.performance_manager import PerformanceManager

        pm = PerformanceManager()

        # åˆ›å»ºä¸åŒå¤§å°çš„æµ‹è¯•æ•°æ®æ¡†
        sizes = [1000, 10000, 50000, 100000]

        results = []
        for size in sizes:
            print(f"\næµ‹è¯•æ•°æ®æ¡†å¤§å°: {size:,} è¡Œ")

            # åˆ›å»ºæµ‹è¯•æ•°æ®
            df = pd.DataFrame({
                'int_col': np.random.randint(0, 100, size),
                'float_col': np.random.randn(size),
                'str_col': ['test_' + str(i) for i in range(size)],
                'date_col': pd.date_range('2023-01-01', periods=size),
                'bool_col': np.random.choice([True, False], size)
            })

            # åŸå§‹å†…å­˜
            start_time = time.time()
            original_memory = df.memory_usage(deep=True).sum() / 1024 / 1024
            original_time = time.time() - start_time

            # ä¼˜åŒ–åå†…å­˜
            start_time = time.time()
            optimized_df = pm.optimize_dataframe(df)
            optimized_memory = optimized_df.memory_usage(deep=True).sum() / 1024 / 1024
            optimized_time = time.time() - start_time

            # è®¡ç®—èŠ‚çœ
            memory_saved = original_memory - optimized_memory
            memory_saved_percent = (memory_saved / original_memory * 100) if original_memory > 0 else 0

            print(f"  åŸå§‹å†…å­˜: {original_memory:.2f} MB ({original_time:.3f}s)")
            print(f"  ä¼˜åŒ–å†…å­˜: {optimized_memory:.2f} MB ({optimized_time:.3f}s)")
            print(f"  èŠ‚çœå†…å­˜: {memory_saved:.2f} MB ({memory_saved_percent:.1f}%)")

            results.append({
                'size': size,
                'original_memory_mb': original_memory,
                'optimized_memory_mb': optimized_memory,
                'memory_saved_mb': memory_saved,
                'memory_saved_percent': memory_saved_percent,
                'original_time_s': original_time,
                'optimized_time_s': optimized_time
            })

        pm.stop()

        # è¾“å‡ºæ€»ç»“
        print("\n" + "=" * 40)
        print("æ•°æ®æ¡†ä¼˜åŒ–åŸºå‡†æµ‹è¯•æ€»ç»“:")
        for r in results:
            print(f"  å¤§å° {r['size']:,}: èŠ‚çœ {r['memory_saved_percent']:.1f}% å†…å­˜")

        return results
    except Exception as e:
        print(f"æ•°æ®æ¡†ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return None


def benchmark_parallel_calculation():
    """åŸºå‡†æµ‹è¯•ï¼šå¹¶è¡Œè®¡ç®—"""
    print("\n\nâš¡ å¹¶è¡Œè®¡ç®—åŸºå‡†æµ‹è¯•")
    print("-" * 40)

    try:
        from src.performance.performance_manager import PerformanceManager

        pm = PerformanceManager()

        # æµ‹è¯•å‡½æ•°
        def complex_calculation(chunk):
            time.sleep(0.001)  # æ¨¡æ‹Ÿè®¡ç®—è´Ÿè½½
            return [x * x * x for x in chunk]

        # ä¸åŒæ•°æ®å¤§å°å’Œå·¥ä½œçº¿ç¨‹æ•°
        data_sizes = [1000, 5000, 10000]
        worker_counts = [1, 2, 4, 8]

        results = []
        for size in data_sizes:
            print(f"\næ•°æ®å¤§å°: {size:,}")
            data = list(range(size))

            for workers in worker_counts:
                # é…ç½®å¹¶è¡Œè®¡ç®—å™¨
                pm.parallel_calculator.config['max_workers'] = workers

                # å¹¶è¡Œè®¡ç®—
                start_time = time.time()
                parallel_results = pm.parallel_calculate(
                    complex_calculation, data, batch_size=100
                )
                parallel_time = time.time() - start_time

                # ä¸²è¡Œè®¡ç®—
                start_time = time.time()
                serial_results = complex_calculation(data)
                serial_time = time.time() - start_time

                # éªŒè¯ç»“æœ
                assert parallel_results == serial_results, "ç»“æœä¸ä¸€è‡´"

                # è®¡ç®—åŠ é€Ÿæ¯”
                speedup = serial_time / parallel_time if parallel_time > 0 else 0
                efficiency = speedup / workers if workers > 0 else 0

                print(f"  å·¥ä½œçº¿ç¨‹ {workers}: ä¸²è¡Œ={serial_time:.3f}s, å¹¶è¡Œ={parallel_time:.3f}s, "
                      f"åŠ é€Ÿ={speedup:.2f}x, æ•ˆç‡={efficiency:.1%}")

                results.append({
                    'data_size': size,
                    'workers': workers,
                    'serial_time_s': serial_time,
                    'parallel_time_s': parallel_time,
                    'speedup': speedup,
                    'efficiency': efficiency
                })

        pm.stop()

        # è¾“å‡ºæ€»ç»“
        print("\n" + "=" * 40)
        print("å¹¶è¡Œè®¡ç®—åŸºå‡†æµ‹è¯•æ€»ç»“:")
        for size in data_sizes:
            size_results = [r for r in results if r['data_size'] == size]
            if size_results:
                best = max(size_results, key=lambda x: x['speedup'])
                print(f"  æ•°æ®å¤§å° {size:,}: æœ€ä½³åŠ é€Ÿ {best['speedup']:.2f}x (ä½¿ç”¨ {best['workers']} çº¿ç¨‹)")

        return results
    except Exception as e:
        print(f"å¹¶è¡Œè®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        return None


def benchmark_cache_performance():
    """åŸºå‡†æµ‹è¯•ï¼šç¼“å­˜æ€§èƒ½"""
    print("\n\nğŸ’¾ ç¼“å­˜æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("-" * 40)

    try:
        from src.performance.performance_manager import PerformanceManager

        pm = PerformanceManager()

        # æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡
        operations = 1000
        cache_hits = 0
        cache_misses = 0

        start_time = time.time()

        for i in range(operations):
            key = f"test_key_{i % 100}"  # åªæœ‰100ä¸ªä¸åŒçš„keyï¼Œå¢åŠ ç¼“å­˜å‘½ä¸­æœºä¼š

            # å°è¯•è·å–ç¼“å­˜
            value = pm.get_cache(key)

            if value is None:
                # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ¨¡æ‹Ÿè®¡ç®—å¹¶è®¾ç½®ç¼“å­˜
                cache_misses += 1
                value = {"data": i * i, "timestamp": datetime.now().isoformat()}
                pm.set_cache(key, value, ttl=60)
            else:
                # ç¼“å­˜å‘½ä¸­
                cache_hits += 1

        total_time = time.time() - start_time

        # è®¡ç®—å‘½ä¸­ç‡
        hit_rate = cache_hits / operations if operations > 0 else 0
        avg_time_per_op = total_time / operations * 1000  # æ¯«ç§’

        print(f"  æ€»æ“ä½œæ•°: {operations}")
        print(f"  ç¼“å­˜å‘½ä¸­: {cache_hits}")
        print(f"  ç¼“å­˜æœªå‘½ä¸­: {cache_misses}")
        print(f"  å‘½ä¸­ç‡: {hit_rate:.1%}")
        print(f"  æ€»æ—¶é—´: {total_time:.3f}s")
        print(f"  å¹³å‡æ“ä½œæ—¶é—´: {avg_time_per_op:.3f}ms")

        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = pm.cache_manager.get_cache_stats()
        print(f"  ç¼“å­˜ç»Ÿè®¡: {cache_stats}")

        pm.stop()

        return {
            'operations': operations,
            'hits': cache_hits,
            'misses': cache_misses,
            'hit_rate': hit_rate,
            'total_time_s': total_time,
            'avg_time_ms': avg_time_per_op
        }
    except Exception as e:
        print(f"ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return None


def benchmark_monitoring_overhead():
    """åŸºå‡†æµ‹è¯•ï¼šç›‘æ§å¼€é”€"""
    print("\n\nğŸ‘ï¸ ç›‘æ§å¼€é”€åŸºå‡†æµ‹è¯•")
    print("-" * 40)

    try:
        from src.monitoring.performance_monitor import PerformanceMonitor

        # æ— ç›‘æ§çš„åŸºå‡†æµ‹è¯•
        def test_function():
            total = 0
            for i in range(100000):
                total += i * i
            return total

        print("æ— ç›‘æ§æµ‹è¯•...")
        start_time = time.time()
        for _ in range(100):
            test_function()
        no_monitor_time = time.time() - start_time

        print(f"  æ— ç›‘æ§æ—¶é—´: {no_monitor_time:.3f}s")

        # æœ‰ç›‘æ§çš„åŸºå‡†æµ‹è¯•
        monitor = PerformanceMonitor({
            'enabled': True,
            'interval': 1,
            'history_size': 100
        })

        monitor.start()

        print("æœ‰ç›‘æ§æµ‹è¯•...")
        start_time = time.time()
        for _ in range(100):
            test_function()
        with_monitor_time = time.time() - start_time

        monitor.stop()

        print(f"  æœ‰ç›‘æ§æ—¶é—´: {with_monitor_time:.3f}s")

        # è®¡ç®—å¼€é”€
        overhead = with_monitor_time - no_monitor_time
        overhead_percent = (overhead / no_monitor_time * 100) if no_monitor_time > 0 else 0

        print(f"  ç›‘æ§å¼€é”€: {overhead:.3f}s ({overhead_percent:.2f}%)")

        return {
            'no_monitor_time_s': no_monitor_time,
            'with_monitor_time_s': with_monitor_time,
            'overhead_s': overhead,
            'overhead_percent': overhead_percent
        }
    except Exception as e:
        print(f"ç›‘æ§å¼€é”€æµ‹è¯•å¤±è´¥: {e}")
        return None


def generate_benchmark_report(results_dict):
    """ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("P6é˜¶æ®µä¸‰ - æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    if results_dict.get('dataframe'):
        print("\nğŸ“Š æ•°æ®æ¡†ä¼˜åŒ–æ€§èƒ½:")
        for r in results_dict['dataframe']:
            print(f"  å¤§å° {r['size']:,}: èŠ‚çœ {r['memory_saved_percent']:.1f}% å†…å­˜")

    if results_dict.get('parallel'):
        print("\nâš¡ å¹¶è¡Œè®¡ç®—æ€§èƒ½:")
        # æ‰¾å‡ºæœ€ä½³é…ç½®
        best_speedup = max((r for r in results_dict['parallel']),
                           key=lambda x: x['speedup'], default=None)
        if best_speedup:
            print(f"  æœ€ä½³é…ç½®: {best_speedup['workers']}çº¿ç¨‹, "
                  f"åŠ é€Ÿ {best_speedup['speedup']:.2f}x")

    if results_dict.get('cache'):
        print("\nğŸ’¾ ç¼“å­˜æ€§èƒ½:")
        cache_results = results_dict['cache']
        print(f"  å‘½ä¸­ç‡: {cache_results['hit_rate']:.1%}")
        print(f"  å¹³å‡æ“ä½œæ—¶é—´: {cache_results['avg_time_ms']:.3f}ms")

    if results_dict.get('monitoring'):
        print("\nğŸ‘ï¸ ç›‘æ§å¼€é”€:")
        monitor_results = results_dict['monitoring']
        print(f"  å¼€é”€: {monitor_results['overhead_percent']:.2f}%")

    print("\n" + "=" * 60)
    print("âœ… åŸºå‡†æµ‹è¯•å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ P6é˜¶æ®µä¸‰ - æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)

    results = {}

    # è¿è¡Œå„ä¸ªåŸºå‡†æµ‹è¯•
    try:
        results['dataframe'] = benchmark_dataframe_optimization()
    except Exception as e:
        print(f"æ•°æ®æ¡†ä¼˜åŒ–æµ‹è¯•å¼‚å¸¸: {e}")

    try:
        results['parallel'] = benchmark_parallel_calculation()
    except Exception as e:
        print(f"å¹¶è¡Œè®¡ç®—æµ‹è¯•å¼‚å¸¸: {e}")

    try:
        results['cache'] = benchmark_cache_performance()
    except Exception as e:
        print(f"ç¼“å­˜æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {e}")

    try:
        results['monitoring'] = benchmark_monitoring_overhead()
    except Exception as e:
        print(f"ç›‘æ§å¼€é”€æµ‹è¯•å¼‚å¸¸: {e}")

    # ç”ŸæˆæŠ¥å‘Š
    generate_benchmark_report(results)

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_file = "reports/performance_benchmark.json"
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    import json
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)

    print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    return True


if __name__ == "__main__":
    main()