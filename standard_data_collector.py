# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1\standard_data_collector.py
# File Name: standard_data_collector
# @ Author: mango-gh22
# @ Dateï¼š2025/12/6 19:00
"""
desc æ•°æ®é‡‡é›†å™¨çš„æ ‡å‡†åŒ–ç‰ˆæœ¬
"""
# !/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡å‡†åŒ–æ•°æ®é‡‡é›†å™¨ - ç¡®ä¿ä½¿ç”¨æ ‡å‡†åˆ—å
"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.database.connection import get_session
from sqlalchemy import text
from src.utils.logger import get_logger
import pandas as pd
from datetime import datetime

logger = get_logger(__name__)


class StandardDataCollector:
    """æ ‡å‡†åŒ–æ•°æ®é‡‡é›†å™¨"""

    def __init__(self):
        self.session = get_session()
        self.logger = get_logger(__name__)

        # æ ‡å‡†åˆ—åå®šä¹‰
        self.standard_columns = {
            'trade_date': 'DATE',
            'symbol': 'VARCHAR(20)',
            'open': 'DECIMAL(10,4)',
            'high': 'DECIMAL(10,4)',
            'low': 'DECIMAL(10,4)',
            'close': 'DECIMAL(10,4)',
            'volume': 'BIGINT',
            'amount': 'DECIMAL(20,4)',
            'pct_change': 'DECIMAL(10,4)',
            'change': 'DECIMAL(10,4)',
            'pre_close': 'DECIMAL(10,4)',
            'turnover_rate': 'DECIMAL(10,4)',
            'amplitude': 'DECIMAL(10,4)',
            'created_at': 'TIMESTAMP',
            'updated_at': 'TIMESTAMP'
        }

    def ensure_standard_table(self):
        """ç¡®ä¿å­˜åœ¨æ ‡å‡†åŒ–çš„è¡¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ ‡å‡†åŒ–è¡¨
            result = self.session.execute(text("SHOW TABLES LIKE 'daily_data_standard'"))
            if result.fetchone():
                self.logger.info("æ ‡å‡†åŒ–è¡¨å·²å­˜åœ¨")
                return True

            # åˆ›å»ºæ ‡å‡†åŒ–è¡¨
            self.logger.info("åˆ›å»ºæ ‡å‡†åŒ–è¡¨...")

            columns_sql = []
            for col_name, col_type in self.standard_columns.items():
                if col_name == 'trade_date':
                    columns_sql.append(f"{col_name} {col_type} NOT NULL COMMENT 'äº¤æ˜“æ—¥æœŸ'")
                elif col_name == 'symbol':
                    columns_sql.append(f"{col_name} {col_type} NOT NULL COMMENT 'è‚¡ç¥¨ä»£ç '")
                elif col_name == 'created_at':
                    columns_sql.append(f"{col_name} TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                elif col_name == 'updated_at':
                    columns_sql.append(f"{col_name} TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP")
                else:
                    columns_sql.append(f"{col_name} {col_type} COMMENT ''")

            create_sql = f"""
            CREATE TABLE daily_data_standard (
                id INT AUTO_INCREMENT PRIMARY KEY,
                {', '.join(columns_sql)},
                UNIQUE KEY uk_date_symbol (trade_date, symbol),
                INDEX idx_symbol (symbol),
                INDEX idx_trade_date (trade_date)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='æ ‡å‡†æ—¥çº¿è¡Œæƒ…æ•°æ®è¡¨'
            """

            self.session.execute(text(create_sql))
            self.session.commit()

            self.logger.info("âœ… æ ‡å‡†åŒ–è¡¨åˆ›å»ºæˆåŠŸ")
            return True

        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ ‡å‡†åŒ–è¡¨å¤±è´¥: {e}")
            self.session.rollback()
            return False

    def insert_standard_data(self, data_dict):
        """æ’å…¥æ ‡å‡†åŒ–æ•°æ®"""
        try:
            # ç¡®ä¿è¡¨å­˜åœ¨
            self.ensure_standard_table()

            # å‡†å¤‡æ•°æ®
            trade_date = data_dict.get('trade_date')
            symbol = data_dict.get('symbol')

            if not trade_date or not symbol:
                self.logger.error("ç¼ºå°‘å¿…è¦å­—æ®µ: trade_date æˆ– symbol")
                return False

            # æ„å»ºINSERTè¯­å¥
            columns = []
            values = []
            params = {}

            for col in self.standard_columns.keys():
                if col in ['created_at', 'updated_at']:
                    continue  # æ•°æ®åº“è‡ªåŠ¨å¤„ç†

                if col in data_dict:
                    columns.append(col)
                    values.append(f":{col}")
                    params[col] = data_dict[col]

            if not columns:
                self.logger.error("æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯æ’å…¥")
                return False

            insert_sql = f"""
            INSERT INTO daily_data_standard ({', '.join(columns)})
            VALUES ({', '.join(values)})
            ON DUPLICATE KEY UPDATE
                {', '.join([f"{col}=VALUES({col})" for col in columns if col not in ['trade_date', 'symbol']])}
            """

            self.session.execute(text(insert_sql), params)
            self.session.commit()

            self.logger.info(f"âœ… æ’å…¥æ•°æ®: {symbol} {trade_date}")
            return True

        except Exception as e:
            self.logger.error(f"æ’å…¥æ•°æ®å¤±è´¥: {e}")
            self.session.rollback()
            return False

    def migrate_existing_data(self):
        """è¿ç§»ç°æœ‰æ•°æ®åˆ°æ ‡å‡†åŒ–è¡¨"""
        try:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨éæ ‡å‡†è¡¨
            result = self.session.execute(text("SHOW TABLES LIKE 'stock_daily_data'"))
            if not result.fetchone():
                self.logger.warning("éæ ‡å‡†è¡¨ä¸å­˜åœ¨ï¼Œæ— éœ€è¿ç§»")
                return True

            self.logger.info("å¼€å§‹è¿ç§»ç°æœ‰æ•°æ®åˆ°æ ‡å‡†åŒ–è¡¨...")

            # ç¡®ä¿æ ‡å‡†åŒ–è¡¨å­˜åœ¨
            self.ensure_standard_table()

            # è¿ç§»æ•°æ®
            migrate_sql = """
            INSERT INTO daily_data_standard (
                trade_date, symbol, 
                open, high, low, close,
                volume, amount, 
                pct_change, change, pre_close,
                turnover_rate, amplitude,
                ma5, ma10, ma20, ma30, ma60,
                created_at, updated_at
            )
            SELECT 
                trade_date, symbol,
                CASE 
                    WHEN COLUMN_NAME = 'open_price' THEN open_price
                    WHEN COLUMN_NAME = 'open' THEN open
                    ELSE NULL
                END as open,
                CASE 
                    WHEN COLUMN_NAME = 'high_price' THEN high_price
                    WHEN COLUMN_NAME = 'high' THEN high
                    ELSE NULL
                END as high,
                CASE 
                    WHEN COLUMN_NAME = 'low_price' THEN low_price
                    WHEN COLUMN_NAME = 'low' THEN low
                    ELSE NULL
                END as low,
                CASE 
                    WHEN COLUMN_NAME = 'close_price' THEN close_price
                    WHEN COLUMN_NAME = 'close' THEN close
                    ELSE NULL
                END as close,
                volume, amount,
                pct_change,
                CASE 
                    WHEN COLUMN_NAME = 'change_amount' THEN change_amount
                    WHEN COLUMN_NAME = 'change' THEN change
                    ELSE NULL
                END as change,
                CASE 
                    WHEN COLUMN_NAME = 'pre_close_price' THEN pre_close_price
                    WHEN COLUMN_NAME = 'pre_close' THEN pre_close
                    ELSE NULL
                END as pre_close,
                turnover_rate, amplitude,
                ma5, ma10, ma20, ma30, ma60,
                CASE 
                    WHEN COLUMN_NAME = 'created_time' THEN created_time
                    ELSE CURRENT_TIMESTAMP
                END as created_at,
                CASE 
                    WHEN COLUMN_NAME = 'updated_time' THEN updated_time
                    ELSE CURRENT_TIMESTAMP
                END as updated_at
            FROM stock_daily_data,
            (SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS 
             WHERE TABLE_NAME = 'stock_daily_data' AND TABLE_SCHEMA = DATABASE()) as cols
            ON DUPLICATE KEY UPDATE
                open = VALUES(open),
                high = VALUES(high),
                low = VALUES(low),
                close = VALUES(close),
                updated_at = CURRENT_TIMESTAMP
            """

            result = self.session.execute(text(migrate_sql))
            rows_migrated = result.rowcount

            self.session.commit()

            self.logger.info(f"âœ… è¿ç§»å®Œæˆ: {rows_migrated} è¡Œæ•°æ®")

            # éªŒè¯è¿ç§»ç»“æœ
            result = self.session.execute(text("SELECT COUNT(*) FROM daily_data_standard"))
            count = result.scalar()
            self.logger.info(f"ğŸ“Š æ ‡å‡†åŒ–è¡¨æ•°æ®é‡: {count}")

            return True

        except Exception as e:
            self.logger.error(f"è¿ç§»æ•°æ®å¤±è´¥: {e}")
            self.session.rollback()
            return False

    def close(self):
        """å…³é—­ä¼šè¯"""
        self.session.close()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“¡ æ ‡å‡†åŒ–æ•°æ®é‡‡é›†å™¨")
    print("=" * 60)

    collector = StandardDataCollector()

    try:
        print("1ï¸âƒ£ æ£€æŸ¥æ ‡å‡†åŒ–è¡¨...")
        collector.ensure_standard_table()

        print("\n2ï¸âƒ£ æ£€æŸ¥ç°æœ‰æ•°æ®...")
        result = collector.session.execute(text("SELECT COUNT(*) FROM stock_daily_data"))
        old_count = result.scalar()
        print(f"   éæ ‡å‡†è¡¨æ•°æ®: {old_count} è¡Œ")

        result = collector.session.execute(text("SELECT COUNT(*) FROM daily_data_standard"))
        new_count = result.scalar()
        print(f"   æ ‡å‡†åŒ–è¡¨æ•°æ®: {new_count} è¡Œ")

        if old_count > 0 and new_count == 0:
            choice = input(f"\næ˜¯å¦è¿ç§» {old_count} è¡Œæ•°æ®åˆ°æ ‡å‡†åŒ–è¡¨ï¼Ÿ(y/n): ")
            if choice.lower() == 'y':
                print("\n3ï¸âƒ£ è¿ç§»æ•°æ®...")
                collector.migrate_existing_data()

        print("\nâœ… æ ‡å‡†åŒ–è®¾ç½®å®Œæˆ")

    finally:
        collector.close()


if __name__ == "__main__":
    main()