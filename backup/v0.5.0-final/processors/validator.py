# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/src/processors\validator.py
# File Name: validator
# @ Author: mango-gh22
# @ Dateï¼š2025/12/14 15:35
"""
desc æ•°æ®éªŒè¯æ¨¡å— - å®ç°å®Œæ•´æ€§æ£€æŸ¥ã€ä¸šåŠ¡è§„åˆ™éªŒè¯ã€å¼‚å¸¸æ£€æµ‹
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any, Union
import yaml
import logging
from dataclasses import dataclass
from enum import Enum

# ä¿®æ­£å¯¼å…¥è·¯å¾„ - æ ¹æ®å®é™…é¡¹ç›®ç»“æ„
from src.query.query_engine import QueryEngine
from src.database.db_connector import DatabaseConnector

# å°è¯•å¯¼å…¥å—1çš„pipelineï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å®šä¹‰æ›¿ä»£
try:
    from src.data.data_pipeline import ProcessingPipeline, UpdateMode

    HAS_PIPELINE = True
except ImportError:
    # å®šä¹‰æ›¿ä»£çš„æšä¸¾
    class UpdateMode(Enum):
        """æ›´æ–°æ¨¡å¼æšä¸¾"""
        FAST = "fast"
        STANDARD = "standard"
        FULL = "full"


    class ProcessingPipeline:
        """æ¨¡æ‹Ÿå¤„ç†æµæ°´çº¿"""

        def __init__(self, config_path: str = 'config/processing.yaml'):
            self.config_path = config_path


    HAS_PIPELINE = False

logger = logging.getLogger(__name__)


class ValidationResult(Enum):
    """éªŒè¯ç»“æœæšä¸¾"""
    PASS = "PASS"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


@dataclass
class ValidationRule:
    """éªŒè¯è§„åˆ™æ•°æ®ç±»"""
    name: str
    description: str
    rule_type: str
    severity: str
    condition: Optional[str] = None
    sql: Optional[str] = None
    algorithm: Optional[str] = None
    threshold: Optional[float] = None
    is_active: bool = True


@dataclass
class ValidationResultDetail:
    """éªŒè¯ç»“æœè¯¦æƒ…"""
    rule_name: str
    rule_description: str
    result: ValidationResult
    error_message: Optional[str] = None
    affected_rows: int = 0
    affected_symbols: List[str] = None
    suggestion: Optional[str] = None
    execution_time: float = 0.0

    def __post_init__(self):
        if self.affected_symbols is None:
            self.affected_symbols = []


class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""

    def __init__(self, config_path: str = 'config/quality_rules.yaml',
                 db_config_path: str = 'config/database.yaml'):
        """
        åˆå§‹åŒ–æ•°æ®éªŒè¯å™¨

        Args:
            config_path: è´¨é‡è§„åˆ™é…ç½®æ–‡ä»¶è·¯å¾„
            db_config_path: æ•°æ®åº“é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.db_config_path = db_config_path
        self.rules = self._load_rules()
        self.query_engine = QueryEngine(db_config_path)
        self.db_connector = DatabaseConnector(db_config_path)
        logger.info(f"æ•°æ®éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½ {len(self.rules)} æ¡è§„åˆ™")

    def _load_rules(self) -> Dict[str, List[ValidationRule]]:
        """ä»YAMLæ–‡ä»¶åŠ è½½è´¨é‡è§„åˆ™"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)

            rules = {}
            for rule_type, rule_list in config.get('quality_rules', {}).items():
                rules[rule_type] = []
                for rule_config in rule_list:
                    rule = ValidationRule(
                        name=rule_config.get('name'),
                        description=rule_config.get('description', ''),
                        rule_type=rule_type,
                        severity=rule_config.get('severity', 'WARNING'),
                        condition=rule_config.get('condition'),
                        sql=rule_config.get('sql'),
                        algorithm=rule_config.get('algorithm'),
                        threshold=rule_config.get('threshold'),
                        is_active=True
                    )
                    rules[rule_type].append(rule)

            return rules

        except Exception as e:
            logger.error(f"åŠ è½½è´¨é‡è§„åˆ™å¤±è´¥: {e}")
            return {}

    def validate_completeness(self, symbol: str = None,
                              start_date: str = None,
                              end_date: str = None) -> List[ValidationResultDetail]:
        """
        æ•°æ®å®Œæ•´æ€§éªŒè¯

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            éªŒè¯ç»“æœåˆ—è¡¨
        """
        results = []
        completeness_rules = self.rules.get('completeness', [])

        for rule in completeness_rules:
            if not rule.is_active:
                continue

            start_time = datetime.now()
            try:
                if rule.sql:
                    # æ‰§è¡ŒSQLæ£€æŸ¥
                    query = rule.sql
                    params = []

                    # æ·»åŠ ç¬¦å·å’Œæ—¥æœŸè¿‡æ»¤
                    if symbol:
                        if "WHERE" in query.upper():
                            query += f" AND symbol = %s"
                        else:
                            query += f" WHERE symbol = %s"
                        params.append(symbol)

                    if start_date:
                        if "WHERE" in query.upper():
                            query += f" AND trade_date >= %s"
                        else:
                            query += f" WHERE trade_date >= %s"
                        params.append(start_date)

                    if end_date:
                        if "WHERE" in query.upper():
                            query += f" AND trade_date <= %s"
                        else:
                            query += f" WHERE trade_date <= %s"
                        params.append(end_date)

                    result = self.query_engine.execute_custom_query(query, tuple(params) if params else None)

                    if result.empty:
                        validation_result = ValidationResult.PASS
                        affected_rows = 0
                        affected_symbols = []
                        error_msg = None
                    else:
                        validation_result = getattr(ValidationResult, rule.severity)
                        affected_rows = len(result)
                        affected_symbols = result['symbol'].tolist() if 'symbol' in result.columns else []
                        error_msg = f"å‘ç°{affected_rows}æ¡è¿å{rule.description}çš„è®°å½•"

                execution_time = (datetime.now() - start_time).total_seconds()

                result_detail = ValidationResultDetail(
                    rule_name=rule.name,
                    rule_description=rule.description,
                    result=validation_result,
                    error_message=error_msg,
                    affected_rows=affected_rows,
                    affected_symbols=affected_symbols,
                    suggestion="æ£€æŸ¥æ•°æ®æºå®Œæ•´æ€§æˆ–é‡æ–°å¯¼å…¥æ•°æ®",
                    execution_time=execution_time
                )

                results.append(result_detail)
                self._log_validation_result(result_detail, symbol)

            except Exception as e:
                logger.error(f"æ‰§è¡Œå®Œæ•´æ€§è§„åˆ™{rule.name}å¤±è´¥: {e}")
                result_detail = ValidationResultDetail(
                    rule_name=rule.name,
                    rule_description=rule.description,
                    result=ValidationResult.ERROR,
                    error_message=str(e),
                    execution_time=(datetime.now() - start_time).total_seconds()
                )
                results.append(result_detail)

        return results

    def validate_business_logic(self, symbol: str = None,
                                start_date: str = None,
                                end_date: str = None) -> List[ValidationResultDetail]:
        """
        ä¸šåŠ¡é€»è¾‘éªŒè¯

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            éªŒè¯ç»“æœåˆ—è¡¨
        """
        results = []
        business_rules = self.rules.get('business_logic', [])

        if not business_rules:
            return results

        # æŸ¥è¯¢æ•°æ®
        df = self.query_engine.query_daily_data(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            limit=10000  # é™åˆ¶æ•°é‡é˜²æ­¢å†…å­˜æº¢å‡º
        )

        if df.empty:
            logger.warning("æ²¡æœ‰æ•°æ®å¯ç”¨äºä¸šåŠ¡é€»è¾‘éªŒè¯")
            return results

        for rule in business_rules:
            if not rule.is_active:
                continue

            start_time = datetime.now()
            try:
                if rule.condition:
                    # è§£ææ¡ä»¶å¹¶åº”ç”¨
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ä½¿ç”¨å®‰å…¨çš„è¡¨è¾¾å¼æ±‚å€¼
                    condition = rule.condition

                    # æ›¿æ¢åˆ—å
                    column_mapping = {
                        'open_price': 'open',
                        'close_price': 'close',
                        'high_price': 'high',
                        'low_price': 'low',
                        'volume': 'volume',
                        'pct_change': 'pct_change'
                    }

                    for old_col, new_col in column_mapping.items():
                        condition = condition.replace(old_col, new_col)

                    # æ£€æŸ¥æ•°æ®æ¡†ä¸­æ˜¯å¦å­˜åœ¨è¿™äº›åˆ—
                    try:
                        # ä½¿ç”¨evalè¿›è¡Œæ¡ä»¶åˆ¤æ–­ï¼ˆæ³¨æ„å®‰å…¨æ€§ï¼‰
                        mask = df.eval(condition)
                        violations = df[~mask]

                        if violations.empty:
                            validation_result = ValidationResult.PASS
                            affected_rows = 0
                            affected_symbols = []
                            error_msg = None
                        else:
                            validation_result = getattr(ValidationResult, rule.severity)
                            affected_rows = len(violations)
                            affected_symbols = violations['symbol'].tolist() if 'symbol' in violations.columns else []
                            error_msg = f"å‘ç°{affected_rows}æ¡è¿å{rule.description}çš„è®°å½•"

                    except Exception as e:
                        logger.warning(f"æ¡ä»¶æ±‚å€¼å¤±è´¥ {rule.condition}: {e}")
                        continue

                execution_time = (datetime.now() - start_time).total_seconds()

                result_detail = ValidationResultDetail(
                    rule_name=rule.name,
                    rule_description=rule.description,
                    result=validation_result,
                    error_message=error_msg,
                    affected_rows=affected_rows,
                    affected_symbols=affected_symbols,
                    suggestion="æ£€æŸ¥æ•°æ®æºæˆ–è°ƒæ•´éªŒè¯è§„åˆ™",
                    execution_time=execution_time
                )

                results.append(result_detail)
                self._log_validation_result(result_detail, symbol)

            except Exception as e:
                logger.error(f"æ‰§è¡Œä¸šåŠ¡è§„åˆ™{rule.name}å¤±è´¥: {e}")
                result_detail = ValidationResultDetail(
                    rule_name=rule.name,
                    rule_description=rule.description,
                    result=ValidationResult.ERROR,
                    error_message=str(e),
                    execution_time=(datetime.now() - start_time).total_seconds()
                )
                results.append(result_detail)

        return results

    def detect_statistical_anomalies(self, symbol: str,
                                     start_date: str = None,
                                     end_date: str = None) -> List[ValidationResultDetail]:
        """
        ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            å¼‚å¸¸æ£€æµ‹ç»“æœ
        """
        results = []
        statistical_rules = self.rules.get('statistical', [])

        if not statistical_rules:
            return results

        # æŸ¥è¯¢æ•°æ®
        df = self.query_engine.query_daily_data(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            limit=1000
        )

        if df.empty or len(df) < 10:
            logger.warning(f"æ•°æ®ä¸è¶³è¿›è¡Œç»Ÿè®¡å¼‚å¸¸æ£€æµ‹: {symbol}")
            return results

        for rule in statistical_rules:
            if not rule.is_active:
                continue

            start_time = datetime.now()
            try:
                anomalies = []

                if rule.algorithm == 'z_score' and rule.threshold:
                    # Z-scoreå¼‚å¸¸æ£€æµ‹
                    for column in ['close', 'volume', 'pct_change']:
                        if column in df.columns:
                            z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())
                            anomaly_mask = z_scores > rule.threshold
                            anomalies.extend(df[anomaly_mask][['trade_date', column]].to_dict('records'))

                elif rule.algorithm == 'iqr' and rule.threshold:
                    # IQRå¼‚å¸¸æ£€æµ‹
                    for column in ['close', 'volume', 'pct_change']:
                        if column in df.columns:
                            Q1 = df[column].quantile(0.25)
                            Q3 = df[column].quantile(0.75)
                            IQR = Q3 - Q1
                            lower_bound = Q1 - rule.threshold * IQR
                            upper_bound = Q3 + rule.threshold * IQR
                            anomaly_mask = (df[column] < lower_bound) | (df[column] > upper_bound)
                            anomalies.extend(df[anomaly_mask][['trade_date', column]].to_dict('records'))

                if anomalies:
                    validation_result = getattr(ValidationResult, rule.severity)
                    affected_rows = len(anomalies)
                    error_msg = f"å‘ç°{affected_rows}ä¸ªç»Ÿè®¡å¼‚å¸¸ç‚¹ï¼Œä½¿ç”¨{rule.algorithm}ç®—æ³•"
                else:
                    validation_result = ValidationResult.PASS
                    affected_rows = 0
                    error_msg = None

                execution_time = (datetime.now() - start_time).total_seconds()

                result_detail = ValidationResultDetail(
                    rule_name=rule.name,
                    rule_description=rule.description,
                    result=validation_result,
                    error_message=error_msg,
                    affected_rows=affected_rows,
                    affected_symbols=[symbol],
                    suggestion="æ£€æŸ¥æ˜¯å¦ä¸ºçœŸå®å¼‚å¸¸æˆ–æ•°æ®é”™è¯¯",
                    execution_time=execution_time
                )

                results.append(result_detail)
                self._log_validation_result(result_detail, symbol)

                # ä¿å­˜å¼‚å¸¸åˆ°æ•°æ®åº“
                if anomalies:
                    self._save_anomalies_to_db(anomalies, rule.name, symbol, rule.algorithm)

            except Exception as e:
                logger.error(f"æ‰§è¡Œç»Ÿè®¡è§„åˆ™{rule.name}å¤±è´¥: {e}")
                result_detail = ValidationResultDetail(
                    rule_name=rule.name,
                    rule_description=rule.description,
                    result=ValidationResult.ERROR,
                    error_message=str(e),
                    execution_time=(datetime.now() - start_time).total_seconds()
                )
                results.append(result_detail)

        return results

    def _log_validation_result(self, result: ValidationResultDetail, symbol: str = None):
        """è®°å½•éªŒè¯ç»“æœåˆ°æ•°æ®åº“"""
        try:
            query = """
                INSERT INTO data_quality_log 
                (check_type, symbol, check_date, rule_name, rule_description, 
                 check_result, error_message, affected_rows, severity_level, suggestion)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """

            params = (
                result.rule_description.split('æ£€æŸ¥')[0] if 'æ£€æŸ¥' in result.rule_description else 'general',
                symbol,
                datetime.now().date(),
                result.rule_name,
                result.rule_description,
                result.result.value,
                result.error_message,
                result.affected_rows,
                result.result.value,
                result.suggestion
            )

            self.db_connector.execute_query(query, params)

        except Exception as e:
            logger.error(f"è®°å½•éªŒè¯ç»“æœå¤±è´¥: {e}")

    def _save_anomalies_to_db(self, anomalies: List[dict], anomaly_type: str,
                              symbol: str, algorithm: str):
        """ä¿å­˜å¼‚å¸¸æ£€æµ‹ç»“æœåˆ°æ•°æ®åº“"""
        try:
            for anomaly in anomalies:
                query = """
                    INSERT INTO data_anomalies 
                    (anomaly_type, symbol, trade_date, field_name, 
                     actual_value, algorithm, confidence)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                    actual_value = VALUES(actual_value),
                    algorithm = VALUES(algorithm),
                    confidence = VALUES(confidence)
                """

                # æå–å­—æ®µåå’Œå€¼
                for field, value in anomaly.items():
                    if field != 'trade_date':
                        field_name = field
                        actual_value = value
                        break

                params = (
                    anomaly_type,
                    symbol,
                    anomaly.get('trade_date'),
                    field_name,
                    actual_value,
                    algorithm,
                    0.8  # é»˜è®¤ç½®ä¿¡åº¦
                )

                self.db_connector.execute_query(query, params)

        except Exception as e:
            logger.error(f"ä¿å­˜å¼‚å¸¸ç»“æœå¤±è´¥: {e}")

    def validate_all(self, symbol: str = None,
                     start_date: str = None,
                     end_date: str = None) -> Dict[str, List[ValidationResultDetail]]:
        """
        æ‰§è¡Œæ‰€æœ‰éªŒè¯

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            æŒ‰ç±»å‹ç»„ç»‡çš„éªŒè¯ç»“æœ
        """
        all_results = {}

        logger.info(f"å¼€å§‹å…¨é¢éªŒè¯: symbol={symbol}, date_range={start_date}~{end_date}")

        # 1. å®Œæ•´æ€§éªŒè¯
        completeness_results = self.validate_completeness(symbol, start_date, end_date)
        all_results['completeness'] = completeness_results

        # 2. ä¸šåŠ¡é€»è¾‘éªŒè¯
        business_results = self.validate_business_logic(symbol, start_date, end_date)
        all_results['business_logic'] = business_results

        # 3. ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹
        if symbol:  # ç»Ÿè®¡æ£€æµ‹éœ€è¦å…·ä½“ç¬¦å·
            statistical_results = self.detect_statistical_anomalies(symbol, start_date, end_date)
            all_results['statistical'] = statistical_results

        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        self._generate_summary_report(all_results, symbol)

        return all_results

    def _generate_summary_report(self, results: Dict[str, List[ValidationResultDetail]], symbol: str = None):
        """ç”ŸæˆéªŒè¯æ‘˜è¦æŠ¥å‘Š"""
        total_rules = 0
        passed_rules = 0
        warnings = 0
        errors = 0

        for category, category_results in results.items():
            for result in category_results:
                total_rules += 1
                if result.result == ValidationResult.PASS:
                    passed_rules += 1
                elif result.result == ValidationResult.WARNING:
                    warnings += 1
                elif result.result in [ValidationResult.ERROR, ValidationResult.CRITICAL]:
                    errors += 1

        logger.info(f"éªŒè¯æ‘˜è¦: æ€»æ•°={total_rules}, é€šè¿‡={passed_rules}, "
                    f"è­¦å‘Š={warnings}, é”™è¯¯={errors}")

        if errors > 0:
            logger.error(f"å‘ç°{errors}ä¸ªä¸¥é‡é”™è¯¯ï¼Œéœ€è¦ç«‹å³å¤„ç†ï¼")

        return {
            'total_rules': total_rules,
            'passed_rules': passed_rules,
            'warnings': warnings,
            'errors': errors,
            'pass_rate': passed_rules / total_rules if total_rules > 0 else 0
        }

    def get_validation_summary(self, days: int = 7) -> pd.DataFrame:
        """è·å–æœ€è¿‘éªŒè¯æ‘˜è¦"""
        try:
            query = """
                SELECT 
                    DATE(check_date) as check_date,
                    check_type,
                    check_result,
                    COUNT(*) as count,
                    SUM(affected_rows) as total_affected_rows
                FROM data_quality_log
                WHERE check_date >= DATE_SUB(CURDATE(), INTERVAL %s DAY)
                GROUP BY DATE(check_date), check_type, check_result
                ORDER BY check_date DESC, check_type
            """

            result = self.db_connector.execute_query(query, (days,))
            df = pd.DataFrame(result) if result else pd.DataFrame()

            return df

        except Exception as e:
            logger.error(f"è·å–éªŒè¯æ‘˜è¦å¤±è´¥: {e}")
            return pd.DataFrame()

    def close(self):
        """å…³é—­è¿æ¥"""
        self.db_connector.close_all_connections()
        logger.info("æ•°æ®éªŒè¯å™¨è¿æ¥å·²å…³é—­")


# ä¸å—1 pipelineçš„é›†æˆ
class ValidationPipeline(ProcessingPipeline):
    """éªŒè¯æµæ°´çº¿ - ç»§æ‰¿è‡ªå—1çš„ProcessingPipeline"""

    def __init__(self, config_path: str = 'config/processing.yaml'):
        super().__init__(config_path)
        self.validator = DataValidator()

    def run_validation(self, symbol: str = None, update_mode: UpdateMode = UpdateMode.STANDARD):
        """
        è¿è¡ŒéªŒè¯æµæ°´çº¿

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            update_mode: æ›´æ–°æ¨¡å¼
        """
        logger.info(f"å¯åŠ¨éªŒè¯æµæ°´çº¿: symbol={symbol}, mode={update_mode.value}")

        # ç¡®å®šæ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime('%Y-%m-%d')

        if update_mode == UpdateMode.FAST:
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        elif update_mode == UpdateMode.STANDARD:
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        else:  # FULL
            start_date = None

        # æ‰§è¡ŒéªŒè¯
        results = self.validator.validate_all(symbol, start_date, end_date)

        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_validation_report(results)

        logger.info(f"éªŒè¯æµæ°´çº¿å®Œæˆ: {report}")

        return {
            'success': True,
            'results': results,
            'report': report,
            'symbol': symbol,
            'mode': update_mode.value
        }

    def _generate_validation_report(self, results: Dict[str, List[ValidationResultDetail]]) -> Dict:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        summary = {}
        issues = []

        for category, category_results in results.items():
            summary[category] = {
                'total': len(category_results),
                'passed': sum(1 for r in category_results if r.result == ValidationResult.PASS),
                'warnings': sum(1 for r in category_results if r.result == ValidationResult.WARNING),
                'errors': sum(
                    1 for r in category_results if r.result in [ValidationResult.ERROR, ValidationResult.CRITICAL])
            }

            # æ”¶é›†é—®é¢˜
            for result in category_results:
                if result.result != ValidationResult.PASS:
                    issues.append({
                        'category': category,
                        'rule': result.rule_name,
                        'severity': result.result.value,
                        'description': result.rule_description,
                        'affected_rows': result.affected_rows,
                        'message': result.error_message
                    })

        return {
            'timestamp': datetime.now().isoformat(),
            'summary': summary,
            'issues': issues,
            'has_issues': len(issues) > 0
        }


def test_validator():
    """æµ‹è¯•æ•°æ®éªŒè¯å™¨"""
    import logging

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("ğŸ§ª æµ‹è¯•æ•°æ®éªŒè¯å™¨")
    print("=" * 50)

    validator = DataValidator()

    try:
        # 1. è·å–è‚¡ç¥¨åˆ—è¡¨æµ‹è¯•
        print("\nğŸ“‹ 1. è·å–è‚¡ç¥¨åˆ—è¡¨")
        stock_df = validator.query_engine.get_stock_list()
        if not stock_df.empty:
            test_symbol = stock_df.iloc[0]['symbol']
            print(f"   æµ‹è¯•è‚¡ç¥¨: {test_symbol}")

            # 2. å®Œæ•´æ€§éªŒè¯
            print("\nâœ… 2. å®Œæ•´æ€§éªŒè¯")
            completeness_results = validator.validate_completeness(test_symbol)
            for result in completeness_results:
                print(f"   {result.rule_name}: {result.result.value} ({result.affected_rows}æ¡)")

            # 3. ä¸šåŠ¡é€»è¾‘éªŒè¯
            print("\nğŸ” 3. ä¸šåŠ¡é€»è¾‘éªŒè¯")
            business_results = validator.validate_business_logic(test_symbol)
            for result in business_results:
                print(f"   {result.rule_name}: {result.result.value} ({result.affected_rows}æ¡)")

            # 4. ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹
            print("\nğŸ“Š 4. ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹")
            statistical_results = validator.detect_statistical_anomalies(test_symbol)
            for result in statistical_results:
                print(f"   {result.rule_name}: {result.result.value} ({result.affected_rows}ä¸ªå¼‚å¸¸ç‚¹)")

            # 5. å…¨é¢éªŒè¯
            print("\nğŸš€ 5. å…¨é¢éªŒè¯")
            all_results = validator.validate_all(test_symbol)
            summary = validator._generate_summary_report(all_results, test_symbol)
            print(f"   éªŒè¯æ‘˜è¦: {summary}")

        print("\nğŸ‰ æ•°æ®éªŒè¯å™¨æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    finally:
        validator.close()


if __name__ == "__main__":
    test_validator()