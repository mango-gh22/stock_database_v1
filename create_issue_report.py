# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1\create_issue_report.py
# File Name: create_issue_report
# @ Author: mango-gh22
# @ Dateï¼š2026/1/1 13:33
"""
desc 
"""
# create_issue_report.py
"""
åˆ›å»ºè¯¦ç»†çš„é—®é¢˜è¯Šæ–­æŠ¥å‘Š
"""
import os
import sys
from datetime import datetime


def analyze_data_pipeline():
    """åˆ†æ DataPipeline çš„é—®é¢˜"""
    report = []

    pipeline_path = os.path.join(r"E:\MyFile\stock_database_v1", "src/data/data_pipeline.py")

    if os.path.exists(pipeline_path):
        with open(pipeline_path, 'r', encoding='utf-8') as f:
            content = f.read()

        lines = content.split('\n')

        # æŸ¥æ‰¾ fetch_and_store_daily_data æ–¹æ³•
        in_method = False
        method_lines = []

        for i, line in enumerate(lines):
            if 'def fetch_and_store_daily_data' in line:
                in_method = True
                report.append(f"ğŸ” æ‰¾åˆ°å…³é”®æ–¹æ³•: fetch_and_store_daily_data (ç¬¬{i + 1}è¡Œ)")

            if in_method:
                method_lines.append((i + 1, line))

                # æ£€æŸ¥å¯èƒ½å¯¼è‡´è·³è¿‡çš„ä»£ç 
                if any(keyword in line.lower() for keyword in ['skip', 'continue', 'return', 'if', 'else']):
                    report.append(f"   ç¬¬{i + 1}è¡Œ: {line.strip()}")

                # æ–¹æ³•ç»“æŸï¼ˆä¸‹ä¸€ä¸ªdefæˆ–ç±»ç»“æŸï¼‰
                if i > 0 and 'def ' in line and 'fetch_and_store_daily_data' not in line:
                    break

        # åˆ†æå…³é”®é€»è¾‘
        report.append("\nğŸ”¬ æ–¹æ³•é€»è¾‘åˆ†æ:")

        # æŸ¥æ‰¾æ—¥æœŸæ£€æŸ¥é€»è¾‘
        for i, line in method_lines:
            if 'last_update' in line or 'latest_date' in line:
                report.append(f"   ç¬¬{i}è¡Œ - æ—¥æœŸæ£€æŸ¥: {line.strip()}")

        # æŸ¥æ‰¾å­˜å‚¨è°ƒç”¨
        for i, line in method_lines:
            if 'store_daily_data' in line:
                report.append(f"   ç¬¬{i}è¡Œ - å­˜å‚¨è°ƒç”¨: {line.strip()}")

    return report


def create_full_report():
    """åˆ›å»ºå®Œæ•´æŠ¥å‘Š"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"issue_report_{timestamp}.txt"

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("è‚¡ç¥¨æ•°æ®åº“ç³»ç»Ÿé—®é¢˜è¯Šæ–­æŠ¥å‘Š\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}\n")
        f.write("=" * 60 + "\n\n")

        # åˆ†ææ•°æ®ç®¡é“
        f.write("1. æ•°æ®ç®¡é“åˆ†æ\n")
        f.write("-" * 40 + "\n")
        pipeline_issues = analyze_data_pipeline()
        for issue in pipeline_issues:
            f.write(issue + "\n")

        # ç¯å¢ƒä¿¡æ¯
        f.write("\n2. ç¯å¢ƒä¿¡æ¯\n")
        f.write("-" * 40 + "\n")
        f.write(f"Pythonç‰ˆæœ¬: {sys.version}\n")
        f.write(f"å·¥ä½œç›®å½•: {os.getcwd()}\n")
        f.write(f"é¡¹ç›®è·¯å¾„: E:\\MyFile\\stock_database_v1\n")

        # å…³é”®æ–‡ä»¶çŠ¶æ€
        f.write("\n3. å…³é”®æ–‡ä»¶çŠ¶æ€\n")
        f.write("-" * 40 + "\n")

        key_files = [
            ".env",
            "config/database.yaml",
            "src/data/data_pipeline.py",
            "src/data/data_storage.py",
            "src/data/baostock_collector.py"
        ]

        for file in key_files:
            full_path = os.path.join(r"E:\MyFile\stock_database_v1", file)
            if os.path.exists(full_path):
                size = os.path.getsize(full_path)
                f.write(f"âœ… {file} - å­˜åœ¨ ({size} bytes)\n")
            else:
                f.write(f"âŒ {file} - ä¸å­˜åœ¨\n")

        f.write("\n" + "=" * 60 + "\n")
        f.write("é—®é¢˜æè¿°:\n")
        f.write("æ•°æ®åº“'çº¹ä¸ä¸åŠ¨'ï¼Œæ•°æ®æ— æ³•å†™å…¥ï¼Œä½†æ‰€æœ‰æµ‹è¯•æ˜¾ç¤ºç³»ç»Ÿæ­£å¸¸ã€‚\n")
        f.write("æ€€ç–‘æ˜¯ DataPipeline ä¸­çš„é€»è¾‘æ¡ä»¶é˜»æ­¢äº†æ•°æ®å†™å…¥ã€‚\n")

    print(f"âœ… è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    # ä¹Ÿè¾“å‡ºåˆ°æ§åˆ¶å°
    with open(report_file, 'r', encoding='utf-8') as f:
        print(f.read())


if __name__ == "__main__":
    create_full_report()