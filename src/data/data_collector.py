# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/src/data\data_collector.py
# File Name: data_collector
# @ Author: mango-gh22
# @ Dateï¼š2025/12/5 18:44
"""
desc æ•°æ®é‡‡é›†å™¨æŠ½è±¡åŸºç±»
å®šä¹‰ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºï¼ˆBaostock/Tushare/AKShareç­‰ï¼‰
ç›®å‰åŸºäºbaostockï¼Œç¨³å®šå¯é ï¼Œä½æ•ˆï¼ˆå—å¹³å°å•çº¿ç¨‹æ•°æ®ä¸‹è½½æ‰€é™ï¼‰
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any, Tuple
import pandas as pd
import yaml
import logging
import time
import re

logger = logging.getLogger(__name__)


class BaseDataCollector(ABC):
    """
    æ•°æ®é‡‡é›†å™¨æŠ½è±¡åŸºç±»
    æ‰€æœ‰å…·ä½“é‡‡é›†å™¨ï¼ˆå¦‚ BaostockCollectorï¼‰å¿…é¡»ç»§æ‰¿å¹¶å®ç°æŠ½è±¡æ–¹æ³•
    """

    def __init__(self, config_path: str = 'config/database.yaml'):
        """
        åˆå§‹åŒ–é…ç½®

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.rate_limit_count = 0
        self.rate_limit_time = None
        self._request_stats = {
            'total_requests': 0,
            'successful': 0,
            'failed': 0,
            'start_time': time.time()
        }

    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ {config_path}: {e}")
            return {}

    # ==================== æŠ½è±¡æ–¹æ³•ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰====================

    @abstractmethod
    def fetch_daily_data(self, symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
        """
        è·å–æ—¥çº¿è¡Œæƒ…æ•°æ®
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼Œå¦‚ sh600519ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: ç»“æŸæ—¥æœŸ (YYYYMMDD)
        Returns:
            DataFrame åŒ…å«æ ‡å‡†å­—æ®µï¼ˆè§æ–‡æ¡£ï¼‰
        """
        pass

    @abstractmethod
    def fetch_minute_data(self, symbol: str, trade_date: str, freq: str = '5min') -> Optional[pd.DataFrame]:
        """
        è·å–åˆ†é’Ÿçº§è¡Œæƒ…æ•°æ®
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            trade_date: äº¤æ˜“æ—¥ (YYYYMMDD)
            freq: é¢‘ç‡ ('1min', '5min', '15min', '30min', '60min')
        Returns:
            DataFrame
        """
        pass

    @abstractmethod
    def fetch_basic_info(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        Returns:
            å­—å…¸ï¼ŒåŒ…å« name, list_date, market_type ç­‰
        """
        pass

    @abstractmethod
    def fetch_stock_list(self, market: str = "Aè‚¡") -> pd.DataFrame:
        """
        è·å–è‚¡ç¥¨åˆ—è¡¨
        Args:
            market: å¸‚åœºç±»å‹ï¼ˆ"ä¸Šè¯", "æ·±è¯", "ç§‘åˆ›æ¿", "åˆ›ä¸šæ¿", "åŒ—äº¤æ‰€", "Aè‚¡"ï¼‰
        Returns:
            DataFrame åˆ—ï¼šsymbol, stock_code, name, list_date, market_type, exchange
        """
        pass

    # ==================== å¯é€‰/é»˜è®¤æ–¹æ³•ï¼ˆå­ç±»å¯é‡å†™ï¼‰====================

    def batch_download_daily_data(
            self,
            symbols: List[str],
            start_date: str,
            end_date: str,
            max_workers: int = 1
    ) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡ä¸‹è½½æ—¥çº¿æ•°æ®ï¼ˆé»˜è®¤å•çº¿ç¨‹å®ç°ï¼Œå­ç±»å¯ä¼˜åŒ–ä¸ºå¹¶å‘ï¼‰
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed

        results = {}
        logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(symbols)} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®")
        logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")

        if max_workers > 1 and len(symbols) > 1:
            # å¤šçº¿ç¨‹æ¨¡å¼
            logger.info(f"âš¡ ä½¿ç”¨å¤šçº¿ç¨‹æ¨¡å¼ï¼Œçº¿ç¨‹æ•°: {max_workers}")
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_symbol = {
                    executor.submit(self.fetch_daily_data, symbol, start_date, end_date): symbol
                    for symbol in symbols
                }

                for future in as_completed(future_to_symbol):
                    symbol = future_to_symbol[future]
                    try:
                        df = future.result()
                        if df is not None and not df.empty:
                            results[symbol] = df
                            self._request_stats['successful'] += 1
                        else:
                            logger.warning(f"âš ï¸  {symbol}: è·å–æ•°æ®ä¸ºç©º")
                            self._request_stats['failed'] += 1
                    except Exception as e:
                        logger.error(f"âŒ  {symbol}: ä¸‹è½½å¤±è´¥ - {e}")
                        self._request_stats['failed'] += 1
        else:
            # å•çº¿ç¨‹æ¨¡å¼
            logger.info("ğŸŒ ä½¿ç”¨å•çº¿ç¨‹æ¨¡å¼")
            for symbol in symbols:
                try:
                    self.enforce_rate_limit()  # åº”ç”¨é€Ÿç‡é™åˆ¶
                    df = self.fetch_daily_data(symbol, start_date, end_date)
                    if df is not None and not df.empty:
                        results[symbol] = df
                        self._request_stats['successful'] += 1
                    else:
                        logger.warning(f"âš ï¸  {symbol}: è·å–æ•°æ®ä¸ºç©º")
                        self._request_stats['failed'] += 1
                except Exception as e:
                    logger.error(f"âŒ  {symbol}: ä¸‹è½½å¤±è´¥ - {e}")
                    self._request_stats['failed'] += 1

                self._request_stats['total_requests'] += 1

        logger.info(f"âœ… æ‰¹é‡ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ: {len(results)}/{len(symbols)}")
        return results

    def get_download_stats(self) -> Dict[str, Any]:
        """
        è·å–ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯
        """
        total = self._request_stats['total_requests']
        successful = self._request_stats['successful']
        failed = self._request_stats['failed']

        success_rate = successful / total if total > 0 else 0.0

        return {
            'total_requests': total,
            'successful': successful,
            'failed': failed,
            'success_rate': success_rate,
            'duration_seconds': time.time() - self._request_stats['start_time']
        }

    def logout(self):
        """
        é€€å‡ºç™»å½•/é‡Šæ”¾èµ„æºï¼ˆå¯é€‰ï¼‰
        """
        logger.info("ğŸ‘‹ æ•°æ®é‡‡é›†å™¨é€€å‡º")
        pass

    # ==================== å·¥å…·æ–¹æ³• ====================

    def _format_date_to_standard(self, date_series) -> pd.Series:
        """
        å°†æ—¥æœŸåˆ—ç»Ÿä¸€è½¬ä¸º YYYYMMDD æ ¼å¼ï¼ˆå­—ç¬¦ä¸²ï¼‰
        å­ç±»å¯å¤ç”¨
        """
        return pd.to_datetime(date_series).dt.strftime('%Y%m%d')

    def enforce_rate_limit(self, requests_per_minute: int = 500):
        """
        æ‰§è¡Œé€Ÿç‡é™åˆ¶ï¼Œé˜²æ­¢APIè°ƒç”¨è¿‡äºé¢‘ç¹

        Args:
            requests_per_minute: æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°
        """
        current_time = time.time()

        if self.rate_limit_time is None:
            self.rate_limit_time = current_time
            self.rate_limit_count = 1
            return

        # å¦‚æœè¶…è¿‡1åˆ†é’Ÿï¼Œé‡ç½®è®¡æ•°å™¨
        if current_time - self.rate_limit_time > 60:
            self.rate_limit_time = current_time
            self.rate_limit_count = 1
            return

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if self.rate_limit_count >= requests_per_minute:
            sleep_time = 60 - (current_time - self.rate_limit_time)
            if sleep_time > 0:
                logger.info(f"âš ï¸ è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {sleep_time:.1f} ç§’")
                time.sleep(sleep_time)
                self.rate_limit_time = time.time()
                self.rate_limit_count = 1
        else:
            self.rate_limit_count += 1

    def convert_to_dataframe(self, data: List[Dict], columns: List[str]) -> pd.DataFrame:
        """
        å°†æ•°æ®åˆ—è¡¨è½¬æ¢ä¸ºDataFrame

        Args:
            data: æ•°æ®å­—å…¸åˆ—è¡¨
            columns: éœ€è¦ä¿ç•™çš„åˆ—ååˆ—è¡¨

        Returns:
            DataFrame
        """
        if not data:
            return pd.DataFrame()

        df = pd.DataFrame(data)
        if set(columns).issubset(set(df.columns)):
            return df[columns]
        return df

    def validate_date_format(self, date_str: str) -> bool:
        """
        éªŒè¯æ—¥æœŸæ ¼å¼æ˜¯å¦ä¸ºYYYYMMDD

        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²

        Returns:
            bool: æ˜¯å¦æœ‰æ•ˆ
        """
        pattern = r'^\d{8}$'
        if not re.match(pattern, date_str):
            return False

        try:
            year = int(date_str[0:4])
            month = int(date_str[4:6])
            day = int(date_str[6:8])

            # åŸºæœ¬éªŒè¯
            if not (1900 <= year <= 2100):
                return False
            if not (1 <= month <= 12):
                return False
            if not (1 <= day <= 31):
                return False

            # æ›´ç²¾ç¡®çš„æ—¥æœŸéªŒè¯
            from datetime import datetime
            datetime.strptime(date_str, '%Y%m%d')
            return True
        except:
            return False

    def standardize_symbol(self, symbol: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 600519, sh600519, 000001.SZç­‰ï¼‰

        Returns:
            str: æ ‡å‡†åŒ–æ ¼å¼ï¼ˆå¦‚ sh600519ï¼‰
        """
        # ç§»é™¤ç©ºæ ¼å’Œæ¢è¡Œç¬¦
        symbol = symbol.strip().upper()

        # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if symbol.startswith(('SH', 'SZ', 'BJ')):
            return symbol.lower()

        # å¤„ç†å¸¦åç¼€çš„æ ¼å¼
        if symbol.endswith(('.SH', '.SZ', '.BJ')):
            prefix = symbol[-3:].lower().replace('.', '')
            code = symbol[:-3]
            return f"{prefix}{code}"

        # æ ¹æ®ä»£ç åˆ¤æ–­å¸‚åœº
        if symbol.startswith(('6', '9', '5')):
            return f"sh{symbol}"
        elif symbol.startswith(('0', '3', '2')):
            return f"sz{symbol}"
        elif symbol.startswith(('4', '8')):
            return f"bj{symbol}"
        else:
            logger.warning(f"âš ï¸ æ— æ³•è¯†åˆ«è‚¡ç¥¨ä»£ç æ ¼å¼: {symbol}")
            return symbol


# åœ¨ data_collector.py æœ«å°¾æ·»åŠ 
def get_data_collector(collector_type: str = 'baostock', config_path: str = 'config/database.yaml'):
    """
    è·å–æ•°æ®é‡‡é›†å™¨å®ä¾‹ï¼ˆå·¥å‚å‡½æ•°ï¼‰

    Args:
        collector_type: é‡‡é›†å™¨ç±»å‹ ('baostock', 'tushare', 'akshare')
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        æ•°æ®é‡‡é›†å™¨å®ä¾‹
    """
    if collector_type.lower() == 'baostock':
        from src.data.baostock_collector import BaostockCollector
        return BaostockCollector(config_path)
    elif collector_type.lower() == 'tushare':
        from src.data.tushare_collector import TushareDataCollector
        return TushareDataCollector(config_path)
        # raise NotImplementedError("Tushareé‡‡é›†å™¨æš‚æœªå®ç°")
    elif collector_type.lower() == 'akshare':
        from src.data.akshare_collector import AKShareCollector
        return AKShareCollector(config_path)
        # raise NotImplementedError("AKShareé‡‡é›†å™¨æš‚æœªå®ç°")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é‡‡é›†å™¨ç±»å‹: {collector_type}")


# ä¿®æ”¹ä¹‹å‰çš„ DataCollector åˆ«åï¼Œä½¿å…¶æŒ‡å‘å·¥å‚å‡½æ•°æˆ–åŸºç±»
# ä¿æŒå…¼å®¹æ€§ï¼Œä½†ä¸ç›´æ¥å®ä¾‹åŒ–
DataCollector = BaseDataCollector  # ä»ä½œä¸ºåŸºç±»å¼•ç”¨
