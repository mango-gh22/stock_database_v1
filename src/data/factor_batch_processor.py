# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/src/data\factor_batch_processor.py
# File Name: factor_batch_processor
# @ Author: mango-gh22
# @ Dateï¼š2026/1/3 22:43
"""
desc 
"""

# File Path: E:/MyFile/stock_database_v1/src/data/factor_batch_processor.py
"""
æ‰¹é‡å› å­å¤„ç†å™¨ - é«˜æ•ˆå¤„ç†å¤§é‡è‚¡ç¥¨çš„å› å­æ•°æ®ä¸‹è½½å’Œå­˜å‚¨
æ”¯æŒåˆ†æ‰¹å¤„ç†ã€è¿›åº¦ç›‘æ§ã€é”™è¯¯æ¢å¤
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging
import time
import sys
import os
from tqdm import tqdm
import json
from pathlib import Path

# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
# æ·»åŠ é¡¹ç›®è·¯å¾„
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


from src.data.baostock_pb_factor_downloader import BaostockPBFactorDownloader
from src.data.factor_storage_manager import FactorStorageManager
from src.utils.enhanced_trade_date_manager import EnhancedTradeDateManager
from src.config.logging_config import setup_logging
from src.data.a50_fixer import A50SymbolFixer

logger = setup_logging()


class FactorBatchProcessor:
    """
    æ‰¹é‡å› å­å¤„ç†å™¨ - ä¸“é—¨å¤„ç†å¤§é‡è‚¡ç¥¨çš„å› å­æ•°æ®
    ç‰¹æ€§ï¼š
    1. åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
    2. è¿›åº¦ç›‘æ§å’ŒæŠ¥å‘Š
    3. é”™è¯¯æ¢å¤å’Œé‡è¯•
    4. æ€§èƒ½ç»Ÿè®¡å’Œä¼˜åŒ–
    """

    def __init__(self, config_path: str = 'config/database.yaml'):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.downloader = BaostockPBFactorDownloader()
        self.storage = FactorStorageManager(config_path)
        self.trade_date_manager = EnhancedTradeDateManager()

        # é…ç½®
        self.batch_size = 10  # æ¯æ‰¹å¤„ç†çš„è‚¡ç¥¨æ•°
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = 5  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'start_time': None,
            'end_time': None,
            'total_symbols': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'total_records': 0,
            'total_downloaded': 0,
            'total_stored': 0,
            'retry_count': 0,
            'cache_hits': 0,
            'duration_seconds': 0
        }

        # æŠ¥å‘Šç›®å½•
        self.report_dir = Path('data/reports/factors')
        self.report_dir.mkdir(parents=True, exist_ok=True)

        logger.info("âœ… æ‰¹é‡å› å­å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _extract_symbol_from_item(self, item):
        """
        ä»é…ç½®é¡¹ä¸­æå–è‚¡ç¥¨ä»£ç 

        Args:
            item: é…ç½®é¡¹ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€å­—å…¸æˆ–å…¶ä»–æ ¼å¼ï¼‰

        Returns:
            æ ‡å‡†åŒ–çš„è‚¡ç¥¨ä»£ç 
        """
        if isinstance(item, dict):
            # å­—å…¸æ ¼å¼ï¼š{'name': 'è´µå·èŒ…å°', 'symbol': '600519.SH', 'weight': 10.38}
            if 'symbol' in item:
                symbol = item['symbol']
                return self._normalize_symbol(symbol)
            else:
                raise ValueError(f"å­—å…¸ä¸­ç¼ºå°‘symbolå­—æ®µ: {item}")

        elif isinstance(item, str):
            # å­—ç¬¦ä¸²æ ¼å¼ï¼š"600519.SH" æˆ– "sh600519" æˆ– "600519"
            return self._normalize_symbol(item)

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é…ç½®é¡¹æ ¼å¼: {type(item)}")

    def _normalize_symbol(self, symbol: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼

        Args:
            symbol: åŸå§‹è‚¡ç¥¨ä»£ç 

        Returns:
            æ ‡å‡†åŒ–çš„Baostockæ ¼å¼è‚¡ç¥¨ä»£ç 
        """
        if not symbol:
            raise ValueError("è‚¡ç¥¨ä»£ç ä¸ºç©º")

        symbol = str(symbol).strip().upper()

        # å¦‚æœå·²ç»æ˜¯Baostockæ ¼å¼ï¼ˆsh600519/sz000001ï¼‰ï¼Œç›´æ¥è¿”å›
        if symbol.startswith(('SH', 'SZ')):
            return symbol.lower()  # è½¬æ¢ä¸ºå°å†™

        # å¤„ç†å¸¦äº¤æ˜“æ‰€åç¼€çš„æ ¼å¼ï¼š600519.SH
        if '.' in symbol:
            code, exchange = symbol.split('.')
            if exchange == 'SH':
                return f'sh{code}'
            elif exchange == 'SZ':
                return f'sz{code}'
            else:
                return f'{exchange.lower()}{code}'

        # çº¯æ•°å­—ä»£ç ï¼Œéœ€è¦åˆ¤æ–­å¸‚åœº
        if symbol.isdigit():
            if symbol.startswith('6'):
                return f'sh{symbol}'
            elif symbol.startswith(('0', '3')):
                return f'sz{symbol}'
            else:
                raise ValueError(f"æ— æ³•åˆ¤æ–­è‚¡ç¥¨å¸‚åœº: {symbol}")

        # å…¶ä»–æ ¼å¼ï¼Œç›´æ¥è¿”å›
        return symbol.lower()


    def process_symbol_list(self, symbols: List[str], mode: str = 'incremental',
                            start_date: str = None, end_date: str = None,
                            progress_callback=None) -> Dict[str, Any]:
        """
        å¤„ç†è‚¡ç¥¨åˆ—è¡¨

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            mode: æ›´æ–°æ¨¡å¼ ('incremental', 'full', 'specific')
            start_date: ç‰¹å®šå¼€å§‹æ—¥æœŸ
            end_date: ç‰¹å®šç»“æŸæ—¥æœŸ
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            å¤„ç†ç»“æœæŠ¥å‘Š
        """
        self.stats = {
            'start_time': datetime.now(),
            'end_time': None,
            'total_symbols': len(symbols),
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'total_records': 0,
            'total_downloaded': 0,
            'total_stored': 0,
            'retry_count': 0,
            'cache_hits': 0,
            'duration_seconds': 0
        }

        detailed_results = []
        failed_symbols = []

        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(symbols)} åªè‚¡ç¥¨")
        logger.info(f"âš™ï¸  æ¨¡å¼: {mode}, æ‰¹æ¬¡å¤§å°: {self.batch_size}")

        # åˆ†æ‰¹å¤„ç†
        total_batches = (len(symbols) + self.batch_size - 1) // self.batch_size

        for batch_num in range(total_batches):
            batch_start = batch_num * self.batch_size
            batch_end = min((batch_num + 1) * self.batch_size, len(symbols))
            batch_symbols = symbols[batch_start:batch_end]

            logger.info(f"æ‰¹æ¬¡ {batch_num + 1}/{total_batches}: å¤„ç† {len(batch_symbols)} åªè‚¡ç¥¨")

            # å¤„ç†å½“å‰æ‰¹æ¬¡
            batch_results = self._process_batch(
                batch_symbols, mode, start_date, end_date, batch_num
            )

            # æ”¶é›†ç»“æœ
            for result in batch_results:
                detailed_results.append(result)

                if result['status'] == 'success':
                    self.stats['successful'] += 1
                    self.stats['total_records'] += result.get('records_stored', 0)
                    self.stats['total_downloaded'] += result.get('records_downloaded', 0)
                    self.stats['total_stored'] += result.get('records_stored', 0)
                elif result['status'] == 'skipped':
                    self.stats['skipped'] += 1
                    self.stats['cache_hits'] += 1
                elif result['status'] == 'no_data':
                    self.stats['skipped'] += 1
                elif result['status'] == 'error':
                    self.stats['failed'] += 1
                    failed_symbols.append(result['symbol'])

            # æ›´æ–°è¿›åº¦
            if progress_callback:
                progress = (batch_end / len(symbols)) * 100
                progress_callback(progress, batch_end, len(symbols))

            # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
            if batch_num < total_batches - 1:
                time.sleep(2)

        # å®Œæˆç»Ÿè®¡
        self.stats['end_time'] = datetime.now()
        self.stats['duration_seconds'] = (
                self.stats['end_time'] - self.stats['start_time']
        ).total_seconds()

        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_report(detailed_results)

        # ä¿å­˜æŠ¥å‘Š
        self._save_report(report)

        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
        logger.info(f"   æˆåŠŸ: {self.stats['successful']}, å¤±è´¥: {self.stats['failed']}, è·³è¿‡: {self.stats['skipped']}")
        logger.info(f"   ä¸‹è½½è®°å½•: {self.stats['total_downloaded']}, å­˜å‚¨è®°å½•: {self.stats['total_stored']}")
        logger.info(f"   è€—æ—¶: {self.stats['duration_seconds']:.2f}ç§’")

        return report

    def _process_batch(self, symbols: List[Any], mode: str,
                       start_date: str, end_date: str, batch_num: int) -> List[Dict]:
        """
        å¤„ç†å•ä¸ªæ‰¹æ¬¡
        """
        batch_results = []

        for i, item in enumerate(symbols, 1):
            try:
                # ä½¿ç”¨A50ä¿®å¤å™¨å¤„ç†ç¬¦å·
                try:
                    normalized_symbol = A50SymbolFixer.fix_symbol(item)
                    symbol_info = A50SymbolFixer.extract_symbol_info(item)
                except Exception as e:
                    logger.error(f"ç¬¦å·å¤„ç†å¤±è´¥ {item}: {e}")
                    batch_results.append({
                        'symbol': str(item),
                        'status': 'error',
                        'error': f'ç¬¦å·å¤„ç†å¤±è´¥: {e}',
                        'retry_count': 0
                    })
                    continue

                logger.debug(f"[æ‰¹æ¬¡{batch_num + 1}] å¤„ç† {normalized_symbol} ({i}/{len(symbols)})")

                # å¤„ç†è‚¡ç¥¨
                result = self._process_single_symbol_with_retry(
                    normalized_symbol, mode, start_date, end_date
                )

                # æ·»åŠ ç¬¦å·ä¿¡æ¯
                result['symbol_info'] = symbol_info
                result['original_item'] = str(item)

                batch_results.append(result)

                # å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                if i < len(symbols):
                    time.sleep(1.5)

            except Exception as e:
                logger.error(f"å¤„ç†è‚¡ç¥¨å¤±è´¥ {item}: {e}")
                batch_results.append({
                    'symbol': str(item),
                    'status': 'error',
                    'error': str(e),
                    'retry_count': 0
                })

        return batch_results

    def _process_single_symbol_with_retry(self, symbol: str, mode: str,
                                          start_date: str, end_date: str) -> Dict:
        """
        å¸¦é‡è¯•çš„å¤„ç†å•åªè‚¡ç¥¨

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            mode: æ›´æ–°æ¨¡å¼
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            å¤„ç†ç»“æœ
        """
        last_error = None

        for attempt in range(self.max_retries):
            try:
                result = self._process_single_symbol(symbol, mode, start_date, end_date)

                if result['status'] != 'error':
                    if attempt > 0:
                        self.stats['retry_count'] += 1
                        logger.info(f"  {symbol}: ç¬¬{attempt + 1}æ¬¡é‡è¯•æˆåŠŸ")
                    return result

            except Exception as e:
                last_error = e
                logger.warning(f"  {symbol}: ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}")

                if attempt < self.max_retries - 1:
                    delay = self.retry_delay * (attempt + 1)
                    logger.info(f"  {symbol}: {delay}ç§’åé‡è¯•...")
                    time.sleep(delay)

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        logger.error(f"  {symbol}: æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œæœ€ç»ˆé”™è¯¯: {last_error}")
        return {
            'symbol': symbol,
            'status': 'error',
            'error': str(last_error),
            'retry_count': self.max_retries
        }

    # def _process_single_symbol(self, symbol: str, mode: str,
    #                            start_date: str, end_date: str) -> Dict:
    #     """
    #     å¤„ç†å•åªè‚¡ç¥¨
    #
    #     Args:
    #         symbol: è‚¡ç¥¨ä»£ç 
    #         mode: æ›´æ–°æ¨¡å¼
    #         start_date: å¼€å§‹æ—¥æœŸ
    #         end_date: ç»“æŸæ—¥æœŸ
    #
    #     Returns:
    #         å¤„ç†ç»“æœ
    #     """
    #     result = {
    #         'symbol': symbol,
    #         'mode': mode,
    #         'status': 'pending',
    #         'records_downloaded': 0,
    #         'records_stored': 0,
    #         'error': None,
    #         'execution_time': 0,
    #         'retry_count': 0
    #     }
    #
    #     start_time = time.time()
    #
    #     try:
    #         # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆå¢é‡æ¨¡å¼ï¼‰
    #         if mode == 'incremental':
    #             start_date, end_date = self.storage.calculate_incremental_range(symbol)
    #             if not start_date or not end_date:
    #                 result['status'] = 'skipped'
    #                 result['reason'] = 'æ•°æ®å·²æœ€æ–°'
    #                 result['execution_time'] = time.time() - start_time
    #                 return result
    #
    #         # 2. è°ƒæ•´æ—¥æœŸèŒƒå›´
    #         if start_date and end_date:
    #             start_date, end_date = self._adjust_date_range(start_date, end_date)
    #             logger.debug(f"  {symbol}: ä¸‹è½½èŒƒå›´ {start_date} - {end_date}")
    #
    #         # 3. ä¸‹è½½æ•°æ®
    #         logger.debug(f"  {symbol}: å¼€å§‹ä¸‹è½½")
    #         factor_data = self.downloader.fetch_factor_data(symbol, start_date, end_date)
    #
    #         if factor_data.empty:
    #             result['status'] = 'no_data'
    #             result['reason'] = 'æ— æ•°æ®'
    #             result['execution_time'] = time.time() - start_time
    #             return result
    #
    #         result['records_downloaded'] = len(factor_data)
    #         logger.debug(f"  {symbol}: ä¸‹è½½ {len(factor_data)} æ¡è®°å½•")
    #
    #         # 4. å­˜å‚¨æ•°æ®
    #         logger.debug(f"  {symbol}: å¼€å§‹å­˜å‚¨")
    #         affected_rows, storage_report = self.storage.store_factor_data(factor_data)
    #
    #         result['records_stored'] = affected_rows
    #         result['storage_report'] = storage_report
    #
    #         if affected_rows > 0:
    #             result['status'] = 'success'
    #             logger.debug(f"  {symbol}: å­˜å‚¨ {affected_rows} æ¡è®°å½•")
    #         else:
    #             result['status'] = 'skipped'
    #             result['reason'] = 'æ•°æ®å·²å­˜åœ¨'
    #             logger.debug(f"  {symbol}: æ— æ–°è®°å½•")
    #
    #         # 5. æ¸…ç†ç¼“å­˜
    #         self.storage.clear_cache(symbol)
    #
    #     except Exception as e:
    #         result['status'] = 'error'
    #         result['error'] = str(e)
    #         logger.error(f"  {symbol}: å¤„ç†å¤±è´¥: {e}")
    #
    #     finally:
    #         result['execution_time'] = time.time() - start_time
    #
    #     return result

    # åœ¨_factor_batch_processor.pyä¸­ä¿®æ”¹_process_single_symbolæ–¹æ³•ï¼š

    def _process_single_symbol(self, symbol: str, mode: str,
                               start_date: str, end_date: str) -> Dict:
        """
        ä¿®å¤çš„å•åªè‚¡ç¥¨å¤„ç† - ä¿®å¤æ—¥æœŸèŒƒå›´é—®é¢˜
        """
        result = {
            'symbol': symbol,
            'mode': mode,
            'status': 'pending',
            'records_downloaded': 0,
            'records_stored': 0,
            'error': None,
            'execution_time': 0,
            'retry_count': 0
        }

        start_time = time.time()

        try:
            # ä¿®å¤ï¼šç¡®ä¿åœ¨fullæ¨¡å¼ä¸‹æœ‰æ­£ç¡®çš„æ—¥æœŸèŒƒå›´
            if mode == 'full':
                # å¦‚æœæ²¡æœ‰æä¾›æ—¥æœŸï¼Œä½¿ç”¨é»˜è®¤èŒƒå›´
                if not start_date:
                    start_date = '20050101'  # ä»2005å¹´å¼€å§‹
                if not end_date:
                    end_date = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')  # åˆ°æ˜¨å¤©

            # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆå¢é‡æ¨¡å¼ï¼‰
            if mode == 'incremental':
                start_date, end_date = self.storage.calculate_incremental_range(symbol)
                if not start_date or not end_date:
                    result['status'] = 'skipped'
                    result['reason'] = 'æ•°æ®å·²æœ€æ–°'
                    result['execution_time'] = time.time() - start_time
                    return result

            # 2. è°ƒæ•´æ—¥æœŸèŒƒå›´
            if start_date and end_date:
                start_date, end_date = self._adjust_date_range(start_date, end_date)
                logger.info(f"  {symbol}: ä¸‹è½½èŒƒå›´ {start_date} - {end_date}")  # æ”¹ä¸ºinfoçº§åˆ«

            # 3. ä¸‹è½½æ•°æ®
            logger.info(f"  {symbol}: å¼€å§‹ä¸‹è½½")  # æ”¹ä¸ºinfoçº§åˆ«
            factor_data = self.downloader.fetch_factor_data(symbol, start_date, end_date)

            if factor_data.empty:
                result['status'] = 'no_data'
                result['reason'] = 'æ— æ•°æ®'
                result['execution_time'] = time.time() - start_time
                logger.warning(f"  {symbol}: æ— æ•°æ®")  # æ”¹ä¸ºwarningçº§åˆ«
                return result

            result['records_downloaded'] = len(factor_data)
            logger.info(f"  {symbol}: ä¸‹è½½ {len(factor_data)} æ¡è®°å½•")

            # 4. å­˜å‚¨æ•°æ®
            logger.debug(f"  {symbol}: å¼€å§‹å­˜å‚¨")
            affected_rows, storage_report = self.storage.store_factor_data(factor_data)

            result['records_stored'] = affected_rows
            result['storage_report'] = storage_report

            if affected_rows > 0:
                result['status'] = 'success'
                logger.info(f"  {symbol}: å­˜å‚¨ {affected_rows} æ¡è®°å½•")
            else:
                result['status'] = 'skipped'
                result['reason'] = 'æ•°æ®å·²å­˜åœ¨'
                logger.info(f"  {symbol}: æ— æ–°è®°å½•")

            # 5. æ¸…ç†ç¼“å­˜
            self.storage.clear_cache(symbol)

        except Exception as e:
            result['status'] = 'error'
            result['error'] = str(e)
            logger.error(f"  {symbol}: å¤„ç†å¤±è´¥: {e}")

        finally:
            result['execution_time'] = time.time() - start_time

        return result


    def _adjust_date_range(self, start_date: str, end_date: str) -> Tuple[str, str]:
        """
        è°ƒæ•´æ—¥æœŸèŒƒå›´ä¸ºäº¤æ˜“æ—¥
        """
        try:
            # è°ƒæ•´å¼€å§‹æ—¥æœŸ
            if hasattr(self.trade_date_manager, 'adjust_to_trade_date'):
                adjusted_start = self.trade_date_manager.adjust_to_trade_date(start_date, 'backward')
                if adjusted_start != start_date:
                    start_date = adjusted_start

            # è°ƒæ•´ç»“æŸæ—¥æœŸ
            if hasattr(self.trade_date_manager, 'adjust_to_trade_date'):
                adjusted_end = self.trade_date_manager.adjust_to_trade_date(end_date, 'backward')
                if adjusted_end != end_date:
                    end_date = adjusted_end

            return start_date, end_date

        except Exception as e:
            logger.warning(f"æ—¥æœŸèŒƒå›´è°ƒæ•´å¤±è´¥: {e}")
            return start_date, end_date

    def _generate_report(self, detailed_results: List[Dict]) -> Dict[str, Any]:
        """
        ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        """
        # è®¡ç®—æˆåŠŸç‡
        success_rate = (self.stats['successful'] / self.stats['total_symbols'] * 100
                        if self.stats['total_symbols'] > 0 else 0)

        # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
        avg_execution_time = np.mean([
            r.get('execution_time', 0) for r in detailed_results
            if r.get('execution_time', 0) > 0
        ]) if detailed_results else 0

        report = {
            'batch_id': f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'summary': {
                'total_symbols': self.stats['total_symbols'],
                'successful': self.stats['successful'],
                'failed': self.stats['failed'],
                'skipped': self.stats['skipped'],
                'success_rate': round(success_rate, 2),
                'total_records': self.stats['total_records'],
                'total_downloaded': self.stats['total_downloaded'],
                'total_stored': self.stats['total_stored'],
                'cache_hits': self.stats['cache_hits'],
                'retry_count': self.stats['retry_count']
            },
            'performance': {
                'start_time': self.stats['start_time'].isoformat(),
                'end_time': self.stats['end_time'].isoformat(),
                'duration_seconds': round(self.stats['duration_seconds'], 2),
                'avg_execution_time_per_symbol': round(avg_execution_time, 2),
                'symbols_per_second': round(self.stats['total_symbols'] / self.stats['duration_seconds'], 3)
                if self.stats['duration_seconds'] > 0 else 0,
                'records_per_second': round(self.stats['total_records'] / self.stats['duration_seconds'], 2)
                if self.stats['duration_seconds'] > 0 else 0
            },
            'configuration': {
                'batch_size': self.batch_size,
                'max_retries': self.max_retries,
                'retry_delay': self.retry_delay
            },
            'detailed_results': detailed_results,
            'failed_symbols': [
                r['symbol'] for r in detailed_results if r['status'] == 'error'
            ],
            'successful_symbols': [
                r['symbol'] for r in detailed_results if r['status'] == 'success'
            ]
        }

        return report

    def _save_report(self, report: Dict):
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        """
        try:
            report_file = self.report_dir / f"{report['batch_id']}.json"

            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)

            logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

            # åŒæ—¶ä¿å­˜ç®€ç‰ˆæ–‡æœ¬æŠ¥å‘Š
            self._save_text_report(report, report_file.with_suffix('.txt'))

        except Exception as e:
            logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

    def _save_text_report(self, report: Dict, filepath: Path):
        """
        ä¿å­˜æ–‡æœ¬æ ¼å¼æŠ¥å‘Š
        """
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("ğŸ“Š PBå› å­æ‰¹é‡å¤„ç†æŠ¥å‘Š\n")
                f.write("=" * 60 + "\n\n")

                # æ±‡æ€»ä¿¡æ¯
                summary = report['summary']
                f.write("æ±‡æ€»ç»Ÿè®¡:\n")
                f.write("-" * 40 + "\n")
                f.write(f"æ€»è‚¡ç¥¨æ•°: {summary['total_symbols']}\n")
                f.write(f"æˆåŠŸ: {summary['successful']}\n")
                f.write(f"å¤±è´¥: {summary['failed']}\n")
                f.write(f"è·³è¿‡: {summary['skipped']}\n")
                f.write(f"æˆåŠŸç‡: {summary['success_rate']}%\n")
                f.write(f"æ€»è®°å½•æ•°: {summary['total_records']:,}\n")
                f.write(f"ä¸‹è½½è®°å½•: {summary['total_downloaded']:,}\n")
                f.write(f"å­˜å‚¨è®°å½•: {summary['total_stored']:,}\n")
                f.write(f"ç¼“å­˜å‘½ä¸­: {summary['cache_hits']}\n")
                f.write(f"é‡è¯•æ¬¡æ•°: {summary['retry_count']}\n\n")

                # æ€§èƒ½ä¿¡æ¯
                perf = report['performance']
                f.write("æ€§èƒ½ç»Ÿè®¡:\n")
                f.write("-" * 40 + "\n")
                f.write(f"å¼€å§‹æ—¶é—´: {perf['start_time']}\n")
                f.write(f"ç»“æŸæ—¶é—´: {perf['end_time']}\n")
                f.write(f"æ€»è€—æ—¶: {perf['duration_seconds']}ç§’\n")
                f.write(f"å¹³å‡å¤„ç†æ—¶é—´: {perf['avg_execution_time_per_symbol']}ç§’/åª\n")
                f.write(f"å¤„ç†é€Ÿåº¦: {perf['symbols_per_second']}åª/ç§’\n")
                f.write(f"è®°å½•é€Ÿåº¦: {perf['records_per_second']}æ¡/ç§’\n\n")

                # å¤±è´¥è‚¡ç¥¨åˆ—è¡¨
                failed_symbols = report.get('failed_symbols', [])
                if failed_symbols:
                    f.write("å¤±è´¥è‚¡ç¥¨åˆ—è¡¨:\n")
                    f.write("-" * 40 + "\n")
                    for symbol in failed_symbols[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ª
                        f.write(f"  {symbol}\n")
                    if len(failed_symbols) > 20:
                        f.write(f"  è¿˜æœ‰ {len(failed_symbols) - 20} åª...\n")
                    f.write("\n")

                # æˆåŠŸè‚¡ç¥¨ç¤ºä¾‹
                successful_symbols = report.get('successful_symbols', [])
                if successful_symbols:
                    f.write("æˆåŠŸè‚¡ç¥¨ç¤ºä¾‹ (å‰10åª):\n")
                    f.write("-" * 40 + "\n")
                    for symbol in successful_symbols[:10]:
                        # æ‰¾åˆ°è¯¥è‚¡ç¥¨çš„è¯¦ç»†ç»“æœ
                        for detail in report['detailed_results']:
                            if detail.get('symbol') == symbol and detail.get('status') == 'success':
                                records = detail.get('records_stored', 0)
                                f.write(f"  {symbol}: {records} æ¡è®°å½•\n")
                                break
                    f.write("\n")

                f.write("=" * 60 + "\n")
                f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 60 + "\n")

            logger.debug(f"æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {filepath}")

        except Exception as e:
            logger.warning(f"ä¿å­˜æ–‡æœ¬æŠ¥å‘Šå¤±è´¥: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'start_time': None,
            'end_time': None,
            'total_symbols': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'total_records': 0,
            'total_downloaded': 0,
            'total_stored': 0,
            'retry_count': 0,
            'cache_hits': 0,
            'duration_seconds': 0
        }

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.downloader.logout()
            logger.info("æ‰¹é‡å¤„ç†å™¨æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"æ¸…ç†èµ„æºå¼‚å¸¸: {e}")


# åœ¨_factor_batch_processor.pyä¸­æ·»åŠ ä»¥ä¸‹ä¿®å¤

class FixedFactorBatchProcessor(FactorBatchProcessor):
    """ä¿®å¤çš„æ‰¹é‡å¤„ç†å™¨ - æ”¯æŒå¼ºåˆ¶ä¸‹è½½"""

    def __init__(self, config_path: str = 'config/database.yaml', force_download: bool = False):
        """
        åˆå§‹åŒ–ï¼Œæ·»åŠ force_downloadå‚æ•°

        Args:
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼ˆå¿½ç•¥æœ€åæ›´æ–°æ£€æŸ¥ï¼‰
        """
        super().__init__(config_path)
        self.force_download = force_download
        logger.info(f"æ‰¹é‡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œå¼ºåˆ¶ä¸‹è½½æ¨¡å¼: {force_download}")

    def _process_single_symbol(self, symbol: str, mode: str,
                               start_date: str, end_date: str) -> Dict:
        """
        ä¿®å¤çš„å•åªè‚¡ç¥¨å¤„ç† - æ”¯æŒå¼ºåˆ¶ä¸‹è½½
        """
        result = {
            'symbol': symbol,
            'mode': mode,
            'status': 'pending',
            'records_downloaded': 0,
            'records_stored': 0,
            'error': None,
            'execution_time': 0,
            'retry_count': 0
        }

        start_time = time.time()

        try:
            # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆå¢é‡æ¨¡å¼ï¼‰- ä¿®å¤é€»è¾‘
            if mode == 'incremental' and not self.force_download:
                # ä½¿ç”¨æ”¹è¿›çš„å¢é‡èŒƒå›´è®¡ç®—
                start_date, end_date = self.storage.calculate_improved_incremental_range(symbol)
                if not start_date or not end_date:
                    # å³ä½¿æ•°æ®å·²æœ€æ–°ï¼Œä¹Ÿæ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                    if self._should_force_refresh(symbol):
                        logger.info(f"  {symbol}: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥ï¼Œå¼ºåˆ¶åˆ·æ–°")
                        start_date = '20050101'  # ä»2005å¹´å¼€å§‹
                        end_date = datetime.now().strftime('%Y%m%d')
                    else:
                        result['status'] = 'skipped'
                        result['reason'] = 'æ•°æ®å·²æœ€æ–°'
                        result['execution_time'] = time.time() - start_time
                        logger.info(f"  {symbol}: æ•°æ®å·²æœ€æ–°ï¼Œè·³è¿‡")
                        return result

            # 2. å¦‚æœæ˜¯å¼ºåˆ¶ä¸‹è½½æˆ–å…¨é‡æ¨¡å¼
            elif mode == 'full' or self.force_download:
                start_date = start_date or '20050101'
                end_date = end_date or datetime.now().strftime('%Y%m%d')
                logger.info(f"  {symbol}: å¼ºåˆ¶ä¸‹è½½æ¨¡å¼ï¼ŒèŒƒå›´ {start_date} - {end_date}")

            # 3. è°ƒæ•´æ—¥æœŸèŒƒå›´
            if start_date and end_date:
                start_date, end_date = self._adjust_date_range(start_date, end_date)
                logger.debug(f"  {symbol}: ä¸‹è½½èŒƒå›´ {start_date} - {end_date}")

            # 4. ä¸‹è½½æ•°æ®
            logger.debug(f"  {symbol}: å¼€å§‹ä¸‹è½½")
            factor_data = self.downloader.fetch_factor_data(symbol, start_date, end_date)

            if factor_data.empty:
                result['status'] = 'no_data'
                result['reason'] = 'æ— æ•°æ®'
                result['execution_time'] = time.time() - start_time
                logger.warning(f"  {symbol}: æ— æ•°æ®")
                return result

            result['records_downloaded'] = len(factor_data)
            logger.info(f"  {symbol}: ä¸‹è½½ {len(factor_data)} æ¡è®°å½•")

            # 5. å­˜å‚¨æ•°æ®
            logger.debug(f"  {symbol}: å¼€å§‹å­˜å‚¨")
            affected_rows, storage_report = self.storage.store_factor_data(factor_data)

            result['records_stored'] = affected_rows
            result['storage_report'] = storage_report

            if affected_rows > 0:
                result['status'] = 'success'
                logger.info(f"  {symbol}: å­˜å‚¨ {affected_rows} æ¡è®°å½•")
            else:
                # æ£€æŸ¥ä¸ºä»€ä¹ˆæ²¡æœ‰æ–°è®°å½•
                existing_count = self._check_existing_data(symbol)
                if existing_count > 0:
                    result['status'] = 'skipped'
                    result['reason'] = 'æ•°æ®å·²å­˜åœ¨'
                    logger.info(f"  {symbol}: æ— æ–°è®°å½•ï¼ˆæ•°æ®åº“ä¸­å·²æœ‰ {existing_count} æ¡ï¼‰")
                else:
                    result['status'] = 'error'
                    result['error'] = 'ä¸‹è½½æˆåŠŸä½†å­˜å‚¨å¤±è´¥'
                    logger.error(f"  {symbol}: ä¸‹è½½æˆåŠŸä½†å­˜å‚¨0æ¡è®°å½•")

            # 6. æ¸…ç†ç¼“å­˜
            self.storage.clear_cache(symbol)

        except Exception as e:
            result['status'] = 'error'
            result['error'] = str(e)
            logger.error(f"  {symbol}: å¤„ç†å¤±è´¥: {e}")

        finally:
            result['execution_time'] = time.time() - start_time

        return result

    def _should_force_refresh(self, symbol: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶åˆ·æ–°æ•°æ®

        Returns:
            True: éœ€è¦å¼ºåˆ¶åˆ·æ–°
            False: æ•°æ®å®Œæ•´ï¼Œæ— éœ€åˆ·æ–°
        """
        try:
            # 1. æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰æ•°æ®
            data_exists = self._check_data_exists(symbol)
            if not data_exists:
                logger.info(f"  {symbol}: æ•°æ®åº“ä¸­æ— æ•°æ®ï¼Œéœ€è¦ä¸‹è½½")
                return True

            # 2. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ˆæ˜¯å¦æœ‰PBã€PEç­‰å…³é”®å› å­ï¼‰
            factor_complete = self._check_factor_completeness(symbol)
            if not factor_complete:
                logger.warning(f"  {symbol}: å› å­æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦åˆ·æ–°")
                return True

            # 3. æ£€æŸ¥æœ€åæ›´æ–°æ—¥æœŸæ˜¯å¦å¤ªæ—§
            last_date = self.storage.get_last_factor_date(symbol)
            if last_date:
                last_dt = datetime.strptime(str(last_date), '%Y-%m-%d')
                today = datetime.now().date()
                days_diff = (today - last_dt.date()).days

                # å¦‚æœè¶…è¿‡7å¤©æ²¡æœ‰æ›´æ–°ï¼Œå¼ºåˆ¶åˆ·æ–°
                if days_diff > 7:
                    logger.info(f"  {symbol}: æœ€åæ›´æ–°äº {last_date}ï¼Œå·²è¶…è¿‡{days_diff}å¤©ï¼Œéœ€è¦åˆ·æ–°")
                    return True

            return False

        except Exception as e:
            logger.warning(f"æ£€æŸ¥å¼ºåˆ¶åˆ·æ–°æ¡ä»¶å¤±è´¥ {symbol}: {e}")
            return True  # æ£€æŸ¥å¤±è´¥æ—¶é»˜è®¤å¼ºåˆ¶åˆ·æ–°

    def _check_data_exists(self, symbol: str) -> bool:
        """æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰è¯¥è‚¡ç¥¨çš„æ•°æ®"""
        try:
            with self.storage.db_connector.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(
                        "SELECT COUNT(*) FROM stock_daily_data WHERE symbol = %s",
                        (symbol.replace('.', ''),)
                    )
                    count = cursor.fetchone()[0]
                    return count > 0
        except Exception as e:
            logger.warning(f"æ£€æŸ¥æ•°æ®å­˜åœ¨å¤±è´¥ {symbol}: {e}")
            return False

    def _check_factor_completeness(self, symbol: str) -> bool:
        """æ£€æŸ¥å› å­æ•°æ®æ˜¯å¦å®Œæ•´ï¼ˆæ˜¯å¦æœ‰PBã€PEç­‰å…³é”®å› å­ï¼‰"""
        try:
            with self.storage.db_connector.get_connection() as conn:
                with conn.cursor() as cursor:
                    # æ£€æŸ¥æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥æ˜¯å¦æœ‰PBã€PEæ•°æ®
                    cursor.execute("""
                        SELECT 
                            SUM(CASE WHEN pb IS NOT NULL THEN 1 ELSE 0 END) as pb_count,
                            SUM(CASE WHEN pe_ttm IS NOT NULL THEN 1 ELSE 0 END) as pe_count
                        FROM stock_daily_data 
                        WHERE symbol = %s 
                        AND trade_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)
                        LIMIT 10
                    """, (symbol.replace('.', ''),))

                    result = cursor.fetchone()
                    if result:
                        pb_count, pe_count = result
                        # å¦‚æœæœ€è¿‘10æ¡è®°å½•éƒ½æ²¡æœ‰PBæˆ–PEæ•°æ®ï¼Œè¯´æ˜ä¸å®Œæ•´
                        if pb_count == 0 or pe_count == 0:
                            return False

                    return True
        except Exception as e:
            logger.warning(f"æ£€æŸ¥å› å­å®Œæ•´æ€§å¤±è´¥ {symbol}: {e}")
            return False

    def _check_existing_data(self, symbol: str) -> int:
        """æ£€æŸ¥æ•°æ®åº“ä¸­å·²æœ‰æ•°æ®æ•°é‡"""
        try:
            clean_symbol = symbol.replace('.', '')
            with self.storage.db_connector.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(
                        "SELECT COUNT(*) FROM stock_daily_data WHERE symbol = %s",
                        (clean_symbol,)
                    )
                    return cursor.fetchone()[0]
        except Exception as e:
            logger.warning(f"æ£€æŸ¥ç°æœ‰æ•°æ®å¤±è´¥ {symbol}: {e}")
            return 0


# æµ‹è¯•å‡½æ•°
def test_batch_processor():
    """æµ‹è¯•æ‰¹é‡å¤„ç†å™¨"""
    print("\nğŸ§ª æµ‹è¯•æ‰¹é‡å› å­å¤„ç†å™¨")
    print("=" * 50)

    try:
        # åˆå§‹åŒ–
        print("åˆå§‹åŒ–FactorBatchProcessor...")
        processor = FactorBatchProcessor()
        print("âœ… åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
        test_symbols = ['600519', '000001', '000858', '601318', '000333']

        # è¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(progress, current, total):
            print(f"  è¿›åº¦: {progress:.1f}% ({current}/{total})")

        print(f"\nå¤„ç† {len(test_symbols)} åªè‚¡ç¥¨...")

        # å¤„ç†è‚¡ç¥¨åˆ—è¡¨
        report = processor.process_symbol_list(
            symbols=test_symbols,
            mode='incremental',
            progress_callback=progress_callback
        )

        # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
        print(f"\nğŸ“‹ å¤„ç†æŠ¥å‘Šæ‘˜è¦:")
        summary = report['summary']
        print(f"   æˆåŠŸ: {summary['successful']}/{summary['total_symbols']}")
        print(f"   å¤±è´¥: {summary['failed']}")
        print(f"   è·³è¿‡: {summary['skipped']}")
        print(f"   æ€»è®°å½•: {summary['total_records']:,}")
        print(f"   æˆåŠŸç‡: {summary['success_rate']}%")

        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        perf = report['performance']
        print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
        print(f"   æ€»è€—æ—¶: {perf['duration_seconds']}ç§’")
        print(f"   å¤„ç†é€Ÿåº¦: {perf['symbols_per_second']:.2f}åª/ç§’")
        print(f"   è®°å½•é€Ÿåº¦: {perf['records_per_second']:.2f}æ¡/ç§’")

        # æ¸…ç†
        processor.cleanup()

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_batch_processor()

    if success:
        print("\nâœ… æ‰¹é‡å› å­å¤„ç†å™¨æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ æ‰¹é‡å› å­å¤„ç†å™¨æµ‹è¯•å¤±è´¥")

    exit(0 if success else 1)