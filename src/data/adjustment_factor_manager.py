# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/src/data\adjustment_factor_manager.py
# File Name: adjustment_factor_manager
# @ Author: mango-gh22
# @ Dateï¼š2025/12/15 0:30
"""
desc å¤æƒå› å­ç®¡ç†å™¨ - è´Ÿè´£é‡‡é›†ã€å­˜å‚¨å’Œç®¡ç†å¤æƒå› å­
ä¿®å¤ç‰ˆæœ¬: v0.5.1-fix - æ·»åŠ ç¼ºå¤±çš„fetch_factorsæ–¹æ³•
å¤æƒå› å­ç®¡ç†å™¨ - P6é˜¶æ®µå®Œæ•´å®ç°
è´Ÿè´£ï¼šä¸‹è½½ â†’ è®¡ç®— â†’ å­˜å‚¨ â†’ æŸ¥è¯¢ å…¨é“¾è·¯
å•çº¿ç¨‹çº¦æŸï¼šé€šè¿‡BaostockAdjustmentFactorDownloaderå¼ºåˆ¶å®ç°
P7/P8é¢„ç•™ï¼š--daemon å’Œ --batch å‚æ•°è§£ææ¥å£
è¿è¡Œï¼špython -m src.data.adjustment_factor_manager --mode incremental

æ ¸å¿ƒçº¦æŸï¼šå•çº¿ç¨‹æ‰§è¡Œï¼ˆthread_num=1ï¼‰ï¼ŒP7/P8å¯å¹³æ»‘æ‰©å±•
"""

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any, Union
import logging
import argparse
import sys
import time
from pathlib import Path
import threading
import os

from src.data.baostock_adjustment_factor_downloader import BaostockAdjustmentFactorDownloader
from src.data.adjustment_factor_storage import AdjustmentFactorStorage
from src.data.adjustment_factor_date_calculator import AdjustmentFactorDateCalculator
from src.utils.code_converter import normalize_stock_code
from src.utils.logger import get_logger
from src.monitoring.calculation_logger import CalculationLogger

logger = get_logger(__name__)


class AdjustmentFactorManager:
    """
    å¤æƒå› å­å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨
    P6é˜¶æ®µï¼šå¼ºåˆ¶å•çº¿ç¨‹ï¼Œç¨³å¥ä¼˜å…ˆ
    P7/P8é˜¶æ®µï¼šé€šè¿‡é…ç½®åˆ‡æ¢ä¸ºå¤šçº¿ç¨‹/å®ˆæŠ¤è¿›ç¨‹
    """

    def __init__(self, config_path: str = 'config/adjustment_factor_config.yaml'):
        """
        åˆå§‹åŒ–ç®¡ç†å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config = self._load_config()

        # æ ¸å¿ƒç»„ä»¶ï¼ˆæŒ‰æ‰§è¡Œé¡ºåºåˆå§‹åŒ–ï¼‰
        self.downloader = BaostockAdjustmentFactorDownloader(config_path)
        self.storage = AdjustmentFactorStorage(self.config.get('database_config', 'config/database.yaml'))
        self.date_calculator = AdjustmentFactorDateCalculator(self.storage)

        # ç›‘æ§æ—¥å¿—å™¨
        self.calc_logger = self._init_calculation_logger()

        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆæŒ‰æµç¨‹é˜¶æ®µç»†åˆ†ï¼‰
        self.stats = {
            'start_time': None,
            'end_time': None,
            'total_symbols': 0,
            'successful_download': 0,
            'failed_download': 0,
            'successful_calculate': 0,
            'failed_calculate': 0,
            'successful_store': 0,
            'failed_store': 0,
            'total_records_downloaded': 0,
            'total_records_stored': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'duration_ms': 0
        }

        # å•çº¿ç¨‹é”ï¼ˆP6é˜¶æ®µå¼ºåˆ¶ä½¿ç”¨ï¼‰
        self._operation_lock = threading.Lock()

        logger.info("âœ… å¤æƒå› å­ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   å•çº¿ç¨‹æ¨¡å¼: {'ENABLED' if self.is_single_thread() else 'DISABLED'}")

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®ï¼Œæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–"""
        try:
            from src.config.config_loader import ConfigLoader
            loader = ConfigLoader()
            config = loader.load_yaml_config(self.config_path)

            # åˆå¹¶ç¯å¢ƒå˜é‡ï¼ˆå¦‚DB_PASSWORDï¼‰
            from dotenv import load_dotenv
            load_dotenv()

            if os.getenv('ADJUSTMENT_FACTOR_THREAD_NUM'):
                config['download']['thread_num'] = int(os.getenv('ADJUSTMENT_FACTOR_THREAD_NUM'))

            return config.get('adjustment_factors', {})
        except Exception as e:
            logger.warning(f"åŠ è½½é…ç½®å¤±è´¥ {self.config_path}: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return {
                'download': {'thread_num': 1, 'incremental_mode': True, 'enable_cache': False},
                'storage': {'batch_size': 500, 'use_upsert': True}
            }

    def _init_calculation_logger(self) -> CalculationLogger:
        """åˆå§‹åŒ–æ€§èƒ½ç›‘æ§æ—¥å¿—å™¨"""
        log_config = {
            'enabled': self.config.get('logging', {}).get('enable_performance_monitoring', True),
            'log_level': self.config.get('logging', {}).get('log_level', 'INFO'),
            'log_dir': 'logs/adjustment_factors',
            'log_queries': True,
            'log_results': False,
            'log_performance': True,
            'buffer_size': 50,
            'flush_interval': 30,
            'max_log_size': 100 * 1024 * 1024  # 100MB
        }
        return CalculationLogger(log_config)

    def is_single_thread(self) -> bool:
        """P6é˜¶æ®µï¼šå§‹ç»ˆè¿”å›True"""
        # P7é˜¶æ®µï¼šè¿”å› self.config.get('download', {}).get('thread_num', 1) == 1
        return True

    def download_batch(self, symbols: List[str], start_date: str = None,
                       end_date: str = None, mode: str = 'incremental') -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡ä¸‹è½½å¹¶å­˜å‚¨å¤æƒå› å­ï¼ˆP6é˜¶æ®µå•çº¿ç¨‹å®ç°ï¼‰

        æ‰§è¡Œæµç¨‹ï¼š
        1. è®¡ç®—ä¸‹è½½èŒƒå›´ â†’ 2. ä¸‹è½½å¤æƒå› å­ â†’ 3. å­˜å‚¨æ•°æ®åº“ â†’ 4. è®°å½•æ—¥å¿—

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸ YYYYMMDD
            mode: æ—¥æœŸè®¡ç®—æ¨¡å¼ ('incremental', 'full', 'specific')

        Returns:
            Dict[str, pd.DataFrame]: æˆåŠŸå¤„ç†çš„ç¬¦å· -> å› å­DataFrame
        """
        # å¼ºåˆ¶å•çº¿ç¨‹æ‰§è¡Œï¼ˆP6çº¦æŸï¼‰
        with self._operation_lock:
            return self._execute_batch_sync(symbols, start_date, end_date, mode)

    def _execute_batch_sync(self, symbols: List[str], start_date: str = None,
                            end_date: str = None, mode: str = 'incremental') -> Dict[str, pd.DataFrame]:
        """åŒæ­¥æ‰¹é‡æ‰§è¡Œæ ¸å¿ƒé€»è¾‘ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        self.stats['start_time'] = datetime.now()
        self.stats['total_symbols'] = len(symbols)

        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†å¤æƒå› å­: {len(symbols)} åªè‚¡ç¥¨")
        logger.info(f"ğŸ“… æ¨¡å¼: {mode} | èŒƒå›´: {start_date or 'auto'} - {end_date or 'auto'}")
        logger.info(f"âš™ï¸  å•çº¿ç¨‹æ¨¡å¼: {'å¼ºåˆ¶å¯ç”¨' if self.is_single_thread() else 'å·²å…³é—­'}")

        results = {}

        # P6ï¼šå•çº¿ç¨‹é¡ºåºå¤„ç†
        for i, symbol in enumerate(symbols, 1):
            success = self._process_single_symbol(
                symbol, i, len(symbols), start_date, end_date, mode, results
            )

        # æ›´æ–°ç»Ÿè®¡
        self.stats['end_time'] = datetime.now()
        self.stats['duration_ms'] = int((self.stats['end_time'] - self.stats['start_time']).total_seconds() * 1000)

        # è¾“å‡ºæ€»ç»“
        self._print_batch_summary()

        return results

    def _process_single_symbol(self, symbol: str, index: int, total: int,
                               start_date: str, end_date: str, mode: str,
                               results: Dict) -> bool:
        """å¤„ç†å•åªè‚¡ç¥¨ï¼ˆåŸå­æ“ä½œï¼‰"""
        log_id = self.calc_logger.log_calculation_start(
            indicator_name="adjustment_factor",
            symbol=str(symbol),
            period="daily",
            calculation_type="download_calculate_store",
            parameters={
                "mode": mode,
                "start_date": start_date,
                "end_date": end_date,
                "config": self.config
            },
            input_data_shape=(0, 0)
        )

        start_ms = time.time() * 1000

        try:
            logger.info(f"[{index}/{total}] å¤„ç† {symbol}")

            # Step 1: è®¡ç®—ä¸‹è½½èŒƒå›´
            date_range = self.date_calculator.calculate_download_range(
                symbol, mode=mode, custom_params={'start_date': start_date, 'end_date': end_date}
            )

            if not date_range:
                logger.info(f"  {symbol} æ•°æ®å·²æœ€æ–°ï¼Œè·³è¿‡")
                self.stats['cache_hits'] += 1
                self.calc_logger.log_calculation_end(
                    log_id=log_id, success=True, output_data_shape=(0, 0),
                    duration_ms=int(time.time() * 1000 - start_ms), cache_hit=True
                )
                return True

            start, end = date_range
            logger.info(f"  ä¸‹è½½èŒƒå›´: {start} - {end}")

            # Step 2: ä¸‹è½½å¤æƒå› å­æ•°æ®ï¼ˆæ¥å£å·²è¿”å›è®¡ç®—å¥½çš„å› å­ï¼‰
            factor_df = self.downloader.fetch_adjustment_factor_data(symbol, start, end)

            if factor_df.empty:
                logger.warning(f"  {symbol} æ— å¤æƒå› å­æ•°æ®")
                self.stats['failed_download'] += 1
                self.calc_logger.log_calculation_end(
                    log_id=log_id, success=True, output_data_shape=(0, 0),
                    duration_ms=int(time.time() * 1000 - start_ms), cache_hit=False
                )
                return True  # æ— æ•°æ®ä¸ç®—å¤±è´¥

            self.stats['successful_download'] += 1
            self.stats['total_records_downloaded'] += len(factor_df)
            logger.info(f"  âœ… ä¸‹è½½æˆåŠŸ: {len(factor_df)} æ¡")

            # Step 3: ç›´æ¥ä½¿ç”¨æ•°æ®ï¼ˆæ— éœ€è®¡ç®—ï¼‰
            factors_df = factor_df.copy()

            if factors_df.empty:
                logger.warning(f"  {symbol} æ— å¤æƒå› å­æ•°æ®")
                self.calc_logger.log_calculation_end(
                    log_id=log_id, success=True, output_data_shape=(0, 0),
                    duration_ms=int(time.time() * 1000 - start_ms), cache_hit=False
                )
                return True

            self.stats['successful_calculate'] += 1
            logger.info(f"  âœ… æ•°æ®å‡†å¤‡æˆåŠŸ: {len(factors_df)} æ¡")

            # Step 4: å­˜å‚¨åˆ°æ•°æ®åº“
            affected_rows, report = self.storage.store_adjustment_factors(factors_df)

            if affected_rows > 0:
                results[symbol] = factors_df
                self.stats['successful_store'] += 1
                self.stats['total_records_stored'] += affected_rows
                logger.info(f"  âœ… å­˜å‚¨æˆåŠŸ: {affected_rows}/{len(factors_df)} æ¡")

                end_ms = time.time() * 1000
                self.calc_logger.log_calculation_end(
                    log_id=log_id, success=True, output_data_shape=factors_df.shape,
                    duration_ms=int(end_ms - start_ms), performance_metrics=report
                )
                return True
            else:
                logger.warning(f"  {symbol}: å­˜å‚¨å¤±è´¥ - {report.get('reason', 'unknown')}")
                self.stats['failed_store'] += 1

                end_ms = time.time() * 1000
                self.calc_logger.log_calculation_end(
                    log_id=log_id, success=False, output_data_shape=factors_df.shape,
                    duration_ms=int(end_ms - start_ms), error_message=report.get('error', 'Storage failed')
                )
                return False

        except Exception as e:
            logger.error(f"  âŒ {symbol} å¤„ç†å¼‚å¸¸: {e}", exc_info=True)
            self.stats['failed_download'] += 1  # ç»Ÿå½’ä¸ºä¸‹è½½å¤±è´¥

            end_ms = time.time() * 1000
            self.calc_logger.log_calculation_end(
                log_id=log_id, success=False, output_data_shape=None,
                duration_ms=int(end_ms - start_ms), error_message=str(e)
            )
            return False

# -------4-----------------------------
    def update_symbol(self, symbol: str, mode: str = 'incremental') -> bool:
        """
        æ›´æ–°å•åªè‚¡ç¥¨å¤æƒå› å­ï¼ˆæ™ºèƒ½å¢é‡ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            mode: æ›´æ–°æ¨¡å¼

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            normalized_symbol = normalize_stock_code(symbol)
            logger.info(f"æ›´æ–°å•åªè‚¡ç¥¨: {normalized_symbol}")

            result = self.download_batch([normalized_symbol], mode=mode)
            return len(result) > 0

        except Exception as e:
            logger.error(f"å•åªè‚¡ç¥¨æ›´æ–°å¤±è´¥ {symbol}: {e}")
            return False

    def get_adjustment_factor(
            self,
            symbol: str,
            date: Union[str, datetime],
            factor_type: str = 'forward'
    ) -> Optional[float]:
        """
        æ ¸å¿ƒæŸ¥è¯¢æ¥å£ï¼šè·å–æŒ‡å®šæ—¥æœŸå¤æƒå› å­

        ç®—æ³•ï¼š
        1. æŸ¥è¯¢å°äºç­‰äºç›®æ ‡æ—¥æœŸçš„æœ€æ–°é™¤æƒè®°å½•
        2. è‹¥æ— è®°å½•ï¼Œè¿”å›1.0ï¼ˆæ— é™¤æƒï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸï¼ˆYYYY-MM-DD æˆ– YYYYMMDD æˆ– datetimeï¼‰
            factor_type: 'forward', 'backward', 'total'

        Returns:
            å¤æƒå› å­å€¼ï¼ˆå¼‚å¸¸è¿”å›Noneï¼‰
        """
        try:
            # æ—¥æœŸæ ‡å‡†åŒ–
            date_str = self._normalize_date(date)

            normalized_symbol = normalize_stock_code(symbol)

            # æŸ¥è¯¢æœ€æ¥è¿‘çš„é™¤æƒæ—¥ï¼ˆå°äºç­‰äºç›®æ ‡æ—¥æœŸï¼‰
            query = f"""
                SELECT {factor_type}_factor, ex_date 
                FROM {self.storage.factor_table}
                WHERE symbol = %s AND ex_date <= %s
                ORDER BY ex_date DESC 
                LIMIT 1
            """

            with self.storage.db_connector.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(query, (normalized_symbol, date_str))
                    result = cursor.fetchone()

            if result and result[0] is not None:
                factor = float(result[0])
                logger.debug(f"æŸ¥è¯¢å¤æƒå› å­: {symbol} {date_str} {factor_type}={factor:.6f}")
                return factor

            # æ— é™¤æƒäº‹ä»¶ï¼Œè¿”å›1.0
            logger.debug(f"æ— é™¤æƒäº‹ä»¶ï¼Œè¿”å›1.0: {symbol} {date_str}")
            return 1.0

        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤æƒå› å­å¤±è´¥ {symbol} {date}: {e}")
            return None

    def get_factors_for_symbol(self, symbol: str, start_date: str = None,
                               end_date: str = None) -> pd.DataFrame:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨çš„æ‰€æœ‰å¤æƒå› å­ï¼ˆå…¼å®¹adjustor.pyï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            å¤æƒå› å­DataFrame
        """
        return self.storage.get_factors_by_symbol(symbol, start_date, end_date)

    def _normalize_date(self, date: Union[str, datetime]) -> str:
        """æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ– -> YYYY-MM-DD"""
        if isinstance(date, datetime):
            return date.strftime('%Y-%m-%d')
        elif isinstance(date, str):
            return f"{date[:4]}-{date[4:6]}-{date[6:8]}" if len(date) == 8 else date
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ—¥æœŸç±»å‹: {type(date)}")

    def _print_batch_summary(self):
        """æ‰“å°æ‰¹é‡å¤„ç†æ€»ç»“æŠ¥å‘Š"""
        if not self.stats['start_time']:
            return

        print("\n" + "=" * 80)
        print("ğŸ“Š å¤æƒå› å­æ‰¹é‡å¤„ç†æ€»ç»“æŠ¥å‘Š")
        print("-" * 80)
        print(f"  æ‰§è¡Œæ—¶é—´: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  ç»“æŸæ—¶é—´: {self.stats['end_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  æ€»è€—æ—¶: {self.stats['duration_ms']}ms")
        print("-" * 80)
        print(f"  ğŸ“¥ ä¸‹è½½é˜¶æ®µ:")
        print(f"     æˆåŠŸ: {self.stats['successful_download']} / {self.stats['total_symbols']}")
        print(f"     å¤±è´¥: {self.stats['failed_download']}")
        print(f"     è®°å½•æ•°: {self.stats['total_records_downloaded']:,}")
        print(f"  ğŸ§® è®¡ç®—é˜¶æ®µ:")
        print(f"     æˆåŠŸ: {self.stats['successful_calculate']}")
        print(f"     å¤±è´¥: {self.stats['failed_calculate']}")
        print(f"  ğŸ’¾ å­˜å‚¨é˜¶æ®µ:")
        print(f"     æˆåŠŸ: {self.stats['successful_store']}")
        print(f"     å¤±è´¥: {self.stats['failed_store']}")
        print(f"     è®°å½•æ•°: {self.stats['total_records_stored']:,}")
        print("-" * 80)
        print(f"  ç¼“å­˜å‘½ä¸­: {self.stats['cache_hits']}")
        print(f"  ç¼“å­˜æœªå‘½ä¸­: {self.stats['cache_misses']}")
        success_rate = self.stats['successful_store'] / self.stats['total_symbols'] * 100 if self.stats[
                                                                                                 'total_symbols'] > 0 else 0
        print(f"  æ•´ä½“æˆåŠŸç‡: {success_rate:.1f}%")
        print("=" * 80)

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ·±æ‹·è´ï¼‰"""
        return self.stats.copy()

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'start_time': None,
            'end_time': None,
            'total_symbols': 0,
            'successful_download': 0,
            'failed_download': 0,
            'successful_calculate': 0,
            'failed_calculate': 0,
            'successful_store': 0,
            'failed_store': 0,
            'total_records_downloaded': 0,
            'total_records_stored': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'duration_ms': 0
        }

    def cleanup(self):
        """æ¸…ç†èµ„æºï¼ˆå¹‚ç­‰ï¼‰"""
        try:
            self.downloader.logout()
            self.calc_logger.flush_buffer()
            logger.info("å¤æƒå› å­ç®¡ç†å™¨æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"æ¸…ç†èµ„æºå¼‚å¸¸: {e}")

    def __del__(self):
        """ææ„å‡½æ•°ï¼ˆç¡®ä¿èµ„æºé‡Šæ”¾ï¼‰"""
        self.cleanup()

    # ========== P7/P8é˜¶æ®µæ‰©å±•æ¥å£ ==========

    def download_batch_parallel(self, symbols: List[str], start_date: str = None,
                                end_date: str = None, mode: str = 'incremental',
                                max_workers: int = 3) -> Dict[str, pd.DataFrame]:
        """
        P7é˜¶æ®µï¼šå¤šçº¿ç¨‹æ‰¹é‡ä¸‹è½½ï¼ˆé¢„ç•™æ¥å£ï¼‰
        å½“å‰P6é˜¶æ®µè°ƒç”¨æ­¤æ–¹æ³•ä¼šé™çº§ä¸ºå•çº¿ç¨‹
        """
        logger.warning("P6é˜¶æ®µï¼šå¤šçº¿ç¨‹æ¨¡å¼å·²é™çº§ä¸ºå•çº¿ç¨‹")
        return self.download_batch(symbols, start_date, end_date, mode)

    def run_daemon_mode(self, interval_hours: int = 24):
        """
        P7é˜¶æ®µï¼šå®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ï¼ˆé¢„ç•™æ¥å£ï¼‰
        """
        logger.info(f"ğŸ”„ å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼å°†åœ¨P7é˜¶æ®µå®ç°ï¼ˆå½“å‰é—´éš”: {interval_hours}hï¼‰")
        # TODO: P7å®ç°
        pass

    def run_batch_job(self, job_file: str):
        """
        P8é˜¶æ®µï¼šæ‰¹é‡ä»»åŠ¡æ¨¡å¼ï¼ˆé¢„ç•™æ¥å£ï¼‰
        """
        logger.info(f"ğŸ“¦ æ‰¹é‡ä»»åŠ¡æ¨¡å¼å°†åœ¨P8é˜¶æ®µå®ç°ï¼ˆé…ç½®æ–‡ä»¶: {job_file}ï¼‰")
        # TODO: P8å®ç°
        pass

    def export_factors(self, symbol: str, format: str = 'csv',
                       output_path: Optional[str] = None) -> str:
        """
        P8é˜¶æ®µï¼šå¯¼å‡ºå¤æƒå› å­æ•°æ®ï¼ˆé¢„ç•™æ¥å£ï¼‰

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            format: å¯¼å‡ºæ ¼å¼ï¼ˆcsv, json, parquetï¼‰
            output_path: è¾“å‡ºè·¯å¾„

        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        logger.info(f"ğŸ“¤ å¯¼å‡ºåŠŸèƒ½å°†åœ¨P8é˜¶æ®µå®ç°: {symbol} -> {format}")
        return ""


# ========== å‘½ä»¤è¡Œæ¥å£ï¼ˆP7/P8ç‹¬ç«‹è¿è¡Œå…¥å£ï¼‰ ==========
# P6é˜¶æ®µï¼šä»…æ”¯æŒå•æ¬¡æ‰§è¡Œ
# P7é˜¶æ®µï¼šæ”¯æŒ --daemon
# P8é˜¶æ®µï¼šæ”¯æŒ --batch

def main():
    """å‘½ä»¤è¡Œä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="å¤æƒå› å­ç®¡ç†å™¨ - P6é˜¶æ®µå•çº¿ç¨‹æ¨¡å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # P6ï¼šå•æ¬¡è¿è¡Œï¼ˆé»˜è®¤ï¼‰
  python adjustment_factor_manager.py --symbols sh600519 sz000001 --mode incremental

  # P6ï¼šä»æ–‡ä»¶åŠ è½½è‚¡ç¥¨åˆ—è¡¨
  python adjustment_factor_manager.py --symbols-file config/symbols.yaml --mode full

  # P7ï¼šå®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ï¼ˆæš‚æœªå®ç°ï¼‰
  python adjustment_factor_manager.py --daemon --interval 24

  # P8ï¼šæ‰¹é‡ä»»åŠ¡æ¨¡å¼ï¼ˆæš‚æœªå®ç°ï¼‰
  python adjustment_factor_manager.py --batch job_config.yaml
        """
    )

    parser.add_argument(
        "--symbols",
        nargs="+",
        help="è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¦‚ sh600519 sz000001ï¼‰"
    )
    parser.add_argument(
        "--symbols-file",
        help="è‚¡ç¥¨ä»£ç æ–‡ä»¶è·¯å¾„ï¼ˆYAMLæ ¼å¼ï¼‰"
    )
    parser.add_argument(
        "--start-date",
        help="å¼€å§‹æ—¥æœŸ YYYYMMDD"
    )
    parser.add_argument(
        "--end-date",
        help="ç»“æŸæ—¥æœŸ YYYYMMDD"
    )
    parser.add_argument(
        "--mode",
        default="incremental",
        choices=["incremental", "full", "specific"],
        help="ä¸‹è½½æ¨¡å¼ï¼ˆé»˜è®¤: incrementalï¼‰"
    )
    parser.add_argument(
        "--config",
        default="config/adjustment_factor_config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )

    # P7/P8é¢„ç•™å‚æ•°
    parser.add_argument(
        "--daemon",
        action="store_true",
        help="P7: å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ï¼ˆæš‚æœªå®ç°ï¼‰"
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=24,
        help="P7: å®ˆæŠ¤è¿›ç¨‹æ‰§è¡Œé—´éš”ï¼ˆå°æ—¶ï¼‰"
    )
    parser.add_argument(
        "--batch",
        help="P8: æ‰¹é‡ä»»åŠ¡é…ç½®æ–‡ä»¶ï¼ˆæš‚æœªå®ç°ï¼‰"
    )

    args = parser.parse_args()

    # P7/P8æ¨¡å¼æ£€æŸ¥
    if args.daemon:
        print("ğŸ”„ P7å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼å°†åœ¨åç»­ç‰ˆæœ¬å®ç°")
        sys.exit(0)

    if args.batch:
        print(f"ğŸ“¦ P8æ‰¹é‡ä»»åŠ¡æ¨¡å¼å°†åœ¨åç»­ç‰ˆæœ¬å®ç°: {args.batch}")
        sys.exit(0)

    # P6é˜¶æ®µï¼šå•æ¬¡æ‰§è¡Œ
    print("ğŸš€ P6é˜¶æ®µå•çº¿ç¨‹æ¨¡å¼å¯åŠ¨")

    manager = AdjustmentFactorManager(args.config)

    # åŠ è½½è‚¡ç¥¨åˆ—è¡¨
    symbols = []
    if args.symbols:
        symbols = [normalize_stock_code(s) for s in args.symbols]
    elif args.symbols_file:
        from src.data.symbol_manager import get_symbol_manager
        sm = get_symbol_manager()
        symbols = sm.get_symbols_from_file(args.symbols_file)
    else:
        # é»˜è®¤ä½¿ç”¨CSI A50
        from src.data.symbol_manager import get_symbol_manager
        sm = get_symbol_manager()
        symbols = sm.get_symbols('csi_a50')
        print(f"ğŸ“‹ æœªæŒ‡å®šè‚¡ç¥¨ï¼Œé»˜è®¤ä½¿ç”¨CSI A50: {len(symbols)} åª")

    if not symbols:
        print("âŒ é”™è¯¯: æœªæä¾›æœ‰æ•ˆè‚¡ç¥¨ä»£ç ")
        sys.exit(1)

    print(f"ğŸ“Š å‡†å¤‡å¤„ç† {len(symbols)} åªè‚¡ç¥¨")
    print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {args.start_date or 'è‡ªåŠ¨'} - {args.end_date or 'è‡ªåŠ¨'}")
    print(f"âš™ï¸  æ¨¡å¼: {args.mode}")
    print("-" * 60)

    try:
        # æ ¸å¿ƒæ‰§è¡Œ
        results = manager.download_batch(
            symbols,
            start_date=args.start_date,
            end_date=args.end_date,
            mode=args.mode
        )

        # è¾“å‡ºç»“æœ
        print("\n" + "=" * 60)
        print("âœ… æ‰§è¡Œå®Œæˆ")
        print(f"ğŸ“ˆ æˆåŠŸå¤„ç†: {len(results)} åªè‚¡ç¥¨")
        print(f"â±ï¸  æ€»è€—æ—¶: {manager.stats['duration_ms']}ms")
        print("=" * 60)

        sys.exit(0)

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ è‡´å‘½é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        manager.cleanup()


if __name__ == "__main__":
    main()
