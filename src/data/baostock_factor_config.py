# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/src/data\baostock_factor_config.py
# File Name: baostock_factor_config
# @ Author: mango-gh22
# @ Dateï¼š2026/1/3 8:51
"""
desc PBå› å­ä¸‹è½½é…ç½®ç®¡ç†æ¨¡å—
"""

import yaml
import os
from typing import Dict, Any, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class FactorConfigLoader:
    """å› å­ä¸‹è½½é…ç½®åŠ è½½å™¨"""

    def __init__(self, config_path: str = 'config/factor_config.yaml'):
        self.config_path = config_path
        self.config = self._load_config()

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path(self.config_path)

        if not config_file.exists():
            logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()

        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)

            # åˆå¹¶ç¯å¢ƒå˜é‡
            self._merge_env_vars(config)

            logger.info(f"åŠ è½½å› å­é…ç½®æˆåŠŸ: {config_file}")
            return config

        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return self._get_default_config()

    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'execution': {
                'thread_num': 1,
                'request_interval': 1.5,
                'max_retries': 3,
                'retry_delay_base': 3
            },
            'batch': {
                'batch_size': 50,
                'symbols_per_request': 100,
                'progress_report_interval': 10
            },
            'date_range': {
                'default_days_back': 365,
                'max_history_years': 5,
                'full_update_months': 12
            },
            'storage': {
                'table_name': 'stock_daily_data',
                'enable_incremental': True,
                'force_update': False,
                'batch_insert_size': 500
            },
            'performance': {
                'enable_cache': True,
                'cache_ttl': 3600,
                'cache_dir': 'data/cache/baostock/factors'
            },
            'monitoring': {
                'enable_detailed_log': True,
                'log_level': 'INFO',
                'save_report': True,
                'report_dir': 'data/reports/factors'
            },
            'baostock_fields': {
                'daily_fields': 'date,code,peTTM,pbMRQ,psTTM'
            }
        }

    def _merge_env_vars(self, config: Dict[str, Any]):
        """åˆå¹¶ç¯å¢ƒå˜é‡"""
        # æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®
        env_mappings = {
            'FACTOR_THREAD_NUM': ('execution', 'thread_num', int),
            'FACTOR_REQUEST_INTERVAL': ('execution', 'request_interval', float),
            'FACTOR_MAX_RETRIES': ('execution', 'max_retries', int),
        }

        for env_var, (section, key, type_func) in env_mappings.items():
            if env_var in os.environ:
                try:
                    value = type_func(os.environ[env_var])
                    if section in config and key in config[section]:
                        config[section][key] = value
                        logger.info(f"ä»ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®: {section}.{key}={value}")
                except (ValueError, TypeError) as e:
                    logger.warning(f"ç¯å¢ƒå˜é‡è½¬æ¢å¤±è´¥ {env_var}: {e}")

    def get(self, key_path: str, default: Any = None) -> Any:
        """è·å–é…ç½®å€¼ï¼ˆæ”¯æŒç‚¹è·¯å¾„ï¼‰"""
        keys = key_path.split('.')
        value = self.config

        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default

        return value

    def update(self, key_path: str, value: Any):
        """æ›´æ–°é…ç½®å€¼"""
        keys = key_path.split('.')
        config = self.config

        for i, key in enumerate(keys[:-1]):
            if key not in config:
                config[key] = {}
            config = config[key]

        config[keys[-1]] = value

    def save(self, output_path: Optional[str] = None):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        if output_path is None:
            output_path = self.config_path

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
            logger.info(f"é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")

    def validate(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        errors = []

        # æ£€æŸ¥å¿…è¦é…ç½®
        required_paths = [
            'execution.thread_num',
            'execution.request_interval',
            'baostock_fields.daily_fields'
        ]

        for path in required_paths:
            if self.get(path) is None:
                errors.append(f"ç¼ºå°‘å¿…è¦é…ç½®: {path}")

        # éªŒè¯å•çº¿ç¨‹çº¦æŸï¼ˆP6é˜¶æ®µï¼‰
        thread_num = self.get('execution.thread_num')
        if thread_num != 1:
            logger.warning(f"P6é˜¶æ®µå¼ºåˆ¶å•çº¿ç¨‹ï¼Œå½“å‰é…ç½®ä¸º{thread_num}ï¼Œå°†è‡ªåŠ¨è°ƒæ•´ä¸º1")
            self.update('execution.thread_num', 1)

        if errors:
            for error in errors:
                logger.error(error)
            return False

        return True

    def get_baostock_fields(self) -> str:
        """è·å–Baostockå­—æ®µå­—ç¬¦ä¸²"""
        return self.get('baostock_fields.daily_fields', 'date,code,peTTM,pbMRQ,psTTM')

    def get_cache_dir(self) -> Path:
        """è·å–ç¼“å­˜ç›®å½•"""
        cache_dir_str = self.get('performance.cache_dir', 'data/cache/baostock/factors')
        cache_dir = Path(cache_dir_str)
        cache_dir.mkdir(parents=True, exist_ok=True)
        return cache_dir


# å•ä¾‹é…ç½®å®ä¾‹
_config_loader = None


def get_config_loader(config_path: str = 'config/factor_config.yaml') -> FactorConfigLoader:
    """è·å–é…ç½®åŠ è½½å™¨å•ä¾‹"""
    global _config_loader
    if _config_loader is None:
        _config_loader = FactorConfigLoader(config_path)
    return _config_loader


def test_config_loader():
    """æµ‹è¯•é…ç½®åŠ è½½å™¨"""
    print("ğŸ§ª æµ‹è¯•å› å­é…ç½®åŠ è½½å™¨")
    print("=" * 50)

    # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
    test_config = """
execution:
  thread_num: 1
  request_interval: 1.5
  max_retries: 3

batch:
  batch_size: 50
  symbols_per_request: 100
  progress_report_interval: 10
    """

    # æµ‹è¯•é»˜è®¤é…ç½®
    loader = FactorConfigLoader()
    config = loader.config

    print("ğŸ“‹ é»˜è®¤é…ç½®:")
    print(f"  çº¿ç¨‹æ•°: {config['execution']['thread_num']}")
    print(f"  è¯·æ±‚é—´éš”: {config['execution']['request_interval']}ç§’")
    print(f"  æ‰¹é‡å¤§å°: {config['batch']['batch_size']}")
    print(f"  Baostockå­—æ®µ: {config['baostock_fields']['daily_fields']}")

    # æµ‹è¯•è·å–æ–¹æ³•
    print("\nğŸ” æµ‹è¯•getæ–¹æ³•:")
    print(f"  execution.thread_num: {loader.get('execution.thread_num')}")
    print(f"  batch.batch_size: {loader.get('batch.batch_size')}")
    print(f"  non.existing.key: {loader.get('non.existing.key', 'default_value')}")

    # æµ‹è¯•æ›´æ–°æ–¹æ³•
    print("\nâœï¸ æµ‹è¯•updateæ–¹æ³•:")
    loader.update('execution.request_interval', 2.0)
    print(f"  æ›´æ–°åè¯·æ±‚é—´éš”: {loader.get('execution.request_interval')}")

    # æµ‹è¯•éªŒè¯
    print("\nâœ… æµ‹è¯•é…ç½®éªŒè¯:")
    is_valid = loader.validate()
    print(f"  é…ç½®æœ‰æ•ˆæ€§: {is_valid}")

    print("\nğŸ‰ é…ç½®åŠ è½½å™¨æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_config_loader()