# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/src/data\factor_data_pipeline.py
# File Name: factor_data_pipeline
# @ Author: mango-gh22
# @ Dateï¼š2026/1/3 12:42
"""
desc å› å­æ•°æ®å®Œæ•´ç®¡é“ - é›†æˆä¸‹è½½ã€å­˜å‚¨ã€å¢é‡æ›´æ–°
æ”¯æŒäº¤æ˜“æ—¥ç®¡ç†ï¼ŒåŸºäºçœŸå®äº¤æ˜“æ—¥è¿›è¡Œæ•°æ®ä¸‹è½½
"""

import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging
import time
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from src.data.baostock_pb_factor_downloader import BaostockPBFactorDownloader
from src.data.factor_storage_manager import FactorStorageManager
from src.utils.enhanced_trade_date_manager import EnhancedTradeDateManager
from src.config.logging_config import setup_logging

logger = setup_logging()


class FactorDataPipeline:
    """
    å› å­æ•°æ®å®Œæ•´ç®¡é“ - é›†æˆä¸‹è½½ã€å­˜å‚¨ã€å¢é‡æ›´æ–°
    æ”¯æŒäº¤æ˜“æ—¥ç®¡ç†ï¼Œç¡®ä¿åŸºäºçœŸå®äº¤æ˜“æ—¥è¿›è¡Œæ•°æ®æ“ä½œ
    """

    def __init__(self, config_path: str = 'config/database.yaml'):
        """
        åˆå§‹åŒ–å› å­æ•°æ®ç®¡é“

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åˆå§‹åŒ–ç»„ä»¶
        self.downloader = BaostockPBFactorDownloader()
        self.storage = FactorStorageManager(config_path)
        self.trade_date_manager = EnhancedTradeDateManager()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_symbols': 0,
            'successful': 0,
            'failed': 0,
            'no_data': 0,
            'total_records': 0,
            'start_time': None,
            'end_time': None,
            'duration_seconds': 0
        }

        logger.info("âœ… å› å­æ•°æ®ç®¡é“åˆå§‹åŒ–å®Œæˆ")

    def _adjust_date_range(self, start_date: str, end_date: str) -> Tuple[str, str]:
        """
        è°ƒæ•´æ—¥æœŸèŒƒå›´ä¸ºçœŸå®çš„äº¤æ˜“æ—¥èŒƒå›´

        Args:
            start_date: åŸå§‹å¼€å§‹æ—¥æœŸ (YYYYMMDD)
            end_date: åŸå§‹ç»“æŸæ—¥æœŸ (YYYYMMDD)

        Returns:
            è°ƒæ•´åçš„(å¼€å§‹æ—¥æœŸ, ç»“æŸæ—¥æœŸ)
        """
        try:
            # å¦‚æœäº¤æ˜“æ—¥ç®¡ç†å™¨æ²¡æœ‰ç›¸åº”æ–¹æ³•ï¼Œä½¿ç”¨ä¸‹è½½å™¨è‡ªå¸¦çš„è°ƒæ•´
            if hasattr(self.trade_date_manager, 'adjust_to_trade_date'):
                # è°ƒæ•´å¼€å§‹æ—¥æœŸä¸ºæœ€è¿‘çš„äº¤æ˜“æ—¥ï¼ˆå‘åè°ƒæ•´ï¼‰
                adjusted_start = self.trade_date_manager.adjust_to_trade_date(start_date, direction='backward')
                if adjusted_start != start_date:
                    logger.info(f"è°ƒæ•´å¼€å§‹æ—¥æœŸ: {start_date} -> {adjusted_start}")
                    start_date = adjusted_start

                # è°ƒæ•´ç»“æŸæ—¥æœŸä¸ºæœ€è¿‘çš„äº¤æ˜“æ—¥ï¼ˆå‘å‰è°ƒæ•´ï¼‰
                adjusted_end = self.trade_date_manager.adjust_to_trade_date(end_date, direction='backward')
                if adjusted_end != end_date:
                    logger.info(f"è°ƒæ•´ç»“æŸæ—¥æœŸ: {end_date} -> {adjusted_end}")
                    end_date = adjusted_end
            else:
                # ä½¿ç”¨ä¸‹è½½å™¨çš„äº¤æ˜“æ—¥æ£€æŸ¥
                logger.debug("ä½¿ç”¨ä¸‹è½½å™¨çš„äº¤æ˜“æ—¥æ£€æŸ¥")
                # è¿™é‡Œä¾èµ–ä¸‹è½½å™¨å†…éƒ¨çš„äº¤æ˜“æ—¥è°ƒæ•´

            # éªŒè¯æ—¥æœŸèŒƒå›´
            try:
                start_dt = datetime.strptime(start_date, '%Y%m%d')
                end_dt = datetime.strptime(end_date, '%Y%m%d')

                if start_dt > end_dt:
                    logger.warning(f"å¼€å§‹æ—¥æœŸæ™šäºç»“æŸæ—¥æœŸï¼Œäº¤æ¢: {start_date} <-> {end_date}")
                    start_date, end_date = end_date, start_date

            except ValueError as e:
                logger.warning(f"æ—¥æœŸæ ¼å¼éªŒè¯å¤±è´¥: {e}")

            return start_date, end_date

        except Exception as e:
            logger.warning(f"æ—¥æœŸèŒƒå›´è°ƒæ•´å¤±è´¥: {e}, ä½¿ç”¨åŸå§‹èŒƒå›´")
            return start_date, end_date

    def update_single_symbol(self, symbol: str, mode: str = 'incremental',
                             start_date: str = None, end_date: str = None) -> Dict[str, Any]:
        """
        æ›´æ–°å•åªè‚¡ç¥¨çš„å› å­æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            mode: æ›´æ–°æ¨¡å¼ ('incremental', 'full', 'specific')
            start_date: ç‰¹å®šå¼€å§‹æ—¥æœŸ (ä»…mode='specific'æ—¶ä½¿ç”¨)
            end_date: ç‰¹å®šç»“æŸæ—¥æœŸ (ä»…mode='specific'æ—¶ä½¿ç”¨)

        Returns:
            æ›´æ–°ç»“æœå­—å…¸
        """
        result = {
            'symbol': symbol,
            'mode': mode,
            'status': 'pending',
            'records_downloaded': 0,
            'records_stored': 0,
            'error': None,
            'execution_time': 0
        }

        start_time = time.time()

        try:
            logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†: {symbol} ({mode}æ¨¡å¼)")

            # 1. ç¡®å®šä¸‹è½½èŒƒå›´
            if mode == 'incremental':
                # å¢é‡æ¨¡å¼ï¼šåŸºäºæ•°æ®åº“å·²æœ‰æ•°æ®
                download_range = self.storage.calculate_incremental_range(symbol)
                if not download_range or not download_range[0]:
                    result['status'] = 'no_update_needed'
                    result['reason'] = 'æ•°æ®å·²æœ€æ–°'
                    logger.info(f"  {symbol}: æ•°æ®å·²æœ€æ–°ï¼Œè·³è¿‡")
                    return result

                start_date, end_date = download_range

            elif mode == 'full':
                # å…¨é‡æ¨¡å¼ï¼šé»˜è®¤ä¸‹è½½æœ€è¿‘2å¹´æ•°æ®
                if not end_date:
                    end_date = datetime.now().strftime('%Y%m%d')
                if not start_date:
                    # é»˜è®¤ä¸‹è½½æœ€è¿‘2å¹´
                    start_date = (datetime.now() - timedelta(days=730)).strftime('%Y%m%d')

            elif mode == 'specific' and start_date and end_date:
                # ç‰¹å®šèŒƒå›´æ¨¡å¼
                pass
            else:
                raise ValueError(f"æ— æ•ˆçš„æ¨¡å¼æˆ–æ—¥æœŸå‚æ•°: mode={mode}, start_date={start_date}, end_date={end_date}")

            # 2. è°ƒæ•´æ—¥æœŸèŒƒå›´ä¸ºäº¤æ˜“æ—¥
            start_date, end_date = self._adjust_date_range(start_date, end_date)
            logger.info(f"  ä¸‹è½½èŒƒå›´: {start_date} - {end_date}")

            # 3. ä¸‹è½½å› å­æ•°æ®
            logger.info(f"  ä¸‹è½½å› å­æ•°æ®...")
            factor_data = self.downloader.fetch_factor_data(symbol, start_date, end_date)

            if factor_data.empty:
                result['status'] = 'no_data'
                logger.warning(f"  {symbol}: æ— æ•°æ®")
                return result

            result['records_downloaded'] = len(factor_data)
            logger.info(f"  ä¸‹è½½æˆåŠŸ: {len(factor_data)} æ¡è®°å½•")

            # 4. å­˜å‚¨æ•°æ®
            logger.info(f"  å­˜å‚¨å› å­æ•°æ®...")
            affected_rows, storage_report = self.storage.store_factor_data(factor_data)

            result['records_stored'] = affected_rows
            result['storage_report'] = storage_report

            if affected_rows > 0:
                result['status'] = 'success'
                logger.info(f"  âœ… å­˜å‚¨æˆåŠŸ: {affected_rows} æ¡è®°å½•")
            else:
                result['status'] = 'skipped'
                result['reason'] = 'æ•°æ®å·²å­˜åœ¨æˆ–æ— æ›´æ–°'
                logger.info(f"  âš ï¸  æ— æ–°è®°å½•: {symbol}")

            # 5. æ¸…ç†ç¼“å­˜
            self.storage.clear_cache(symbol)

        except Exception as e:
            result['status'] = 'error'
            result['error'] = str(e)
            logger.error(f"  âŒ å¤„ç†å¤±è´¥ {symbol}: {e}")

        finally:
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            result['execution_time'] = time.time() - start_time
            logger.info(f"  å¤„ç†å®Œæˆ: {symbol}, è€—æ—¶: {result['execution_time']:.2f}ç§’")

        return result

    def update_batch_symbols(self, symbols: List[str], mode: str = 'incremental',
                             start_date: str = None, end_date: str = None,
                             max_workers: int = 1) -> Dict[str, Any]:
        """
        æ‰¹é‡æ›´æ–°å¤šåªè‚¡ç¥¨çš„å› å­æ•°æ®

        æ³¨æ„ï¼šç”±äºBaostockå¹³å°é™åˆ¶ï¼Œè¿™é‡Œä¿æŒå•çº¿ç¨‹
        ä½†æ¥å£è®¾è®¡ä¸ºæ”¯æŒæœªæ¥å¤šçº¿ç¨‹æ‰©å±•

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            mode: æ›´æ–°æ¨¡å¼
            start_date: ç‰¹å®šå¼€å§‹æ—¥æœŸ
            end_date: ç‰¹å®šç»“æŸæ—¥æœŸ
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼ˆå½“å‰å›ºå®šä¸º1ï¼‰

        Returns:
            æ‰¹é‡å¤„ç†ç»“æœ
        """
        # å¼ºåˆ¶å•çº¿ç¨‹ï¼ˆBaostocké™åˆ¶ï¼‰
        max_workers = 1

        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡æ›´æ–°: {len(symbols)} åªè‚¡ç¥¨")
        logger.info(f"âš™ï¸  æ¨¡å¼: {mode}, çº¿ç¨‹æ•°: {max_workers}")

        self.stats = {
            'total_symbols': len(symbols),
            'successful': 0,
            'failed': 0,
            'no_data': 0,
            'total_records': 0,
            'start_time': datetime.now(),
            'end_time': None,
            'duration_seconds': 0
        }

        detailed_results = []

        # å•çº¿ç¨‹é¡ºåºå¤„ç†ï¼ˆéµå®ˆå¹³å°é™åˆ¶ï¼‰
        for i, symbol in enumerate(symbols, 1):
            try:
                logger.info(f"[{i}/{len(symbols)}] å¤„ç† {symbol}")

                # æ›´æ–°å•åªè‚¡ç¥¨
                result = self.update_single_symbol(symbol, mode, start_date, end_date)
                detailed_results.append(result)

                # æ›´æ–°ç»Ÿè®¡
                if result['status'] == 'success':
                    self.stats['successful'] += 1
                    self.stats['total_records'] += result.get('records_stored', 0)
                elif result['status'] == 'no_data':
                    self.stats['no_data'] += 1
                elif result['status'] == 'error':
                    self.stats['failed'] += 1

                # è¿›åº¦æ˜¾ç¤º
                progress = (i / len(symbols)) * 100
                logger.info(f"  è¿›åº¦: {progress:.1f}%")

            except Exception as e:
                logger.error(f"å¤„ç†è‚¡ç¥¨å¤±è´¥ {symbol}: {e}")
                self.stats['failed'] += 1
                detailed_results.append({
                    'symbol': symbol,
                    'status': 'error',
                    'error': str(e)
                })

        # å®Œæˆç»Ÿè®¡
        self.stats['end_time'] = datetime.now()
        self.stats['duration_seconds'] = (
                self.stats['end_time'] - self.stats['start_time']
        ).total_seconds()

        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_batch_report(detailed_results)

        logger.info(f"âœ… æ‰¹é‡æ›´æ–°å®Œæˆ")
        logger.info(
            f"   æˆåŠŸ: {self.stats['successful']}, å¤±è´¥: {self.stats['failed']}, æ— æ•°æ®: {self.stats['no_data']}")
        logger.info(f"   æ€»è®°å½•: {self.stats['total_records']}, è€—æ—¶: {self.stats['duration_seconds']:.2f}ç§’")

        return report

    def _generate_batch_report(self, detailed_results: List[Dict]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š
        """
        report = {
            'summary': {
                'total_symbols': len(detailed_results),
                'successful': sum(1 for r in detailed_results if r['status'] == 'success'),
                'failed': sum(1 for r in detailed_results if r['status'] == 'error'),
                'no_data': sum(1 for r in detailed_results if r['status'] == 'no_data'),
                'skipped': sum(1 for r in detailed_results if r['status'] == 'skipped'),
                'total_records': sum(r.get('records_stored', 0) for r in detailed_results)
            },
            'performance': {
                'start_time': self.stats['start_time'].isoformat(),
                'end_time': self.stats['end_time'].isoformat() if self.stats['end_time'] else None,
                'duration_seconds': self.stats['duration_seconds']
            },
            'detailed_results': detailed_results
        }

        return report

    def get_update_status(self, symbol: str = None) -> Dict[str, Any]:
        """
        è·å–æ›´æ–°çŠ¶æ€

        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ•´ä½“çŠ¶æ€

        Returns:
            çŠ¶æ€å­—å…¸
        """
        if symbol:
            # è·å–ç‰¹å®šè‚¡ç¥¨çš„æœ€åæ›´æ–°æ—¥æœŸ
            last_date = self.storage.get_last_factor_date(symbol)
            return {
                'symbol': symbol,
                'last_update_date': last_date,
                'has_data': last_date is not None,
                'update_needed': self._check_update_needed(symbol) if last_date else True
            }
        else:
            # è¿”å›æ•´ä½“ç»Ÿè®¡
            return {
                'total_symbols': self.stats['total_symbols'],
                'successful': self.stats['successful'],
                'failed': self.stats['failed'],
                'no_data': self.stats['no_data'],
                'total_records': self.stats['total_records'],
                'last_run': {
                    'start_time': self.stats['start_time'].isoformat() if self.stats['start_time'] else None,
                    'duration_seconds': self.stats['duration_seconds']
                }
            }

    def _check_update_needed(self, symbol: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        """
        try:
            start_date, end_date = self.storage.calculate_incremental_range(symbol)
            return start_date is not None and end_date is not None
        except Exception:
            return True


# æµ‹è¯•å‡½æ•°
def test_factor_data_pipeline():
    """æµ‹è¯•å› å­æ•°æ®ç®¡é“"""
    print("\nğŸ§ª æµ‹è¯•å› å­æ•°æ®ç®¡é“")
    print("=" * 50)

    try:
        # 1. åˆå§‹åŒ–
        print("åˆå§‹åŒ–FactorDataPipeline...")
        pipeline = FactorDataPipeline()
        print("âœ… åˆå§‹åŒ–æˆåŠŸ")

        # 2. æµ‹è¯•å•åªè‚¡ç¥¨å¢é‡æ›´æ–°
        print("\næµ‹è¯•å•åªè‚¡ç¥¨å¢é‡æ›´æ–°...")
        test_symbol = '600519'  # è´µå·èŒ…å°

        result = pipeline.update_single_symbol(test_symbol, mode='incremental')

        print(f"æ›´æ–°ç»“æœ:")
        print(f"  çŠ¶æ€: {result['status']}")
        print(f"  ä¸‹è½½è®°å½•: {result.get('records_downloaded', 0)}")
        print(f"  å­˜å‚¨è®°å½•: {result.get('records_stored', 0)}")
        print(f"  è€—æ—¶: {result.get('execution_time', 0):.2f}ç§’")

        if result['status'] == 'error':
            print(f"  é”™è¯¯: {result.get('error', 'Unknown')}")

        # 3. æµ‹è¯•çŠ¶æ€æŸ¥è¯¢
        print("\næµ‹è¯•çŠ¶æ€æŸ¥è¯¢...")
        status = pipeline.get_update_status(test_symbol)
        print(f"çŠ¶æ€ä¿¡æ¯:")
        for key, value in status.items():
            print(f"  {key}: {value}")

        # 4. æµ‹è¯•æ—¥æœŸèŒƒå›´è°ƒæ•´
        print("\næµ‹è¯•æ—¥æœŸèŒƒå›´è°ƒæ•´...")
        test_start = '20260101'  # éäº¤æ˜“æ—¥ï¼ˆå…ƒæ—¦ï¼‰
        test_end = '20260103'  # éäº¤æ˜“æ—¥ï¼ˆå‘¨æœ«ï¼‰

        adjusted_start, adjusted_end = pipeline._adjust_date_range(test_start, test_end)
        print(f"åŸå§‹èŒƒå›´: {test_start} - {test_end}")
        print(f"è°ƒæ•´å: {adjusted_start} - {adjusted_end}")

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_factor_data_pipeline()

    if success:
        print("\nâœ… å› å­æ•°æ®ç®¡é“æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ å› å­æ•°æ®ç®¡é“æµ‹è¯•å¤±è´¥")

    exit(0 if success else 1)