# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/src/data\enhanced_processor.py
# File Name: enhanced_processor
# @ Author: mango-gh22
# @ Dateï¼š2025/12/10 18:55
"""
desc åˆ›å»º EnhancedDataProcessor

å¢å¼ºç‰ˆæ•°æ®å¤„ç†å™¨ - å®Œå…¨é›†æˆç°æœ‰æ¶æ„
é›†æˆ db_connector, data_manager, config_loader, code_converter
ä¿®å¤å·²çŸ¥é—®é¢˜ï¼šfillnaå¼ƒç”¨æ–¹æ³•ã€MAè®¡ç®—é—®é¢˜
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    # å¯¼å…¥ç°æœ‰æ¶æ„æ¨¡å—
    from src.database.db_connector import DatabaseConnector
    from src.data.data_manager import DataManager
    from src.config.config_loader import load_tushare_config
    from src.utils.code_converter import normalize_stock_code
    from src.utils.logger import get_logger  # ä½¿ç”¨ç°æœ‰çš„get_logger
    from src.config.secret_loader import get_db_password
    from src.config.config_loader import load_database_config
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("å°è¯•åˆ›å»ºç¼ºå¤±çš„æ¨¡å—...")
    # åˆ›å»ºç®€åŒ–çš„æ¨¡å—ä¾›æµ‹è¯•
    pass


# åˆ›å»ºç®€åŒ–çš„æ¨¡å—ç»“æ„ä¾›æµ‹è¯•ï¼ˆå¦‚æœå¯¼å…¥å¤±è´¥ï¼‰
class MockCodeConverter:
    @staticmethod
    def to_database_format(code: str) -> str:
        """ç®€åŒ–ç‰ˆæœ¬"""
        if '.' in code:
            parts = code.split('.')
            if len(parts) == 2:
                return f"{parts[1].lower()}{parts[0]}"
        return code


class MockLogger:
    def __init__(self, name):
        self.name = name

    def info(self, msg):
        print(f"[INFO] {msg}")

    def warning(self, msg):
        print(f"[WARNING] {msg}")

    def error(self, msg):
        print(f"[ERROR] {msg}")

    def debug(self, msg):
        print(f"[DEBUG] {msg}")


def get_logger(name):
    return MockLogger(name)


class EnhancedDataProcessor:
    """å¢å¼ºç‰ˆæ•°æ®å¤„ç†å™¨ - ä¸ç°æœ‰æ¶æ„å®Œå…¨é›†æˆ"""

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–å¤„ç†å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨é¡¹ç›®é…ç½®
        """
        # 1. åˆå§‹åŒ–æ—¥å¿—ï¼ˆä½¿ç”¨ç°æœ‰çš„get_loggerï¼‰
        self.logger = get_logger(__name__)

        # 2. åŠ è½½é…ç½®ï¼ˆä½¿ç”¨ç°æœ‰æ¶æ„ï¼‰
        self.config = self._load_configurations(config_path)

        # 3. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ˆå¯é€‰ï¼‰
        self.db_connector = None
        try:
            self.db_connector = DatabaseConnector()
            self.logger.info("æ•°æ®åº“è¿æ¥å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.warning(f"æ•°æ®åº“è¿æ¥å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        # 4. è´¨é‡é˜ˆå€¼ï¼ˆä¸data_managerä¿æŒä¸€è‡´ï¼‰
        self.quality_thresholds = {
            'excellent': 90,
            'good': 70,
            'fair': 50,
            'poor': 30
        }

        # 5. æŠ€æœ¯æŒ‡æ ‡é…ç½®
        self.indicators_config = self._load_indicators_config()

        self.logger.info("å¢å¼ºç‰ˆæ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _load_configurations(self, config_path: Optional[str] = None) -> Dict:
        """åŠ è½½æ‰€æœ‰é…ç½® - é›†æˆç°æœ‰é…ç½®ç³»ç»Ÿ"""
        config = {
            'database': {},
            'tushare': {},
            'processor': {}
        }

        try:
            # å°è¯•åŠ è½½æ•°æ®åº“é…ç½®
            try:
                db_config = load_database_config()
                config['database'] = db_config
            except:
                config['database'] = self._get_default_db_config()

            # å°è¯•åŠ è½½Tushareé…ç½®
            try:
                tushare_config = load_tushare_config()
                config['tushare'] = tushare_config
            except:
                config['tushare'] = {}

            # å¤„ç†å™¨ç‰¹å®šé…ç½®
            config['processor'] = {
                'clean_rules': {
                    'min_price': 0.01,
                    'max_price': 1000000,
                    'min_volume': 0
                },
                'indicators': {
                    'ma_periods': [5, 10, 20, 30, 60, 120, 250],
                    'volume_ma_periods': [5, 10, 20],
                    'min_data_points': 5
                }
            }

        except Exception as e:
            self.logger.warning(f"é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            config = self._get_default_config()

        return config

    def _get_default_db_config(self) -> Dict:
        """è·å–é»˜è®¤æ•°æ®åº“é…ç½®"""
        return {
            'host': 'localhost',
            'port': 3306,
            'user': 'root',
            'database': 'stock_database',
            'charset': 'utf8mb4',
            'pool_size': 5
        }

    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'database': self._get_default_db_config(),
            'processor': {
                'clean_rules': {
                    'min_price': 0.01,
                    'max_price': 1000000,
                    'min_volume': 0
                },
                'indicators': {
                    'ma_periods': [5, 10, 20, 30, 60, 120, 250],
                    'volume_ma_periods': [5, 10, 20],
                    'min_data_points': 5
                }
            }
        }

    def _load_indicators_config(self) -> Dict:
        """åŠ è½½æŠ€æœ¯æŒ‡æ ‡é…ç½®"""
        return {
            'ma_periods': [5, 10, 20, 30, 60, 120, 250],
            'volume_ma_periods': [5, 10, 20],
            'advanced_indicators': {
                'rsi_period': 14,
                'bb_period': 20,
                'bb_std': 2,
                'atr_period': 14
            }
        }

    def clean_data(self, df: pd.DataFrame, symbol: Optional[str] = None) -> pd.DataFrame:
        """
        æ•°æ®æ¸…æ´— - ä¿®å¤å¼ƒç”¨æ–¹æ³•ï¼Œé›†æˆç°æœ‰è§„åˆ™

        Args:
            df: åŸå§‹DataFrame
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            æ¸…æ´—åçš„DataFrame
        """
        if df.empty:
            self.logger.warning(f"ç©ºæ•°æ®: {symbol or 'unknown'}")
            return df

        df_clean = df.copy()
        original_count = len(df_clean)

        self.logger.info(f"å¼€å§‹æ•°æ®æ¸…æ´—: {symbol}, åŸå§‹æ•°æ®{original_count}æ¡")

        # 1. ä¿®å¤å¼ƒç”¨çš„fillnaæ–¹æ³• - ä½¿ç”¨ffill().bfill()æ›¿æ¢
        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns

        for col in numeric_cols:
            if col in df_clean.columns:
                # ä¿®å¤ï¼šä½¿ç”¨ffill().bfill()æ›¿æ¢å¼ƒç”¨çš„fillna(method='...')
                try:
                    # å…ˆå°è¯•å‰å‘å¡«å……ï¼Œå†åå‘å¡«å……
                    df_clean[col] = df_clean[col].ffill().bfill()
                except Exception as e:
                    self.logger.warning(f"åˆ—{col}å¡«å……å¤±è´¥: {e}")

        # 2. ä»·æ ¼æœ‰æ•ˆæ€§æ£€æŸ¥
        price_cols = ['open', 'high', 'low', 'close', 'pre_close']
        available_price_cols = [col for col in price_cols if col in df_clean.columns]

        if available_price_cols:
            min_price = self.config['processor']['clean_rules']['min_price']
            max_price = self.config['processor']['clean_rules']['max_price']

            # åˆ›å»ºæœ‰æ•ˆä»·æ ¼æ©ç 
            valid_mask = pd.Series(True, index=df_clean.index)
            for col in available_price_cols:
                col_mask = (df_clean[col] >= min_price) & (df_clean[col] <= max_price)
                invalid_count = (~col_mask).sum()
                if invalid_count > 0:
                    self.logger.warning(
                        f"ç§»é™¤{invalid_count}æ¡æ— æ•ˆ{col}æ•°æ®: {symbol}"
                    )
                valid_mask = valid_mask & col_mask

            df_clean = df_clean[valid_mask]

        # 3. é€»è¾‘ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆhigh >= low, high >= close, low <= closeï¼‰
        if all(col in df_clean.columns for col in ['high', 'low', 'close']):
            logic_mask = (
                    (df_clean['high'] >= df_clean['low']) &
                    (df_clean['high'] >= df_clean['close']) &
                    (df_clean['low'] <= df_clean['close'])
            )
            invalid_logic = (~logic_mask).sum()
            if invalid_logic > 0:
                self.logger.warning(
                    f"ç§»é™¤{invalid_logic}æ¡é€»è¾‘ä¸ä¸€è‡´æ•°æ®: {symbol}"
                )
                df_clean = df_clean[logic_mask]

        # 4. æˆäº¤é‡æ£€æŸ¥
        if 'volume' in df_clean.columns:
            min_volume = self.config['processor']['clean_rules']['min_volume']
            volume_mask = df_clean['volume'] >= min_volume
            invalid_volume = (~volume_mask).sum()
            if invalid_volume > 0:
                self.logger.warning(
                    f"ç§»é™¤{invalid_volume}æ¡æ— æ•ˆæˆäº¤é‡æ•°æ®: {symbol}"
                )
                df_clean = df_clean[volume_mask]

        # 5. ç§»é™¤é‡å¤æ—¥æœŸ
        if 'trade_date' in df_clean.columns:
            duplicates = df_clean.duplicated(subset=['trade_date'], keep='last')
            if duplicates.any():
                dup_count = duplicates.sum()
                self.logger.warning(f"ç§»é™¤{dup_count}æ¡é‡å¤æ—¥æœŸæ•°æ®: {symbol}")
                df_clean = df_clean[~duplicates]

        cleaned_count = len(df_clean)
        removed_count = original_count - cleaned_count

        if removed_count > 0:
            self.logger.info(
                f"æ•°æ®æ¸…æ´—å®Œæˆ: {symbol}, "
                f"ç§»é™¤{removed_count}æ¡, ä¿ç•™{cleaned_count}æ¡"
            )
        else:
            self.logger.info(f"æ•°æ®æ¸…æ´—å®Œæˆ: {symbol}, æ‰€æœ‰æ•°æ®æœ‰æ•ˆ")

        return df_clean

    def calculate_technical_indicators(
            self,
            df: pd.DataFrame,
            symbol: Optional[str] = None,
            min_data_points: Optional[int] = None
    ) -> pd.DataFrame:
        """
        è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ - ä¿®å¤åˆ—åé—®é¢˜
        """
        if df.empty:
            self.logger.warning(f"ç©ºæ•°æ®ï¼Œè·³è¿‡æŒ‡æ ‡è®¡ç®—: {symbol or 'unknown'}")
            return df

        if min_data_points is None:
            min_data_points = self.config['processor']['indicators']['min_data_points']

        df_calc = df.copy()
        self.logger.info(f"å¼€å§‹è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: {symbol}, {len(df_calc)}æ¡æ•°æ®")

        # ç¡®ä¿æŒ‰æ—¥æœŸæ’åº
        if 'trade_date' in df_calc.columns:
            df_calc = df_calc.sort_values('trade_date').reset_index(drop=True)

        # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ
        if len(df_calc) < min_data_points:
            self.logger.warning(
                f"æ•°æ®ä¸è¶³{min_data_points}æ¡ï¼Œè·³è¿‡æŠ€æœ¯æŒ‡æ ‡è®¡ç®—: {symbol}"
            )
            return df_calc

        # ä¿®å¤ï¼šæ£€æŸ¥åˆ—åï¼Œæ”¯æŒå¤šç§å‘½åæ ¼å¼
        close_col = None
        for col_name in ['close', 'close_price', 'close_price']:
            if col_name in df_calc.columns:
                close_col = col_name
                break

        if close_col is None:
            self.logger.warning(f"æ‰¾ä¸åˆ°æ”¶ç›˜ä»·åˆ—ï¼Œè·³è¿‡æŠ€æœ¯æŒ‡æ ‡è®¡ç®—: {symbol}")
            return df_calc

        # ä¿®å¤ï¼šä½¿ç”¨æ‰¾åˆ°çš„åˆ—å
        # è®¡ç®—æ¶¨è·Œå¹…ï¼ˆå¦‚æœåŸºç¡€æ•°æ®å­˜åœ¨ï¼‰
        pre_close_col = None
        for col_name in ['pre_close', 'pre_close_price', 'preclose']:
            if col_name in df_calc.columns:
                pre_close_col = col_name
                break

        if pre_close_col:
            df_calc['pct_change'] = (
                    (df_calc[close_col] - df_calc[pre_close_col]) /
                    df_calc[pre_close_col].replace(0, np.nan) * 100
            ).round(2)
            # å¤„ç†é™¤é›¶é”™è¯¯
            df_calc['pct_change'] = df_calc['pct_change'].replace([np.inf, -np.inf], np.nan)

        # è®¡ç®—æŒ¯å¹…
        high_col = None
        low_col = None
        for col_name in ['high', 'high_price']:
            if col_name in df_calc.columns:
                high_col = col_name
                break

        for col_name in ['low', 'low_price']:
            if col_name in df_calc.columns:
                low_col = col_name
                break

        if high_col and low_col and pre_close_col:
            df_calc['amplitude'] = (
                    (df_calc[high_col] - df_calc[low_col]) /
                    df_calc[pre_close_col].replace(0, np.nan) * 100
            ).round(2)
            df_calc['amplitude'] = df_calc['amplitude'].replace([np.inf, -np.inf], np.nan)

        # ä¿®å¤ï¼šMAè®¡ç®— - ä½¿ç”¨æ­£ç¡®çš„åˆ—å
        ma_periods = self.indicators_config['ma_periods']

        for period in ma_periods:
            col_name = f'ma{period}'
            if len(df_calc) >= period:
                # å……è¶³æ•°æ®ï¼Œè®¡ç®—å®Œæ•´MA
                df_calc[col_name] = df_calc[close_col].rolling(
                    window=period,
                    min_periods=1
                ).mean().round(2)
            else:
                # æ•°æ®ä¸è¶³ï¼Œè®¡ç®—å¯ç”¨çš„æœ€å¤§å€¼
                available_period = min(period, len(df_calc))
                df_calc[col_name] = df_calc[close_col].rolling(
                    window=available_period,
                    min_periods=1
                ).mean().round(2)
                if period > 5:  # åªå¯¹é•¿å‘¨æœŸè®°å½•è­¦å‘Š
                    self.logger.debug(
                        f"MA{period}ä½¿ç”¨{available_period}æ¡æ•°æ®è®¡ç®—: {symbol}"
                    )

        # æˆäº¤é‡å‡çº¿
        volume_periods = self.indicators_config['volume_ma_periods']
        volume_col = None
        for col_name in ['volume', 'vol']:
            if col_name in df_calc.columns:
                volume_col = col_name
                break

        if volume_col:
            for period in volume_periods:
                col_name = f'volume_ma{period}'
                if len(df_calc) >= period:
                    df_calc[col_name] = df_calc[volume_col].rolling(
                        window=period,
                        min_periods=1
                    ).mean().round(0)
                else:
                    available_period = min(period, len(df_calc))
                    df_calc[col_name] = df_calc[volume_col].rolling(
                        window=available_period,
                        min_periods=1
                    ).mean().round(0)

        # é«˜çº§æŒ‡æ ‡ï¼ˆå¯é€‰ï¼‰
        if len(df_calc) >= 14:  # RSIéœ€è¦è‡³å°‘14ä¸ªå‘¨æœŸ
            try:
                self._calculate_advanced_indicators(df_calc, close_col)
                self.logger.debug(f"é«˜çº§æŒ‡æ ‡è®¡ç®—å®Œæˆ: {symbol}")
            except Exception as e:
                self.logger.warning(f"é«˜çº§æŒ‡æ ‡è®¡ç®—å¤±è´¥: {symbol}, é”™è¯¯: {e}")

        self.logger.info(
            f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ: {symbol}, {len(df_calc)}æ¡è®°å½•"
        )

        return df_calc

    def _calculate_advanced_indicators(self, df: pd.DataFrame, close_col: str = 'close'):
        """è®¡ç®—é«˜çº§æŠ€æœ¯æŒ‡æ ‡"""
        # RSI (14å¤©)
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi'].clip(0, 100).round(2)

        # å¸ƒæ—å¸¦ (20å¤©ï¼Œ2ä¸ªæ ‡å‡†å·®)
        df['bb_middle'] = df[close_col].rolling(window=20).mean()
        bb_std = df[close_col].rolling(window=20).std()
        df['bb_upper'] = df['bb_middle'] + 2 * bb_std
        df['bb_lower'] = df['bb_middle'] - 2 * bb_std

        # 20æ—¥æ³¢åŠ¨ç‡
        df['returns'] = df[close_col].pct_change()
        df['volatility_20d'] = df['returns'].rolling(window=20).std() * np.sqrt(252)
        df['volatility_20d'] = df['volatility_20d'].round(4)

        # æ¸…ç†ä¸´æ—¶åˆ—
        if 'returns' in df.columns:
            df.drop('returns', axis=1, inplace=True)

    def assess_data_quality(self, df: pd.DataFrame, symbol: str) -> Dict:
        """
        æ•°æ®è´¨é‡è¯„ä¼° - ä¸data_managerè´¨é‡æ ‡å‡†ä¸€è‡´

        Args:
            df: å¾…è¯„ä¼°æ•°æ®
            symbol: è‚¡ç¥¨ä»£ç 

        Returns:
            è´¨é‡è¯„ä¼°æŠ¥å‘Š
        """
        if df.empty:
            return {
                'symbol': symbol,
                'total_score': 0,
                'grade': 'poor',
                'status': 'EMPTY_DATA',
                'issues': ['ç©ºæ•°æ®'],
                'record_count': 0,
                'assessment_time': datetime.now().isoformat()
            }

        scores = {}

        # 1. å®Œæ•´æ€§ (30%)
        completeness = self._calculate_completeness_score(df)
        scores['completeness'] = completeness

        # 2. å‡†ç¡®æ€§ (40%)
        accuracy = self._calculate_accuracy_score(df)
        scores['accuracy'] = accuracy

        # 3. ä¸€è‡´æ€§ (20%)
        consistency = self._calculate_consistency_score(df)
        scores['consistency'] = consistency

        # 4. åŠæ—¶æ€§ (10%)
        timeliness = self._calculate_timeliness_score(df)
        scores['timeliness'] = timeliness

        # åŠ æƒæ€»åˆ†
        weights = {'completeness': 0.3, 'accuracy': 0.4,
                   'consistency': 0.2, 'timeliness': 0.1}
        total_score = sum(scores[k] * weights[k] for k in weights)
        total_score = round(total_score, 2)

        # ç¡®å®šè´¨é‡ç­‰çº§
        grade = self._score_to_grade(total_score)

        # è¯†åˆ«é—®é¢˜
        issues = self._identify_quality_issues(df, scores)

        return {
            'symbol': symbol,
            'total_score': total_score,
            'grade': grade,
            'scores': scores,
            'issues': issues,
            'record_count': len(df),
            'assessment_time': datetime.now().isoformat()
        }

    def _calculate_completeness_score(self, df: pd.DataFrame) -> float:
        """è®¡ç®—å®Œæ•´æ€§åˆ†æ•°"""
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        available_cols = [col for col in required_cols if col in df.columns]

        if not available_cols:
            return 0.0

        # å­—æ®µå­˜åœ¨ç‡
        field_score = len(available_cols) / len(required_cols) * 100

        # ç¼ºå¤±å€¼ç‡
        missing_rates = []
        for col in available_cols:
            if col in df.columns:
                missing_rate = df[col].isnull().mean()
                missing_rates.append(missing_rate)

        missing_score = 100 - (sum(missing_rates) / len(missing_rates) * 100) if missing_rates else 100

        # ç»¼åˆåˆ†æ•°
        completeness_score = (field_score * 0.5 + missing_score * 0.5)
        return round(completeness_score, 2)

    def _calculate_accuracy_score(self, df: pd.DataFrame) -> float:
        """è®¡ç®—å‡†ç¡®æ€§åˆ†æ•°"""
        accuracy_items = []

        # 1. ä»·æ ¼æœ‰æ•ˆæ€§
        price_cols = [col for col in ['open', 'high', 'low', 'close'] if col in df.columns]
        if price_cols:
            valid_prices = []
            for col in price_cols:
                valid_ratio = ((df[col] > 0) & (df[col] < 1e6)).mean()
                valid_prices.append(valid_ratio * 100)
            price_score = sum(valid_prices) / len(valid_prices) if valid_prices else 100
            accuracy_items.append(price_score)

        # 2. é€»è¾‘ä¸€è‡´æ€§
        if all(col in df.columns for col in ['high', 'low']):
            logic_ratio = (df['high'] >= df['low']).mean() * 100
            accuracy_items.append(logic_ratio)

        # 3. æˆäº¤é‡æœ‰æ•ˆæ€§
        if 'volume' in df.columns:
            volume_ratio = (df['volume'] >= 0).mean() * 100
            accuracy_items.append(volume_ratio)

        accuracy_score = sum(accuracy_items) / len(accuracy_items) if accuracy_items else 100
        return round(accuracy_score, 2)

    def _calculate_consistency_score(self, df: pd.DataFrame) -> float:
        """è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°"""
        consistency_items = []

        # 1. æ—¥æœŸè¿ç»­æ€§
        if 'trade_date' in df.columns:
            try:
                dates = pd.to_datetime(df['trade_date'])
                date_diff = dates.diff().dt.days
                # æ£€æŸ¥æ˜¯å¦è¿ç»­ï¼ˆå…è®¸å‘¨æœ«é—´éš”ï¼‰
                is_weekday = dates.dt.weekday < 5
                expected_diff = 1  # æœŸæœ›äº¤æ˜“æ—¥é—´éš”ä¸º1å¤©
                # è®¡ç®—è¿ç»­æ€§åˆ†æ•°
                if len(date_diff) > 1:
                    continuity_ratio = (date_diff[1:] <= 3).mean() * 100  # å…è®¸æœ€å¤š3å¤©é—´éš”
                    consistency_items.append(continuity_ratio)
            except:
                pass

        # 2. æ•°æ®ä¸€è‡´æ€§
        if 'pct_change' in df.columns and 'amplitude' in df.columns:
            # æ¶¨è·Œå¹…å’ŒæŒ¯å¹…åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
            pct_change_valid = ((df['pct_change'].abs() <= 20) | df['pct_change'].isna()).mean() * 100
            amplitude_valid = ((df['amplitude'] <= 30) | df['amplitude'].isna()).mean() * 100
            consistency_items.extend([pct_change_valid, amplitude_valid])

        consistency_score = sum(consistency_items) / len(consistency_items) if consistency_items else 100
        return round(consistency_score, 2)

    def _calculate_timeliness_score(self, df: pd.DataFrame) -> float:
        """è®¡ç®—åŠæ—¶æ€§åˆ†æ•°"""
        if 'trade_date' not in df.columns:
            return 100.0

        try:
            dates = pd.to_datetime(df['trade_date'])
            latest_date = dates.max()
            days_diff = (datetime.now() - latest_date).days

            if days_diff <= 1:
                return 100.0
            elif days_diff <= 3:
                return 80.0
            elif days_diff <= 7:
                return 60.0
            elif days_diff <= 30:
                return 40.0
            else:
                return 20.0
        except:
            return 100.0

    def _score_to_grade(self, score: float) -> str:
        """åˆ†æ•°è½¬ç­‰çº§ - ä¸data_managerä¸€è‡´"""
        if score >= self.quality_thresholds['excellent']:
            return 'excellent'
        elif score >= self.quality_thresholds['good']:
            return 'good'
        elif score >= self.quality_thresholds['fair']:
            return 'fair'
        else:
            return 'poor'

    def _identify_quality_issues(self, df: pd.DataFrame, scores: Dict) -> List[str]:
        """è¯†åˆ«è´¨é‡é—®é¢˜"""
        issues = []

        if scores.get('completeness', 100) < 80:
            issues.append('æ•°æ®å®Œæ•´æ€§ä¸è¶³')

        if scores.get('accuracy', 100) < 80:
            issues.append('æ•°æ®å‡†ç¡®æ€§å¯ç–‘')

        if scores.get('consistency', 100) < 80:
            issues.append('æ•°æ®ä¸€è‡´æ€§å·®')

        if scores.get('timeliness', 100) < 60:
            issues.append('æ•°æ®ä¸å¤ŸåŠæ—¶')

        # æ£€æŸ¥å…·ä½“é—®é¢˜
        if 'close' in df.columns:
            if df['close'].isnull().any():
                issues.append('å­˜åœ¨ç¼ºå¤±çš„æ”¶ç›˜ä»·')

            if (df['close'] <= 0).any():
                issues.append('å­˜åœ¨éæ­£æ”¶ç›˜ä»·')

        return issues

    def prepare_for_storage(
            self,
            df: pd.DataFrame,
            symbol: str,
            data_source: str = 'baostock'
    ) -> pd.DataFrame:
        """
        å‡†å¤‡æ•°æ®å­˜å‚¨ - æ ‡å‡†åŒ–åˆ—åå’Œæ ¼å¼

        Args:
            df: å¤„ç†åçš„æ•°æ®
            symbol: è‚¡ç¥¨ä»£ç 
            data_source: æ•°æ®æº

        Returns:
            é€‚åˆæ•°æ®åº“å­˜å‚¨çš„DataFrame
        """
        if df.empty:
            self.logger.warning(f"ç©ºæ•°æ®ï¼Œè·³è¿‡å­˜å‚¨å‡†å¤‡: {symbol}")
            return df

        df_storage = df.copy()

        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        try:
            standardized_symbol = normalize_stock_code(symbol)
        except:
            standardized_symbol = symbol
            self.logger.warning(f"ä»£ç æ ‡å‡†åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ä»£ç : {symbol}")

        # æ·»åŠ å…ƒæ•°æ®
        df_storage['symbol'] = standardized_symbol
        df_storage['processed_time'] = datetime.now()
        df_storage['data_source'] = data_source
        df_storage['quality_grade'] = 'pending'  # å°†åœ¨è´¨æ£€åæ›´æ–°

        # æ ‡å‡†åŒ–åˆ—åï¼ˆåŒ¹é…æ•°æ®åº“è¡¨ç»“æ„ï¼‰
        column_mapping = {
            'trade_date': 'trade_date',
            'ts_code': 'symbol',  # å¦‚æœå·²æœ‰ts_code
            'open': 'open_price',
            'high': 'high_price',
            'low': 'low_price',
            'close': 'close_price',
            'pre_close': 'pre_close_price',
            'change': 'change',  # æ¶¨è·Œé¢
            'pct_change': 'change_percent',
            'volume': 'volume',
            'amount': 'amount',
            'amplitude': 'amplitude',
            'turnover_rate': 'turnover_rate',
            'turnover_rate_f': 'turnover_rate_f',
            'volume_ratio': 'volume_ratio',
            'pe': 'pe',
            'pe_ttm': 'pe_ttm',
            'pb': 'pb',
            'ps': 'ps',
            'ps_ttm': 'ps_ttm',
            'dv_ratio': 'dv_ratio',
            'dv_ttm': 'dv_ttm',
            'total_share': 'total_share',
            'float_share': 'float_share',
            'free_share': 'free_share',
            'total_mv': 'total_mv',
            'circ_mv': 'circ_mv'
        }

        # é‡å‘½ååˆ—
        rename_dict = {}
        for old_col, new_col in column_mapping.items():
            if old_col in df_storage.columns and old_col != new_col:
                rename_dict[old_col] = new_col

        if rename_dict:
            df_storage = df_storage.rename(columns=rename_dict)

        # ç¡®ä¿æ—¥æœŸæ ¼å¼
        if 'trade_date' in df_storage.columns:
            try:
                # å°è¯•è½¬æ¢ä¸ºYYYYMMDDæ ¼å¼
                df_storage['trade_date'] = pd.to_datetime(
                    df_storage['trade_date']
                ).dt.strftime('%Y%m%d')
            except:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·
                pass

        # ç¡®ä¿æ•°å€¼åˆ—ç±»å‹
        numeric_cols = [
            'open_price', 'high_price', 'low_price', 'close_price',
            'pre_close_price', 'volume', 'amount', 'change_percent',
            'amplitude', 'ma5', 'ma10', 'ma20', 'ma30', 'ma60', 'ma120', 'ma250'
        ]

        for col in numeric_cols:
            if col in df_storage.columns:
                df_storage[col] = pd.to_numeric(df_storage[col], errors='coerce')

        self.logger.info(
            f"å­˜å‚¨å‡†å¤‡å®Œæˆ: {symbol}, {len(df_storage)}æ¡è®°å½•, {len(df_storage.columns)}åˆ—"
        )

        return df_storage

    def process_stock_data(
            self,
            raw_df: pd.DataFrame,
            symbol: str,
            data_source: str = 'baostock'
    ) -> Tuple[pd.DataFrame, Dict]:
        """
        å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹

        Args:
            raw_df: åŸå§‹æ•°æ®
            symbol: è‚¡ç¥¨ä»£ç 
            data_source: æ•°æ®æº

        Returns:
            (å¤„ç†åçš„DataFrame, è´¨é‡æŠ¥å‘Š)
        """
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†è‚¡ç¥¨æ•°æ®: {symbol}")

            # 1. æ¸…æ´—æ•°æ®
            df_clean = self.clean_data(raw_df, symbol)

            if df_clean.empty:
                self.logger.warning(f"æ¸…æ´—åæ•°æ®ä¸ºç©º: {symbol}")
                return pd.DataFrame(), {
                    'symbol': symbol,
                    'total_score': 0,
                    'grade': 'poor',
                    'status': 'CLEANED_EMPTY',
                    'issues': ['æ¸…æ´—åæ— æ•°æ®']
                }

            # 2. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            df_with_indicators = self.calculate_technical_indicators(
                df_clean, symbol
            )

            # 3. è´¨é‡è¯„ä¼°
            quality_report = self.assess_data_quality(
                df_with_indicators, symbol
            )

            # 4. å‡†å¤‡å­˜å‚¨
            df_final = self.prepare_for_storage(
                df_with_indicators, symbol, data_source
            )

            # æ›´æ–°è´¨é‡ç­‰çº§
            if not df_final.empty and 'quality_grade' in df_final.columns:
                df_final['quality_grade'] = quality_report['grade']

            self.logger.info(
                f"å¤„ç†å®Œæˆ: {symbol}, "
                f"è´¨é‡: {quality_report['grade']} ({quality_report['total_score']}åˆ†), "
                f"è®°å½•: {len(df_final)}æ¡"
            )

            return df_final, quality_report

        except Exception as e:
            self.logger.error(f"å¤„ç†å¤±è´¥: {symbol}, é”™è¯¯: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            raise


def create_test_data() -> pd.DataFrame:
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    dates = pd.date_range('2024-01-01', periods=31, freq='D')

    # åˆ›å»ºåŸºæœ¬ä»·æ ¼æ•°æ®
    base_price = 100.0
    returns = np.random.normal(0.001, 0.02, 31)  # æ—¥æ”¶ç›Šç‡
    prices = base_price * (1 + np.cumsum(returns))

    df = pd.DataFrame({
        'trade_date': dates.strftime('%Y%m%d'),
        'open': prices * (1 + np.random.uniform(-0.01, 0.01, 31)),
        'high': prices * (1 + np.random.uniform(0, 0.03, 31)),
        'low': prices * (1 + np.random.uniform(-0.03, 0, 31)),
        'close': prices,
        'pre_close': np.roll(prices, 1),
        'volume': np.random.randint(1000000, 10000000, 31),
        'amount': prices * np.random.randint(1000000, 10000000, 31) / 10000
    })

    # è®¾ç½®ç¬¬ä¸€æ¡çš„pre_closeä¸ºclose
    df.loc[0, 'pre_close'] = df.loc[0, 'close'] * 0.99

    return df


def test_enhanced_processor():
    """æµ‹è¯•å¢å¼ºç‰ˆå¤„ç†å™¨"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºç‰ˆæ•°æ®å¤„ç†å™¨")
    print("=" * 50)

    try:
        # 1. åˆå§‹åŒ–å¤„ç†å™¨
        processor = EnhancedDataProcessor()
        print("âœ… å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")

        # 2. åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = create_test_data()
        print(f"ğŸ“Š åˆ›å»ºæµ‹è¯•æ•°æ®: {len(test_data)} æ¡è®°å½•")
        print(f"   æ—¥æœŸèŒƒå›´: {test_data['trade_date'].iloc[0]} åˆ° {test_data['trade_date'].iloc[-1]}")

        # 3. æµ‹è¯•å®Œæ•´æµç¨‹
        symbol = 'sh600519'
        print(f"ğŸ”§ å¼€å§‹å¤„ç†: {symbol}")

        df_processed, quality_report = processor.process_stock_data(
            test_data, symbol, 'test'
        )

        print(f"âœ… å¤„ç†å®Œæˆ: {len(df_processed)} æ¡è®°å½•")
        print(f"ğŸ“ˆ è´¨é‡æŠ¥å‘Š:")
        print(f"   ç­‰çº§: {quality_report['grade']}")
        print(f"   åˆ†æ•°: {quality_report['total_score']}")
        print(f"   å„ç»´åº¦åˆ†æ•°: {quality_report['scores']}")
        if quality_report['issues']:
            print(f"   é—®é¢˜: {', '.join(quality_report['issues'])}")

        # 4. æ˜¾ç¤ºæ•°æ®ç¤ºä¾‹
        if not df_processed.empty:
            print("ğŸ“‹ æ•°æ®ç¤ºä¾‹ (å‰3æ¡):")
            sample_cols = ['trade_date', 'close_price', 'change_percent', 'ma5', 'volume']
            available_cols = [col for col in sample_cols if col in df_processed.columns]

            for i in range(min(3, len(df_processed))):
                row = df_processed.iloc[i]
                info_parts = []
                for col in available_cols:
                    val = row[col]
                    if isinstance(val, (int, np.integer)):
                        info_parts.append(f"{col}: {val:,}")
                    elif isinstance(val, float):
                        if col == 'change_percent':
                            sign = '+' if val >= 0 else ''
                            info_parts.append(f"{col}: {sign}{val:.2f}%")
                        else:
                            info_parts.append(f"{col}: {val:.2f}")
                    else:
                        info_parts.append(f"{col}: {val}")

                print(f"   ç¬¬{i + 1}æ¡: {', '.join(info_parts)}")

            # æ˜¾ç¤ºåˆ—ä¿¡æ¯
            print(f"ğŸ“Š æœ€ç»ˆæ•°æ®å½¢çŠ¶: {len(df_processed)} è¡Œ Ã— {len(df_processed.columns)} åˆ—")
            print(
                f"   æŠ€æœ¯æŒ‡æ ‡åˆ—: {[col for col in df_processed.columns if 'ma' in col or 'bb' in col or 'rsi' in col]}")

        print("âœ… å¢å¼ºç‰ˆæ•°æ®å¤„ç†å™¨æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return False


if __name__ == "__main__":
    success = test_enhanced_processor()
    sys.exit(0 if success else 1)