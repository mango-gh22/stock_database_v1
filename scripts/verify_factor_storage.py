# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/scripts\verify_factor_storage.py
# File Name: verify_factor_storage
# @ Author: mango-gh22
# @ Dateï¼š2026/1/3 19:37
"""
desc éªŒè¯å› å­æ•°æ®å­˜å‚¨æƒ…å†µ
æ£€æŸ¥ï¼šå­˜å‚¨è®°å½•æ•°ã€æ•°æ®å®Œæ•´æ€§ã€æ—¥æœŸèŒƒå›´ç­‰
"""

import sys
import os
from datetime import datetime, timedelta
import pandas as pd

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.factor_storage_manager import FactorStorageManager
from src.data.baostock_pb_factor_downloader import BaostockPBFactorDownloader
from src.config.logging_config import setup_logging

logger = setup_logging()


def verify_factor_storage(symbol: str = '600519'):
    """éªŒè¯å› å­æ•°æ®å­˜å‚¨æƒ…å†µ"""
    print(f"\nğŸ” éªŒè¯å› å­æ•°æ®å­˜å‚¨: {symbol}")
    print("=" * 50)

    try:
        # åˆå§‹åŒ–
        storage = FactorStorageManager()
        downloader = BaostockPBFactorDownloader()

        # 1. æ£€æŸ¥æœ€åæ›´æ–°æ—¥æœŸ
        last_date = storage.get_last_factor_date(symbol)
        print(f"1ï¸âƒ£ æœ€åæ›´æ–°æ—¥æœŸ: {last_date or 'æ— æ•°æ®'}")

        # 2. ä»æ•°æ®åº“æŸ¥è¯¢å®é™…å­˜å‚¨çš„å› å­æ•°æ®
        clean_symbol = str(symbol).replace('.', '')

        with storage.db_connector.get_connection() as conn:
            # æŸ¥è¯¢æ€»è®°å½•æ•°
            df_total = pd.read_sql_query(
                f"SELECT COUNT(*) as total_count FROM stock_daily_data WHERE symbol = '{clean_symbol}'",
                conn
            )
            total_count = df_total['total_count'].iloc[0]

            # æŸ¥è¯¢æœ‰å› å­æ•°æ®çš„è®°å½•æ•°
            df_factor = pd.read_sql_query(
                f"""SELECT COUNT(*) as factor_count 
                    FROM stock_daily_data 
                    WHERE symbol = '{clean_symbol}' 
                    AND (pb IS NOT NULL OR pe_ttm IS NOT NULL OR ps_ttm IS NOT NULL)""",
                conn
            )
            factor_count = df_factor['factor_count'].iloc[0]

            # æŸ¥è¯¢å› å­æ•°æ®çš„æ—¥æœŸèŒƒå›´
            df_range = pd.read_sql_query(
                f"""SELECT MIN(trade_date) as first_date, MAX(trade_date) as last_date
                    FROM stock_daily_data 
                    WHERE symbol = '{clean_symbol}' 
                    AND pb IS NOT NULL""",
                conn
            )

            # æŸ¥è¯¢å› å­å­—æ®µçš„ç»Ÿè®¡ä¿¡æ¯
            df_stats = pd.read_sql_query(
                f"""SELECT 
                        COUNT(pb) as pb_count,
                        COUNT(pe_ttm) as pe_ttm_count,
                        COUNT(ps_ttm) as ps_ttm_count,
                        AVG(pb) as avg_pb,
                        AVG(pe_ttm) as avg_pe_ttm
                    FROM stock_daily_data 
                    WHERE symbol = '{clean_symbol}'""",
                conn
            )

        print(f"2ï¸âƒ£ æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»è®°å½•æ•°: {total_count}")
        print(f"   æœ‰å› å­è®°å½•æ•°: {factor_count}")
        print(f"   å› å­è¦†ç›–ç‡: {factor_count / total_count * 100:.1f}%" if total_count > 0 else "   æ— æ•°æ®")

        if not df_range.empty and df_range['first_date'].iloc[0]:
            print(f"3ï¸âƒ£ å› å­æ—¥æœŸèŒƒå›´:")
            print(f"   æœ€æ—©: {df_range['first_date'].iloc[0]}")
            print(f"   æœ€æ™š: {df_range['last_date'].iloc[0]}")

        if not df_stats.empty:
            print(f"4ï¸âƒ£ å› å­ç»Ÿè®¡:")
            print(f"   PBè®°å½•æ•°: {df_stats['pb_count'].iloc[0]}")
            print(f"   PE_TTMè®°å½•æ•°: {df_stats['pe_ttm_count'].iloc[0]}")
            print(f"   PS_TTMè®°å½•æ•°: {df_stats['ps_ttm_count'].iloc[0]}")
            if df_stats['avg_pb'].iloc[0]:
                print(f"   å¹³å‡PB: {df_stats['avg_pb'].iloc[0]:.2f}")
            if df_stats['avg_pe_ttm'].iloc[0]:
                print(f"   å¹³å‡PE_TTM: {df_stats['avg_pe_ttm'].iloc[0]:.2f}")

        # 5. æ£€æŸ¥æ•°æ®è´¨é‡
        with storage.db_connector.get_connection() as conn:
            # æ£€æŸ¥ç©ºå€¼å’Œå¼‚å¸¸å€¼
            df_quality = pd.read_sql_query(
                f"""SELECT 
                        SUM(CASE WHEN pb IS NULL THEN 1 ELSE 0 END) as pb_null,
                        SUM(CASE WHEN pb <= 0 THEN 1 ELSE 0 END) as pb_non_positive,
                        SUM(CASE WHEN pe_ttm IS NULL THEN 1 ELSE 0 END) as pe_ttm_null,
                        SUM(CASE WHEN pe_ttm <= 0 THEN 1 ELSE 0 END) as pe_ttm_non_positive
                    FROM stock_daily_data 
                    WHERE symbol = '{clean_symbol}'""",
                conn
            )

        if not df_quality.empty:
            print(f"5ï¸âƒ£ æ•°æ®è´¨é‡æ£€æŸ¥:")
            print(f"   PBç©ºå€¼: {df_quality['pb_null'].iloc[0]}")
            print(f"   PBéæ­£å€¼: {df_quality['pb_non_positive'].iloc[0]}")
            print(f"   PE_TTMç©ºå€¼: {df_quality['pe_ttm_null'].iloc[0]}")
            print(f"   PE_TTMéæ­£å€¼: {df_quality['pe_ttm_non_positive'].iloc[0]}")

        # 6. ä¸‹è½½æœ€æ–°æ•°æ®å¯¹æ¯”
        print(f"6ï¸âƒ£ ä¸‹è½½æœ€æ–°æ•°æ®å¯¹æ¯”:")
        try:
            # ä¸‹è½½æœ€è¿‘30å¤©æ•°æ®
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')

            downloaded_data = downloader.fetch_factor_data(symbol, start_date, end_date)
            print(f"   ä¸‹è½½è®°å½•æ•°: {len(downloaded_data)}")

            if not downloaded_data.empty:
                # ä¸æ•°æ®åº“å¯¹æ¯”
                db_dates = set()
                with storage.db_connector.get_connection() as conn:
                    df_db = pd.read_sql_query(
                        f"""SELECT trade_date, pb, pe_ttm 
                            FROM stock_daily_data 
                            WHERE symbol = '{clean_symbol}' 
                            AND trade_date >= '{start_date}' 
                            AND trade_date <= '{end_date}'""",
                        conn
                    )
                    db_dates = set(df_db['trade_date'].astype(str).tolist())

                downloaded_dates = set(downloaded_data['trade_date'].astype(str).tolist())

                missing_in_db = downloaded_dates - db_dates
                extra_in_db = db_dates - downloaded_dates

                print(f"   æ•°æ®åº“å·²æœ‰: {len(db_dates)} ä¸ªæ—¥æœŸ")
                print(f"   ä¸‹è½½æ•°æ®: {len(downloaded_dates)} ä¸ªæ—¥æœŸ")
                print(f"   ç¼ºå¤±æ—¥æœŸ: {len(missing_in_db)} ä¸ª")
                print(f"   å¤šä½™æ—¥æœŸ: {len(extra_in_db)} ä¸ª")

                if missing_in_db:
                    print(f"   å…·ä½“ç¼ºå¤±: {sorted(list(missing_in_db))[:5]}...")

        except Exception as e:
            print(f"   ä¸‹è½½å¯¹æ¯”å¤±è´¥: {e}")

        print("\nâœ… éªŒè¯å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def analyze_storage_discrepancy():
    """åˆ†æå­˜å‚¨è®°å½•æ•°ä¸åŒ¹é…çš„é—®é¢˜"""
    print("\nğŸ”¬ åˆ†æå­˜å‚¨è®°å½•æ•°ä¸åŒ¹é…é—®é¢˜")
    print("=" * 50)

    try:
        storage = FactorStorageManager()

        with storage.db_connector.get_connection() as conn:
            # æ£€æŸ¥stock_daily_dataè¡¨çš„ç»“æ„
            cursor = conn.cursor()
            cursor.execute("DESCRIBE stock_daily_data")
            columns = cursor.fetchall()

            print("è¡¨ç»“æ„æ£€æŸ¥:")
            print(f"  æ€»åˆ—æ•°: {len(columns)}")

            # æ‰¾å‡ºæœ‰å”¯ä¸€çº¦æŸçš„åˆ—
            cursor.execute("""
                SELECT COLUMN_NAME, CONSTRAINT_NAME 
                FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE 
                WHERE TABLE_SCHEMA = DATABASE() 
                AND TABLE_NAME = 'stock_daily_data'
                AND CONSTRAINT_NAME = 'PRIMARY' OR CONSTRAINT_NAME LIKE '%unique%'
            """)
            constraints = cursor.fetchall()

            print(f"  çº¦æŸæ¡ä»¶: {constraints}")

            # æ£€æŸ¥è‚¡ç¥¨600519çš„é‡å¤è®°å½•
            cursor.execute("""
                SELECT symbol, trade_date, COUNT(*) as count
                FROM stock_daily_data
                WHERE symbol LIKE '%600519%'
                GROUP BY symbol, trade_date
                HAVING count > 1
                ORDER BY count DESC
                LIMIT 10
            """)
            duplicates = cursor.fetchall()

            if duplicates:
                print(f"\nâš ï¸  å‘ç°é‡å¤è®°å½•:")
                for dup in duplicates:
                    print(f"  {dup[0]} {dup[1]}: {dup[2]} æ¡é‡å¤")
            else:
                print(f"\nâœ… æ— é‡å¤è®°å½•")

            # æ£€æŸ¥ä¸åŒsymbolæ ¼å¼çš„è®°å½•
            cursor.execute("""
                SELECT DISTINCT symbol
                FROM stock_daily_data
                WHERE symbol LIKE '%600519%'
            """)
            symbols = cursor.fetchall()

            print(f"\nä¸åŒçš„symbolæ ¼å¼:")
            for sym in symbols:
                print(f"  {sym[0]}")

        return True

    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸ“Š PBå› å­æ•°æ®å­˜å‚¨éªŒè¯å·¥å…·")
    print("=" * 60)

    # éªŒè¯ä¸»è¦è‚¡ç¥¨
    test_symbols = ['600519', '000001', '000858']

    for symbol in test_symbols[:1]:  # åªéªŒè¯ç¬¬ä¸€ä¸ª
        verify_factor_storage(symbol)

    # åˆ†æå­˜å‚¨è®°å½•æ•°é—®é¢˜
    analyze_storage_discrepancy()

    print("\n" + "=" * 60)
    print("ğŸ‰ éªŒè¯å·¥å…·è¿è¡Œå®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    main()