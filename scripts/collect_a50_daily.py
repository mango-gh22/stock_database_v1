# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/scripts\collect_a50_daily.py
# File Name: collect_a50_daily
# @ Author: mango-gh22
# @ Dateï¼š2025/12/13 12:42
"""
desc ä» symbols.yaml è¯»å–50åªæˆåˆ†è‚¡çš„ä»£ç 
å°†è‚¡ç¥¨åˆ—è¡¨å’Œè®¾å®šçš„æ—¥æœŸèŒƒå›´ä¼ å…¥ batch_process_stocks æ–¹æ³•
"""

# scripts/collect_a50_daily.py
import yaml
from datetime import datetime, timedelta
from src.data.integrated_pipeline import IntegratedDataPipeline
from src.utils.logger import get_logger

logger = get_logger(__name__)


def collect_csi_a50_data():
    """é‡‡é›†ä¸­è¯A50æŒ‡æ•°æˆåˆ†è‚¡æ—¥çº¿æ•°æ®"""
    logger.info("ğŸš€ å¼€å§‹é‡‡é›†ä¸­è¯A50æŒ‡æ•°æˆåˆ†è‚¡æ•°æ®")

    # 1. åŠ è½½è‚¡ç¥¨åˆ—è¡¨
    with open('config/symbols.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    a50_stocks = config.get('csi_a50', [])
    symbols = [stock['symbol'] for stock in a50_stocks]  # å¾—åˆ° ['000001.SZ', '000002.SZ', ...]

    logger.info(f"ğŸ“‹ åŠ è½½ {len(symbols)} åªæˆåˆ†è‚¡")

    # 2. è®¾ç½®æ—¥æœŸèŒƒå›´ (ç¤ºä¾‹ï¼šé‡‡é›†è¿‡å»ä¸€å¹´çš„å†å²æ•°æ®)
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')

    logger.info(f"ğŸ“… é‡‡é›†æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")

    # 3. åˆå§‹åŒ–å¹¶è¿è¡Œæ•°æ®ç®¡é“
    pipeline = IntegratedDataPipeline()

    # å¯åŠ¨æ‰¹é‡å¤„ç†ï¼ˆå¯è°ƒæ•´ max_concurrent æ§åˆ¶å¹¶å‘æ•°ï¼‰
    report = pipeline.batch_process_stocks(
        symbols=symbols,
        start_date=start_date,
        end_date=end_date,
        adjust='qfq',  # å‰å¤æƒ
        max_concurrent=3  # å»ºè®®è®¾ç½®è¾ƒä½å¹¶å‘æ•°ä»¥é¿å…å¯¹æ•°æ®æºé€ æˆå‹åŠ›
    )

    # 4. æ‰“å°å¹¶ä¿å­˜æŠ¥å‘Š
    logger.info("=" * 60)
    logger.info(f"âœ… æ•°æ®é‡‡é›†ä»»åŠ¡å®Œæˆ")
    logger.info(f"   æˆåŠŸ: {report['success_count']} åª")
    logger.info(f"   å¤±è´¥: {report['error_count']} åª")
    logger.info(f"   æˆåŠŸç‡: {report['success_rate']:.1f}%")

    return report


if __name__ == "__main__":
    collect_csi_a50_data()