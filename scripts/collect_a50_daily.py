# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/scripts\collect_a50_daily.py
# @ Author: mango-gh22
# @ Dateï¼š2025/12/13 12:42
"""
desc ä» symbols.yaml è¯»å–50åªæˆåˆ†è‚¡çš„ä»£ç 
å°†è‚¡ç¥¨åˆ—è¡¨å’Œè®¾å®šçš„æ—¥æœŸèŒƒå›´ä¼ å…¥ batch_process_stocks æ–¹æ³•
desc: ä»ä¸­è¯A50æˆåˆ†è‚¡åˆ—è¡¨å¢é‡ä¸‹è½½æ—¥çº¿æ•°æ®ï¼ˆä»…ä¸‹è½½ç¼ºå¤±æ—¥æœŸï¼‰
      ä½¿ç”¨äº¤æ˜“æ—¥å†æ™ºèƒ½ç¡®å®šæ•°æ®èŒƒå›´ï¼Œæ”¯æŒåœ¨ä»»æ„æ—¥æœŸï¼ˆåŒ…æ‹¬ä¼‘å¸‚æ—¥ï¼‰è¿è¡Œ
"""
# @ Dateï¼š2026/1/18 ç»ˆæä¿®å¤ç‰ˆ - å¼ºåˆ¶å› å­å®Œæ•´æ€§

import sys
import os
import logging
import pandas as pd
from datetime import datetime, timedelta

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.baostock_daily_downloader import BaostockDailyDownloader
from src.data.data_storage import DataStorage
from src.utils.stock_pool_loader import load_a50_components
from src.utils.enhanced_trade_date_manager import get_enhanced_trade_date_manager
from src.data.baostock_pb_factor_downloader import BaostockPBFactorDownloader

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def incremental_download(symbols):
    """
    å¢é‡ä¸‹è½½ - å¼ºåˆ¶å› å­å®Œæ•´æ€§ç‰ˆæœ¬

    é€»è¾‘ï¼š
    1. ä¸‹è½½ä»·æ ¼+å› å­æ•°æ®ï¼ˆä¸€æ¬¡è¯·æ±‚ï¼‰
    2. éªŒè¯å› å­å­—æ®µå®Œæ•´æ€§ï¼ˆæ£€æŸ¥ç©ºå€¼ç‡ï¼‰
    3. å¦‚æœå› å­ç¼ºå¤±>50%ï¼Œè§¦å‘å› å­è¡¥å…¨
    4. åˆå¹¶åå­˜å‚¨
    """
    if not symbols:
        logger.error("è‚¡ç¥¨åˆ—è¡¨ä¸ºç©º")
        return False

    # åˆå§‹åŒ–ç»„ä»¶
    price_downloader = BaostockDailyDownloader()
    factor_downloader = BaostockPBFactorDownloader()
    storage = DataStorage()
    trade_manager = get_enhanced_trade_date_manager()

    # è·å–æœ€åäº¤æ˜“æ—¥
    global_end_date = trade_manager.get_last_trade_date_str()
    logger.info(f"ğŸ“… å…¨å±€æˆªæ­¢æ—¥: {global_end_date}")

    success_count = 0

    for i, symbol in enumerate(symbols, 1):
        try:
            logger.info(f"[{i}/{len(symbols)}] å¤„ç† {symbol}")

            # âœ… æ­¥éª¤1ï¼šæŸ¥è¯¢æ•°æ®åº“æœ€åæ—¥æœŸï¼Œç¡®å®šä¸‹è½½èŒƒå›´
            last_date_str = storage.get_last_update_date(symbol)
            if last_date_str:
                last_dt = datetime.strptime(last_date_str, '%Y-%m-%d')
                start_date = (last_dt + timedelta(days=1)).strftime('%Y%m%d')

                if start_date > global_end_date:
                    logger.info(f"  â­ï¸  {symbol} å·²æœ€æ–°ï¼Œè·³è¿‡")
                    continue
            else:
                start_date = "20240101"
                logger.info(f"  ğŸ”„ {symbol} é¦–æ¬¡ä¸‹è½½ï¼Œä» {start_date} å¼€å§‹")

            # âœ… æ­¥éª¤2ï¼šä¸‹è½½ä»·æ ¼+å› å­æ•°æ®ï¼ˆä¸€æ¬¡è¯·æ±‚ï¼‰
            logger.info(f"  ğŸ“¥ ä¸‹è½½ä»·æ ¼+å› å­æ•°æ®: {start_date} ~ {global_end_date}")
            price_df = price_downloader.fetch_single_stock(symbol, start_date, global_end_date)

            if price_df is None or price_df.empty:
                logger.warning(f"  âš ï¸  {symbol} æ— è¿”å›æ•°æ®ï¼ˆå¯èƒ½åœç‰Œï¼‰")
                continue

            # âœ… æ­¥éª¤3ï¼šéªŒè¯å› å­å­—æ®µå®Œæ•´æ€§ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰
            factor_fields = ['pe_ttm', 'pb', 'ps_ttm', 'pcf_ttm']
            factor_missing = {}

            for field in factor_fields:
                if field not in price_df.columns:
                    factor_missing[field] = 'column_missing'
                else:
                    # æ£€æŸ¥ç©ºå€¼ç‡
                    null_rate = price_df[field].isna().sum() / len(price_df) * 100
                    if null_rate > 50:  # ç©ºå€¼ç‡>50%è§†ä¸ºå¼‚å¸¸
                        factor_missing[field] = f'null_rate_{null_rate:.1f}%'

            # âœ… æ­¥éª¤4ï¼šå¦‚æœå› å­å­—æ®µç¼ºå¤±æˆ–ç©ºå€¼ç‡é«˜ï¼Œè§¦å‘å› å­è¡¥å…¨
            if factor_missing:
                logger.warning(f"  âš ï¸  å› å­å­—æ®µå¼‚å¸¸: {factor_missing}")
                logger.info(f"  ğŸ”§ è§¦å‘å› å­è¡¥å…¨ä¸‹è½½: {symbol}")

                # ä¸‹è½½çº¯å› å­æ•°æ®
                factor_df = factor_downloader.fetch_factor_data(symbol, start_date, global_end_date)

                if factor_df is not None and not factor_df.empty:
                    # åˆå¹¶å› å­åˆ°ä»·æ ¼æ•°æ®ï¼ˆè¦†ç›–ç©ºå€¼ï¼‰
                    merge_cols = ['symbol', 'trade_date']
                    df_merged = pd.merge(price_df, factor_df[merge_cols + factor_fields],
                                         on=merge_cols, how='left', suffixes=('', '_factor'))

                    # ç”¨å› å­æ•°æ®è¦†ç›–ç©ºå€¼
                    for field in factor_fields:
                        if field + '_factor' in df_merged.columns:
                            df_merged[field] = df_merged[field + '_factor'].fillna(df_merged[field])
                            df_merged = df_merged.drop(columns=[field + '_factor'])

                    price_df = df_merged
                    logger.info(f"  âœ… å› å­è¡¥å…¨æˆåŠŸ: {len(factor_df)} æ¡")
                else:
                    logger.error(f"  âŒ å› å­è¡¥å…¨å¤±è´¥: {symbol}")
                    # ç»§ç»­å­˜å‚¨ä»·æ ¼æ•°æ®ï¼ˆå› å­ç•™ç©ºï¼‰

            # âœ… æ­¥éª¤5ï¼šå­˜å‚¨æ•°æ®ï¼ˆä»·æ ¼+å› å­ï¼‰
            rows_affected, report = storage.store_daily_data(price_df)

            if report.get('status') == 'success':
                success_count += 1

                # éªŒè¯å­˜å‚¨åçš„å› å­è¦†ç›–ç‡
                factor_coverage = {}
                for field in factor_fields:
                    if field in price_df.columns:
                        factor_coverage[field] = price_df[field].notna().sum()

                logger.info(f"  âœ… å­˜å‚¨æˆåŠŸ: {rows_affected} è¡Œ")
                logger.debug(f"  ğŸ“Š å› å­è¦†ç›–: {factor_coverage}")
            else:
                logger.error(f"  âŒ å­˜å‚¨å¤±è´¥: {report.get('error')}")

            # âœ… æ­¥éª¤6ï¼šè¯·æ±‚é—´éš”
            if i < len(symbols):
                import time, random
                time.sleep(random.uniform(2, 4))

        except Exception as e:
            logger.error(f"  âŒ å¤„ç† {symbol} å¤±è´¥: {e}", exc_info=True)

    logger.info(f"âœ… å¢é‡é‡‡é›†å®Œæˆï¼æˆåŠŸæ›´æ–° {success_count}/{len(symbols)} åªè‚¡ç¥¨")

    # ç”Ÿæˆå› å­è¦†ç›–ç‡æŠ¥å‘Š
    if success_count > 0:
        generate_factor_coverage_report(storage, symbols)

    return success_count > 0


def generate_factor_coverage_report(storage, symbols):
    """ç”Ÿæˆå› å­è¦†ç›–ç‡æŠ¥å‘Š"""
    try:
        with storage.db_connector.get_connection() as conn:
            with conn.cursor(dictionary=True) as cursor:
                placeholders = ','.join(['%s'] * len(symbols))
                cursor.execute(f"""
                    SELECT 
                        COUNT(*) as total_records,
                        SUM(CASE WHEN pb IS NOT NULL AND pb != 0 THEN 1 ELSE 0 END) as pb_count,
                        SUM(CASE WHEN pe_ttm IS NOT NULL AND pe_ttm != 0 THEN 1 ELSE 0 END) as pe_count,
                        SUM(CASE WHEN ps_ttm IS NOT NULL AND ps_ttm != 0 THEN 1 ELSE 0 END) as ps_count,
                        SUM(CASE WHEN pcf_ttm IS NOT NULL AND pcf_ttm != 0 THEN 1 ELSE 0 END) as pcf_count
                    FROM stock_daily_data
                    WHERE symbol IN ({placeholders}) AND trade_date >= DATE_SUB(CURDATE(), INTERVAL 3 DAY)
                """, tuple(symbols))

                result = cursor.fetchone()

                if result and result['total_records'] > 0:
                    total = result['total_records']
                    logger.info("=" * 50)
                    logger.info("ğŸ“Š å› å­è¦†ç›–ç‡æŠ¥å‘Šï¼ˆæœ€è¿‘3å¤©ï¼‰")
                    logger.info(f"  æ€»è®°å½•: {total} æ¡")
                    logger.info(f"  PB: {result['pb_count']}æ¡ ({result['pb_count'] / total * 100:.1f}%)")
                    logger.info(f"  PE: {result['pe_count']}æ¡ ({result['pe_count'] / total * 100:.1f}%)")
                    logger.info(f"  PS: {result['ps_count']}æ¡ ({result['ps_count'] / total * 100:.1f}%)")
                    logger.info(f"  PCF: {result['pcf_count']}æ¡ ({result['pcf_count'] / total * 100:.1f}%)")
                    logger.info("=" * 50)

    except Exception as e:
        logger.warning(f"ç”Ÿæˆå› å­æŠ¥å‘Šå¤±è´¥: {e}")


def main(symbols=None):
    """å‘½ä»¤è¡Œå…¥å£"""
    if symbols is None:
        symbols = load_a50_components()

    if not symbols:
        logger.error("æœªæ‰¾åˆ°è‚¡ç¥¨åˆ—è¡¨")
        return False

    logger.info(f"ğŸ“‹ åŠ è½½ {len(symbols)} åªæˆåˆ†è‚¡")
    return incremental_download(symbols)


if __name__ == "__main__":
    import sys

    success = main()
    sys.exit(0 if success else 1)