# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/scripts\test_pb_factor_download.py
# File Name: test_pb_factor_downloader
# @ Author: mango-gh22
# @ Dateï¼š2026/1/3 11:21
"""
desc PBå› å­ä¸‹è½½å™¨æµ‹è¯•è„šæœ¬ï¼ˆä¿®æ­£ç‰ˆï¼‰
"""

import sys
import os
import logging
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(f'{log_dir}/pb_factor_download_{datetime.now().strftime("%Y%m%d")}.log')
        ]
    )


def main():
    """ä¸»å‡½æ•°"""
    print("ðŸš€ PBå› å­ä¸‹è½½å™¨é›†æˆæµ‹è¯•ï¼ˆä¿®æ­£ç‰ˆï¼‰")
    print("=" * 60)
    import pandas as pd

    setup_logging()
    logger = logging.getLogger(__name__)

    try:
        from src.data.baostock_pb_factor_downloader import BaostockPBFactorDownloader

        # 1. åˆ›å»ºä¸‹è½½å™¨
        logger.info("åˆå§‹åŒ–PBå› å­ä¸‹è½½å™¨...")
        downloader = BaostockPBFactorDownloader()

        # 2. æµ‹è¯•ç™»å½•
        logger.info("ç™»å½•Baostock...")
        downloader._ensure_logged_in()

        if not hasattr(downloader, 'lg') or not downloader.lg:
            logger.error("Baostockç™»å½•å¤±è´¥")
            return False

        logger.info("âœ… Baostockç™»å½•æˆåŠŸ")

        # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
        # ä½¿ç”¨A50æˆåˆ†è‚¡ä¸­çš„å‡ åª
        test_symbols = [
            '600519',  # è´µå·žèŒ…å°
            '000001',  # å¹³å®‰é“¶è¡Œ
            '000858',  # äº”ç²®æ¶²
        ]

        # æ—¥æœŸèŒƒå›´ï¼šæœ€è¿‘7å¤©ï¼Œé¿å…æ•°æ®è¿‡å¤š
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=7)).strftime('%Y%m%d')

        logger.info(f"æµ‹è¯•é…ç½®:")
        logger.info(f"  è‚¡ç¥¨æ•°é‡: {len(test_symbols)}")
        logger.info(f"  æ—¥æœŸèŒƒå›´: {start_date} - {end_date}")
        logger.info(f"  ä¸‹è½½å› å­: {downloader.download_factor_fields}")

        # 4. æ‰§è¡Œæ‰¹é‡ä¸‹è½½
        logger.info("å¼€å§‹æ‰¹é‡ä¸‹è½½...")
        results = downloader.download_batch_factors(
            symbols=test_symbols,
            start_date=start_date,
            end_date=end_date
        )

        # 5. åˆ†æžç»“æžœ
        logger.info("åˆ†æžä¸‹è½½ç»“æžœ...")

        successful = len(results)
        total_records = sum(len(df) for df in results.values())

        print("\n" + "=" * 60)
        print("ðŸ“Š æµ‹è¯•ç»“æžœæ‘˜è¦:")
        print(f"  æµ‹è¯•è‚¡ç¥¨æ•°: {len(test_symbols)}")
        print(f"  æˆåŠŸä¸‹è½½: {successful}")
        print(f"  å¤±è´¥: {len(test_symbols) - successful}")
        print(f"  æ€»è®°å½•æ•°: {total_records}")

        if not results:
            print("âš ï¸  æ— æ•°æ®ä¸‹è½½æˆåŠŸï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–APIé…ç½®")
            return False

        # æ˜¾ç¤ºæ¯åªè‚¡ç¥¨çš„è®°å½•æ•°
        print("\nðŸ“ˆ å„è‚¡ç¥¨ä¸‹è½½è¯¦æƒ…:")
        for symbol, df in results.items():
            # æ£€æŸ¥æ•°æ®è´¨é‡
            factor_fields_present = []
            for field in downloader.download_factor_fields:
                if field in df.columns and df[field].notna().any():
                    factor_fields_present.append(field)

            print(f"  {symbol}: {len(df)} æ¡è®°å½•")

            if factor_fields_present:
                print(f"    åŒ…å«å› å­: {factor_fields_present}")

                # æ˜¾ç¤ºæœ€è¿‘æ—¥æœŸçš„æ•°æ®
                if not df.empty:
                    latest = df.iloc[0]
                    factor_values = []
                    for field in factor_fields_present:
                        if field in latest and pd.notna(latest[field]):
                            factor_values.append(f"{field}={latest[field]:.2f}")

                    if factor_values:
                        print(f"    æœ€æ–°æ•°æ®: {latest['trade_date']}, {', '.join(factor_values)}")

        # 6. æ•°æ®è´¨é‡ç»Ÿè®¡
        print("\nðŸ” æ•°æ®è´¨é‡ç»Ÿè®¡:")
        for factor_field in downloader.download_factor_fields:
            total_values = 0
            valid_values = 0

            for df in results.values():
                if factor_field in df.columns:
                    total_values += len(df)
                    valid_values += df[factor_field].notna().sum()

            if total_values > 0:
                coverage_rate = (valid_values / total_values) * 100
                print(f"  {factor_field}: {valid_values}/{total_values} ({coverage_rate:.1f}%)")
            else:
                print(f"  {factor_field}: æ— æ•°æ®")

        # 7. ä¿å­˜æ ·æœ¬æ•°æ®
        if results:
            import pandas as pd
            sample_dir = "data/test_samples"
            if not os.path.exists(sample_dir):
                os.makedirs(sample_dir)

            for symbol, df in list(results.items())[:3]:  # ä¿å­˜å‰3åª
                sample_file = f"{sample_dir}/{symbol}_factor_sample.csv"
                df.head(20).to_csv(sample_file, index=False, encoding='utf-8')
                print(f"  ðŸ’¾ {symbol} æ ·æœ¬æ•°æ®ä¿å­˜åˆ°: {sample_file}")

        # 8. é€€å‡ºç™»å½•
        downloader.logout()
        logger.info("âœ… æµ‹è¯•å®Œæˆ")

        return successful > 0

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)