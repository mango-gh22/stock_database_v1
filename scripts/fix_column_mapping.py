# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1/scripts\fix_column_mapping.py
# File Name: fix_column_mapping
# @ Author: mango-gh22
# @ Dateï¼š2025/12/12 21:50
"""
desc æ£€æŸ¥å’Œæ›´æ–°åˆ—åæ˜ å°„
"""

# scripts/fix_column_mapping.py
"""
ä¿®å¤åˆ—åæ˜ å°„é—®é¢˜ - ç¡®ä¿EnhancedDataProcessorçš„è¾“å‡ºåˆ—åä¸æ•°æ®åº“è¡¨åˆ—ååŒ¹é…
"""
import pandas as pd
from src.database.db_connector import DatabaseConnector
from src.utils.logger import get_logger

logger = get_logger(__name__)


def get_database_columns(table_name: str = 'stock_daily_data') -> list:
    """è·å–æ•°æ®åº“è¡¨çš„å®é™…åˆ—å"""
    db = DatabaseConnector()
    try:
        with db.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute(f"DESCRIBE {table_name}")
                columns = [col[0] for col in cursor.fetchall()]
                logger.info(f"æ•°æ®åº“è¡¨ {table_name} æœ‰ {len(columns)} åˆ—")
                return columns
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“åˆ—å¤±è´¥: {e}")
        return []


def check_column_mapping():
    """æ£€æŸ¥å¹¶ä¿®å¤åˆ—åæ˜ å°„"""
    # 1. è·å–æ•°æ®åº“å®é™…åˆ—å
    db_columns = get_database_columns()

    if not db_columns:
        logger.error("æ— æ³•è·å–æ•°æ®åº“åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è¿æ¥")
        return

    logger.info("=" * 60)
    logger.info("æ•°æ®åº“å®é™…åˆ—åï¼ˆå‰20ä¸ªï¼‰ï¼š")
    for col in db_columns[:20]:
        logger.info(f"  - {col}")

    # 2. EnhancedDataProcessor ç”Ÿæˆçš„å…¸å‹åˆ—å
    processor_columns = [
        'open', 'high', 'low', 'close', 'pre_close',
        'volume', 'amount', 'pct_change', 'change', 'amplitude',
        'ma5', 'ma10', 'ma20', 'ma30', 'ma60', 'ma120', 'ma250',
        'volume_ma5', 'volume_ma10', 'volume_ma20',
        'rsi', 'bb_middle', 'bb_upper', 'bb_lower', 'volatility_20d',
        'trade_date', 'symbol', 'data_source', 'processed_time', 'quality_grade'
    ]

    # 3. DataStorage ä¸­çš„åˆ—æ˜ å°„
    storage_mapping = {
        'open': 'open_price',
        'high': 'high_price',
        'low': 'low_price',
        'close': 'close_price',
        'pre_close': 'pre_close_price',
        'change': 'change',
        'pct_change': 'change_percent',
        'volume': 'volume',
        'amount': 'amount',
        'amplitude': 'amplitude',
        'turnover_rate': 'turnover_rate',
        'turnover_rate_f': 'turnover_rate_f',
        'volume_ratio': 'volume_ratio',
        'pe': 'pe',
        'pe_ttm': 'pe_ttm',
        'pb': 'pb',
        'ps': 'ps',
        'ps_ttm': 'ps_ttm',
        'dv_ratio': 'dv_ratio',
        'dv_ttm': 'dv_ttm',
        'total_share': 'total_share',
        'float_share': 'float_share',
        'free_share': 'free_share',
        'total_mv': 'total_mv',
        'circ_mv': 'circ_mv'
    }

    logger.info("\n" + "=" * 60)
    logger.info("æ£€æŸ¥åˆ—åæ˜ å°„ï¼š")

    # æ£€æŸ¥æ˜ å°„æ˜¯å¦å®Œæ•´
    for src_col in processor_columns:
        if src_col in storage_mapping:
            target_col = storage_mapping[src_col]
            if target_col in db_columns:
                logger.info(f"âœ… {src_col} -> {target_col} (æ•°æ®åº“ä¸­å­˜åœ¨)")
            else:
                logger.warning(f"âŒ {src_col} -> {target_col} (æ•°æ®åº“ä¸­ä¸å­˜åœ¨!)")
        else:
            if src_col in ['trade_date', 'symbol', 'data_source', 'processed_time', 'quality_grade']:
                if src_col in db_columns:
                    logger.info(f"âœ… {src_col} (ç›´æ¥ä½¿ç”¨ï¼Œå­˜åœ¨äºæ•°æ®åº“)")
                else:
                    logger.warning(f"âŒ {src_col} (ç›´æ¥ä½¿ç”¨ï¼Œä½†æ•°æ®åº“ä¸­ä¸å­˜åœ¨!)")
            elif src_col in db_columns:
                logger.info(f"âš ï¸ {src_col} (æ— æ˜ å°„ï¼Œä½†ç›´æ¥å­˜åœ¨äºæ•°æ®åº“)")
            else:
                logger.error(f"âŒ {src_col} (æ— æ˜ å°„ä¸”æ•°æ®åº“ä¸­ä¸å­˜åœ¨!)")

    # 4. å»ºè®®ä¿®å¤æ–¹æ¡ˆ
    logger.info("\n" + "=" * 60)
    logger.info("ä¿®å¤å»ºè®®ï¼š")

    # æ–¹æ¡ˆ1: ä¸´æ—¶ä¿®å¤ - æ·»åŠ ç¼ºå¤±çš„åˆ—åˆ°æ•°æ®åº“
    missing_in_db = []
    for src_col in processor_columns:
        target_col = storage_mapping.get(src_col, src_col)
        if target_col not in db_columns and src_col not in ['trade_date', 'symbol', 'data_source', 'processed_time',
                                                            'quality_grade']:
            missing_in_db.append(target_col)

    if missing_in_db:
        logger.warning(f"æ•°æ®åº“ä¸­ç¼ºå¤± {len(missing_in_db)} åˆ—:")
        for col in missing_in_db:
            logger.warning(f"  - {col}")

    # æ–¹æ¡ˆ2: ä¿®å¤DataStorageçš„_preprocess_dataæ–¹æ³•
    logger.info("\nä¿®å¤DataStorageçš„_preprocess_dataæ–¹æ³•ï¼š")
    logger.info("åœ¨_preprocess_dataæ–¹æ³•ä¸­ï¼Œç¡®ä¿é‡å‘½åç”Ÿæ•ˆ")

    return True


def create_fix_sql():
    """åˆ›å»ºä¿®å¤SQLï¼Œæ·»åŠ ç¼ºå¤±çš„åˆ—æˆ–é‡å‘½ååˆ—"""
    db = DatabaseConnector()

    # éœ€è¦æ·»åŠ æˆ–æ£€æŸ¥çš„åˆ—
    columns_to_add = [
        ("open", "DECIMAL(10,4) COMMENT 'å¼€ç›˜ä»·(ä¸´æ—¶å…¼å®¹)'"),
        ("high", "DECIMAL(10,4) COMMENT 'æœ€é«˜ä»·(ä¸´æ—¶å…¼å®¹)'"),
        ("low", "DECIMAL(10,4) COMMENT 'æœ€ä½ä»·(ä¸´æ—¶å…¼å®¹)'"),
        ("close", "DECIMAL(10,4) COMMENT 'æ”¶ç›˜ä»·(ä¸´æ—¶å…¼å®¹)'"),
        ("pre_close", "DECIMAL(10,4) COMMENT 'å‰æ”¶ç›˜ä»·(ä¸´æ—¶å…¼å®¹)'"),
        ("pct_change", "DECIMAL(10,4) COMMENT 'æ¶¨è·Œå¹…(%)(ä¸´æ—¶å…¼å®¹)'"),
    ]

    try:
        with db.get_connection() as conn:
            with conn.cursor() as cursor:
                # è·å–ç°æœ‰åˆ—
                cursor.execute("DESCRIBE stock_daily_data")
                existing_columns = {col[0] for col in cursor.fetchall()}

                added = 0
                for col_name, col_def in columns_to_add:
                    if col_name not in existing_columns:
                        try:
                            alter_sql = f"ALTER TABLE stock_daily_data ADD COLUMN {col_name} {col_def}"
                            cursor.execute(alter_sql)
                            added += 1
                            logger.info(f"âœ… æ·»åŠ å…¼å®¹åˆ—: {col_name}")
                        except Exception as e:
                            logger.warning(f"æ·»åŠ å…¼å®¹åˆ—å¤±è´¥ {col_name}: {e}")

                conn.commit()

                if added > 0:
                    logger.info(f"âœ… æ·»åŠ äº† {added} ä¸ªå…¼å®¹åˆ—")
                else:
                    logger.info("â© æ‰€æœ‰å…¼å®¹åˆ—å·²å­˜åœ¨")

                return True

    except Exception as e:
        logger.error(f"åˆ›å»ºä¿®å¤SQLå¤±è´¥: {e}")
        return False


def test_column_mapping():
    """æµ‹è¯•åˆ—åæ˜ å°„æ˜¯å¦æ­£ç¡®"""
    from src.data.enhanced_processor import create_test_data
    from src.data.enhanced_processor import EnhancedDataProcessor

    logger.info("=" * 60)
    logger.info("æµ‹è¯•åˆ—åæ˜ å°„...")

    try:
        # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = create_test_data()
        logger.info(f"æµ‹è¯•æ•°æ®åˆ—å: {list(test_data.columns)}")

        # 2. å¤„ç†æ•°æ®
        processor = EnhancedDataProcessor()
        symbol = 'sh600519'

        df_processed, quality_report = processor.process_stock_data(
            test_data, symbol, 'test'
        )

        logger.info(f"å¤„ç†åçš„åˆ—å: {list(df_processed.columns)}")

        # 3. æ£€æŸ¥å“ªäº›åˆ—éœ€è¦æ˜ å°„
        mapping_needed = []
        direct_columns = []

        for col in df_processed.columns:
            if col in ['open', 'high', 'low', 'close', 'pre_close', 'pct_change']:
                mapping_needed.append(col)
            elif col in ['trade_date', 'symbol', 'data_source', 'processed_time', 'quality_grade']:
                direct_columns.append(col)

        if mapping_needed:
            logger.warning(f"éœ€è¦æ˜ å°„çš„åˆ—: {mapping_needed}")
        if direct_columns:
            logger.info(f"ç›´æ¥ä½¿ç”¨çš„åˆ—: {direct_columns}")

        return True

    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    print("ğŸ”§ æ£€æŸ¥å¹¶ä¿®å¤åˆ—åæ˜ å°„é—®é¢˜")
    print("=" * 60)

    # 1. æ£€æŸ¥åˆ—æ˜ å°„
    check_column_mapping()

    print("\n" + "=" * 60)
    user_input = input("æ˜¯å¦è¦æ·»åŠ å…¼å®¹åˆ—åˆ°æ•°æ®åº“? (y/n): ")
    if user_input.lower() == 'y':
        create_fix_sql()

    print("\n" + "=" * 60)
    user_input = input("æ˜¯å¦è¦æµ‹è¯•åˆ—åæ˜ å°„? (y/n): ")
    if user_input.lower() == 'y':
        test_column_mapping()

    print("\n" + "=" * 60)
    print("ğŸ’¡ æ ¹æœ¬è§£å†³æ–¹æ¡ˆ:")
    print("1. ä¿®æ”¹ EnhancedDataProcessor.prepare_for_storage() æ–¹æ³•")
    print("2. ç¡®ä¿åˆ—åæ˜ å°„æ­£ç¡®åº”ç”¨åˆ° DataFrame")
    print("3. æˆ–è€…åœ¨ DataStorage ä¸­ä¿®å¤åˆ—åæ˜ å°„")