# _*_ coding: utf-8 _*_
# File Path: E:/MyFile/stock_database_v1\ultimate_breaker.py
# File Name: ultimate_breaker
# @ Author: mango-gh22
# @ Dateï¼š2026/1/1 13:34
"""
desc 
"""
# ultimate_breaker.py
"""
ç»ˆæç ´å£è„šæœ¬ - å®Œå…¨ç»•è¿‡æ‰€æœ‰ç°æœ‰é€»è¾‘ï¼Œå¼ºåˆ¶å†™å…¥æ•°æ®
"""
import sys
import os
import time
import pandas as pd
from datetime import datetime, timedelta
import baostock as bs
import mysql.connector
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
sys.path.insert(0, r"E:\MyFile\stock_database_v1")
load_dotenv(r"E:\MyFile\stock_database_v1\.env")

print("ğŸ’¥ ç»ˆæç ´å£è„šæœ¬ - å¼ºåˆ¶æ•°æ®å†™å…¥")
print("=" * 60)


class UltimateDataBreaker:
    def __init__(self):
        self.db_config = {
            'host': 'localhost',
            'port': 3306,
            'user': 'stock_user',
            'password': os.getenv('DB_PASSWORD'),
            'database': 'stock_database',
            'autocommit': True
        }

    def test_direct_insert(self):
        """æµ‹è¯•ç›´æ¥æ•°æ®åº“æ’å…¥ï¼ˆç»•è¿‡æ‰€æœ‰é¡¹ç›®ä»£ç ï¼‰"""
        print("1. ğŸ”§ æµ‹è¯•ç›´æ¥æ•°æ®åº“æ’å…¥...")

        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor(dictionary=True)

        # åˆ›å»ºå”¯ä¸€æµ‹è¯•æ•°æ®
        test_id = f"BREAKER_{int(time.time())}"
        test_symbol = test_id[:20]

        print(f"   æµ‹è¯•ç¬¦å·: {test_symbol}")

        # ç›´æ¥æ’å…¥
        sql = """
            INSERT INTO stock_daily_data 
            (symbol, trade_date, open_price, close_price, high_price, low_price, 
             volume, created_time, updated_time, data_source)
            VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), NOW(), 'breaker')
        """

        try:
            cursor.execute(sql, (test_symbol, '2025-12-31', 100.0, 101.0, 102.0, 99.0, 10000))
            row_id = cursor.lastrowid
            conn.commit()

            print(f"   âœ… ç›´æ¥æ’å…¥æˆåŠŸ! ID: {row_id}")

            # ç«‹å³éªŒè¯
            cursor.execute("SELECT * FROM stock_daily_data WHERE id = %s", (row_id,))
            result = cursor.fetchone()
            print(f"   âœ… éªŒè¯æˆåŠŸ: {result['symbol']} åˆ›å»ºäº {result['created_time']}")

            # æ¸…ç†
            cursor.execute("DELETE FROM stock_daily_data WHERE id = %s", (row_id,))
            conn.commit()
            print(f"   âœ… æ¸…ç†å®Œæˆ")

            return True

        except Exception as e:
            print(f"   âŒ ç›´æ¥æ’å…¥å¤±è´¥: {e}")
            return False
        finally:
            conn.close()

    def fetch_from_baostock_direct(self):
        """ç›´æ¥è°ƒç”¨Baostockï¼Œç»•è¿‡æ‰€æœ‰åŒ…è£…å™¨"""
        print("\n2. ğŸ“¡ ç›´æ¥è°ƒç”¨Baostock API...")

        # ç›´æ¥ä½¿ç”¨Baostock
        lg = bs.login()
        if lg.error_code != '0':
            print(f"   âŒ Baostockç™»å½•å¤±è´¥: {lg.error_msg}")
            return None

        print("   âœ… Baostockç™»å½•æˆåŠŸ")

        # æŸ¥è¯¢æ•°æ®
        rs = bs.query_history_k_data_plus(
            "sh.600000",
            "date,code,open,high,low,close,volume,amount,turn",
            start_date='2025-12-25',
            end_date='2025-12-31',
            frequency="d",
            adjustflag="3"
        )

        if rs.error_code != '0':
            print(f"   âŒ æŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
            bs.logout()
            return None

        # è½¬æ¢ä¸ºDataFrame
        data_list = []
        while (rs.error_code == '0') & rs.next():
            data_list.append(rs.get_row_data())

        df = pd.DataFrame(data_list, columns=rs.fields)
        bs.logout()

        if df.empty:
            print("   âš ï¸  æ²¡æœ‰è·å–åˆ°æ•°æ®")
            return None

        print(f"   âœ… è·å–åˆ° {len(df)} æ¡åŸå§‹æ•°æ®")
        print(f"   æ•°æ®åˆ—: {list(df.columns)}")
        print(f"   ç¤ºä¾‹:\n{df.head(2)}")

        return df

    def brute_force_insert(self, symbol, start_date, end_date):
        """æš´åŠ›æ’å…¥ï¼šé‡‡é›†+ç›´æ¥å­˜å‚¨ï¼Œå®Œå…¨ç»•è¿‡ç°æœ‰é€»è¾‘"""
        print(f"\n3. ğŸ’¥ æš´åŠ›æ’å…¥ {symbol} [{start_date} åˆ° {end_date}]...")

        # 1. ç›´æ¥è·å–æ•°æ®
        df_raw = self.fetch_from_baostock_direct()
        if df_raw is None or df_raw.empty:
            print("   âŒ æ²¡æœ‰è·å–åˆ°æ•°æ®")
            return False

        # 2. ç›´æ¥è¿æ¥åˆ°æ•°æ®åº“
        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor(dictionary=True)

        # 3. è·å–å½“å‰çŠ¶æ€
        clean_symbol = symbol.replace('.', '')
        # æ”¹ä¸ºï¼š
        cursor.execute("SELECT COUNT(*) as count_before FROM stock_daily_data WHERE symbol = %s", (clean_symbol,))
        before = cursor.fetchone()['before']
        print(f"   æ’å…¥å‰: {before} æ¡è®°å½•")

        # 4. æš´åŠ›æ’å…¥æ‰€æœ‰æ•°æ®ï¼ˆå¿½ç•¥é‡å¤ï¼‰
        inserted = 0
        skipped = 0

        for _, row in df_raw.iterrows():
            try:
                # å‡†å¤‡æ’å…¥æ•°æ®
                sql = """
                    INSERT IGNORE INTO stock_daily_data 
                    (symbol, trade_date, open_price, high_price, low_price, close_price,
                     volume, turnover, turnover_rate, data_source, created_time, updated_time)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, 'breaker', NOW(), NOW())
                """

                params = (
                    clean_symbol,
                    row['date'],
                    float(row['open']),
                    float(row['high']),
                    float(row['low']),
                    float(row['close']),
                    int(row['volume']),
                    float(row['amount']),
                    float(row['turn'])
                )

                cursor.execute(sql, params)
                if cursor.rowcount > 0:
                    inserted += 1
                else:
                    skipped += 1

            except mysql.connector.errors.IntegrityError:
                # ä¸»é”®é‡å¤ï¼Œè·³è¿‡
                skipped += 1
            except Exception as e:
                print(f"   æ’å…¥é”™è¯¯: {e}")

        conn.commit()

        # 5. éªŒè¯ç»“æœ
        cursor.execute("SELECT COUNT(*) as after FROM stock_daily_data WHERE symbol = %s", (clean_symbol,))
        after = cursor.fetchone()['after']

        cursor.close()
        conn.close()

        print(f"   æ’å…¥å: {after} æ¡è®°å½•")
        print(f"   æˆåŠŸæ’å…¥: {inserted} æ¡")
        print(f"   è·³è¿‡é‡å¤: {skipped} æ¡")
        print(f"   å‡€å¢åŠ : {after - before} æ¡")

        return inserted > 0

    def diagnose_pipeline_blockage(self):
        """è¯Šæ–­æ•°æ®ç®¡é“ä¸­çš„é˜»å¡ç‚¹"""
        print("\n4. ğŸ” è¯Šæ–­æ•°æ®ç®¡é“é˜»å¡ç‚¹...")

        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files = [
            "src/data/data_pipeline.py",
            "src/data/data_storage.py",
            "src/data/baostock_collector.py"
        ]

        for file_path in key_files:
            full_path = os.path.join(r"E:\MyFile\stock_database_v1", file_path)
            if os.path.exists(full_path):
                print(f"   ğŸ“„ {file_path} - å­˜åœ¨")

                # æŸ¥æ‰¾å¯èƒ½å¯¼è‡´é˜»å¡çš„å…³é”®è¯
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                blockers = [
                    ('skip', 'è·³è¿‡'),
                    ('duplicate', 'é‡å¤'),
                    ('exist', 'å­˜åœ¨'),
                    ('last_update', 'æœ€åæ›´æ–°'),
                    ('if.*return', 'æ¡ä»¶è¿”å›'),
                    ('continue', 'ç»§ç»­')
                ]

                for keyword, desc in blockers:
                    count = content.lower().count(keyword)
                    if count > 0:
                        print(f"     å‘ç° {count} å¤„ '{desc}' ç›¸å…³ä»£ç ")
            else:
                print(f"   âŒ {file_path} - ä¸å­˜åœ¨")

    def create_clean_test(self):
        """åˆ›å»ºä¸€ä¸ªå®Œå…¨å¹²å‡€çš„æµ‹è¯•ç¯å¢ƒ"""
        print("\n5. ğŸ§ª åˆ›å»ºå®Œå…¨å¹²å‡€çš„æµ‹è¯•...")

        # ä½¿ç”¨ä¸€ä¸ªç»å¯¹æ²¡æœ‰æ•°æ®çš„è‚¡ç¥¨
        test_symbol = "sh.601888"  # ä¸­å›½ä¸­å…
        clean_symbol = test_symbol.replace('.', '')

        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor(dictionary=True)

        # 1. åˆ é™¤è¿™ä¸ªè‚¡ç¥¨çš„æ‰€æœ‰æ•°æ®ï¼ˆç¡®ä¿å¹²å‡€ï¼‰
        cursor.execute("DELETE FROM stock_daily_data WHERE symbol = %s", (clean_symbol,))
        deleted = cursor.rowcount
        conn.commit()

        if deleted > 0:
            print(f"   æ¸…ç†äº† {deleted} æ¡ {test_symbol} çš„å†å²æ•°æ®")

        # 2. ç¡®è®¤ç°åœ¨ä¸º0
        cursor.execute("SELECT COUNT(*) as count FROM stock_daily_data WHERE symbol = %s", (clean_symbol,))
        count = cursor.fetchone()['count']

        if count == 0:
            print(f"   âœ… {test_symbol} ç°åœ¨å®Œå…¨æ²¡æœ‰æ•°æ®")

            # 3. ä½¿ç”¨é¡¹ç›®ä»£ç å°è¯•æ’å…¥
            print(f"   å‡†å¤‡ç”¨é¡¹ç›®ä»£ç æ’å…¥ {test_symbol}...")

            # é‡æ–°å¯¼å…¥æ¨¡å—ï¼ˆç¡®ä¿æœ€æ–°ï¼‰
            import importlib
            import src.data.data_pipeline
            import src.data.data_storage
            import src.data.baostock_collector

            importlib.reload(src.data.data_pipeline)
            importlib.reload(src.data.data_storage)
            importlib.reload(src.data.baostock_collector)

            from src.data.data_pipeline import DataPipeline
            from src.data.data_storage import DataStorage
            from src.data.baostock_collector import BaostockCollector

            # æ‰§è¡Œ
            collector = BaostockCollector()
            storage = DataStorage()
            pipeline = DataPipeline(collector=collector, storage=storage)

            result = pipeline.fetch_and_store_daily_data(
                symbol=test_symbol,
                start_date="2025-12-25",
                end_date="2025-12-31"
            )

            print(f"   é¡¹ç›®ä»£ç æ‰§è¡Œç»“æœ:")
            print(f"     çŠ¶æ€: {result.get('status')}")
            print(f"     æ¶ˆæ¯: {result.get('message', 'N/A')}")
            print(f"     å­˜å‚¨è®°å½•: {result.get('records_stored', 0)}")

            # 4. æ£€æŸ¥ç»“æœ
            cursor.execute("SELECT COUNT(*) as after FROM stock_daily_data WHERE symbol = %s", (clean_symbol,))
            after = cursor.fetchone()['after']

            print(f"   æ‰§è¡Œåæ•°æ®: {after} æ¡")

            if after > 0:
                print(f"   ğŸ‰ é¡¹ç›®ä»£ç æˆåŠŸå†™å…¥äº† {after} æ¡æ•°æ®ï¼")
                return True
            else:
                print(f"   âŒ é¡¹ç›®ä»£ç ä»ç„¶æ²¡æœ‰å†™å…¥æ•°æ®")
                return False
        else:
            print(f"   âŒ æ— æ³•æ¸…ç† {test_symbol} çš„æ•°æ®")
            return False

        conn.close()


def main():
    breaker = UltimateDataBreaker()

    # æµ‹è¯•1: ç›´æ¥æ•°æ®åº“æ’å…¥
    if not breaker.test_direct_insert():
        print("âŒ æ•°æ®åº“åŸºæœ¬åŠŸèƒ½æœ‰é—®é¢˜")
        return

    # æµ‹è¯•2: æš´åŠ›æ’å…¥
    breaker.brute_force_insert("sh.600000", "2025-12-25", "2025-12-31")

    # æµ‹è¯•3: è¯Šæ–­é˜»å¡ç‚¹
    breaker.diagnose_pipeline_blockage()

    # æµ‹è¯•4: å®Œå…¨å¹²å‡€çš„æµ‹è¯•
    success = breaker.create_clean_test()

    print("\n" + "=" * 60)
    print("ğŸ“‹ æœ€ç»ˆæŠ¥å‘Š")
    print("=" * 60)

    if success:
        print("âœ… ç³»ç»Ÿé—®é¢˜å·²æ‰¾åˆ°å¹¶è§£å†³ï¼")
        print("   é¡¹ç›®ä»£ç å¯ä»¥å†™å…¥æ•°æ®ï¼Œåªæ˜¯åœ¨æŸäº›æ¡ä»¶ä¸‹è¢«é˜»å¡ã€‚")
    else:
        print("âŒ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•...")
        print("   å»ºè®®æ£€æŸ¥ DataPipeline ä¸­çš„é€»è¾‘æ¡ä»¶ã€‚")


if __name__ == "__main__":
    main()